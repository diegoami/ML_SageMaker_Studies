{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plagiarism Detection, Feature Engineering\n",
    "\n",
    "In this project, you will be tasked with building a plagiarism detector that examines an answer text file and performs binary classification; labeling that file as either plagiarized or not, depending on how similar that text file is to a provided, source text. \n",
    "\n",
    "Your first task will be to create some features that can then be used to train a classification model. This task will be broken down into a few discrete steps:\n",
    "\n",
    "* Clean and pre-process the data.\n",
    "* Define features for comparing the similarity of an answer text and a source text, and extract similarity features.\n",
    "* Select \"good\" features, by analyzing the correlations between different features.\n",
    "* Create train/test `.csv` files that hold the relevant features and class labels for train/test data points.\n",
    "\n",
    "In the _next_ notebook, Notebook 3, you'll use the features and `.csv` files you create in _this_ notebook to train a binary classification model in a SageMaker notebook instance.\n",
    "\n",
    "You'll be defining a few different similarity features, as outlined in [this paper](https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c412841_developing-a-corpus-of-plagiarised-short-answers/developing-a-corpus-of-plagiarised-short-answers.pdf), which should help you build a robust plagiarism detector!\n",
    "\n",
    "To complete this notebook, you'll have to complete all given exercises and answer all the questions in this notebook.\n",
    "> All your tasks will be clearly labeled **EXERCISE** and questions as **QUESTION**.\n",
    "\n",
    "It will be up to you to decide on the features to include in your final training and test data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Data\n",
    "\n",
    "The cell below will download the necessary, project data and extract the files into the folder `data/`.\n",
    "\n",
    "This data is a slightly modified version of a dataset created by Paul Clough (Information Studies) and Mark Stevenson (Computer Science), at the University of Sheffield. You can read all about the data collection and corpus, at [their university webpage](https://ir.shef.ac.uk/cloughie/resources/plagiarism_corpus.html). \n",
    "\n",
    "> **Citation for data**: Clough, P. and Stevenson, M. Developing A Corpus of Plagiarised Short Answers, Language Resources and Evaluation: Special Issue on Plagiarism and Authorship Analysis, In Press. [Download]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# you only need to run this cell if you have not yet downloaded the data\n",
    "# otherwise you may skip this cell or comment it out\n",
    "\n",
    "!wget https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c4147f9_data/data.zip\n",
    "!unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plagiarism dataset is made of multiple text files; each of these files has characteristics that are is summarized in a `.csv` file named `file_information.csv`, which we can read in using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>heavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task Category\n",
       "0  g0pA_taska.txt    a      non\n",
       "1  g0pA_taskb.txt    b      cut\n",
       "2  g0pA_taskc.txt    c    light\n",
       "3  g0pA_taskd.txt    d    heavy\n",
       "4  g0pA_taske.txt    e      non"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'data/file_information.csv'\n",
    "plagiarism_df = pd.read_csv(csv_file)\n",
    "\n",
    "# print out the first few rows of data info\n",
    "plagiarism_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Plagiarism\n",
    "\n",
    "Each text file is associated with one **Task** (task A-E) and one **Category** of plagiarism, which you can see in the above DataFrame.\n",
    "\n",
    "###  Tasks, A-E\n",
    "\n",
    "Each text file contains an answer to one short question; these questions are labeled as tasks A-E. For example, Task A asks the question: \"What is inheritance in object oriented programming?\"\n",
    "\n",
    "### Categories of plagiarism \n",
    "\n",
    "Each text file has an associated plagiarism label/category:\n",
    "\n",
    "**1. Plagiarized categories: `cut`, `light`, and `heavy`.**\n",
    "* These categories represent different levels of plagiarized answer texts. `cut` answers copy directly from a source text, `light` answers are based on the source text but include some light rephrasing, and `heavy` answers are based on the source text, but *heavily* rephrased (and will likely be the most challenging kind of plagiarism to detect).\n",
    "     \n",
    "**2. Non-plagiarized category: `non`.** \n",
    "* `non` indicates that an answer is not plagiarized; the Wikipedia source text is not used to create this answer.\n",
    "    \n",
    "**3. Special, source text category: `orig`.**\n",
    "* This is a specific category for the original, Wikipedia source text. We will use these files only for comparison purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pre-Process the Data\n",
    "\n",
    "In the next few cells, you'll be tasked with creating a new DataFrame of desired information about all of the files in the `data/` directory. This will prepare the data for feature extraction and for training a binary, plagiarism classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Convert categorical to numerical data\n",
    "\n",
    "You'll notice that the `Category` column in the data, contains string or categorical values, and to prepare these for feature extraction, we'll want to convert these into numerical values. Additionally, our goal is to create a binary classifier and so we'll need a binary class label that indicates whether an answer text is plagiarized (1) or not (0). Complete the below function `numerical_dataframe` that reads in a `file_information.csv` file by name, and returns a *new* DataFrame with a numerical `Category` column and a new `Class` column that labels each answer as plagiarized or not. \n",
    "\n",
    "Your function should return a new DataFrame with the following properties:\n",
    "\n",
    "* 4 columns: `File`, `Task`, `Category`, `Class`. The `File` and `Task` columns can remain unchanged from the original `.csv` file.\n",
    "* Convert all `Category` labels to numerical labels according to the following rules (a higher value indicates a higher degree of plagiarism):\n",
    "    * 0 = `non`\n",
    "    * 1 = `heavy`\n",
    "    * 2 = `light`\n",
    "    * 3 = `cut`\n",
    "    * -1 = `orig`, this is a special value that indicates an original file.\n",
    "* For the new `Class` column\n",
    "    * Any answer text that is not plagiarized (`non`) should have the class label `0`. \n",
    "    * Any plagiarized answer texts should have the class label `1`. \n",
    "    * And any `orig` texts will have a special label `-1`. \n",
    "\n",
    "### Expected output\n",
    "\n",
    "After running your function, you should get a DataFrame with rows that looks like the following: \n",
    "```\n",
    "\n",
    "        File\t     Task  Category  Class\n",
    "0\tg0pA_taska.txt\ta\t  0   \t0\n",
    "1\tg0pA_taskb.txt\tb\t  3   \t1\n",
    "2\tg0pA_taskc.txt\tc\t  2   \t1\n",
    "3\tg0pA_taskd.txt\td\t  1   \t1\n",
    "4\tg0pA_taske.txt\te\t  0\t   0\n",
    "...\n",
    "...\n",
    "99   orig_taske.txt    e     -1      -1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a csv file and return a transformed dataframe\n",
    "def numerical_dataframe(csv_file='data/file_information.csv'):\n",
    "    '''Reads in a csv file which is assumed to have `File`, `Category` and `Task` columns.\n",
    "       This function does two things: \n",
    "       1) converts `Category` column values to numerical values \n",
    "       2) Adds a new, numerical `Class` label column.\n",
    "       The `Class` column will label plagiarized answers as 1 and non-plagiarized as 0.\n",
    "       Source texts have a special label, -1.\n",
    "       :param csv_file: The directory for the file_information.csv file\n",
    "       :return: A dataframe with numerical categories and a new `Class` label column'''\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['Category'] = df['Category'].map({'non': 0, 'heavy': 1, 'light': 2, 'cut':3, 'orig': -1})\n",
    "    df['Class'] = df['Category'].map({0: 0, 1: 1, 2: 1, 3:1, -1: -1})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "Below are a couple of test cells. The first is an informal test where you can check that your code is working as expected by calling your function and printing out the returned result.\n",
    "\n",
    "The **second** cell below is a more rigorous test cell. The goal of a cell like this is to ensure that your code is working as expected, and to form any variables that might be used in _later_ tests/code, in this case, the data frame, `transformed_df`.\n",
    "\n",
    "> The cells in this notebook should be run in chronological order (the order they appear in the notebook). This is especially important for test cells.\n",
    "\n",
    "Often, later cells rely on the functions, imports, or variables defined in earlier cells. For example, some tests rely on previous tests to work.\n",
    "\n",
    "These tests do not test all cases, but they are a great way to check that you are on the right track!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g0pB_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g0pB_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g0pB_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g0pB_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g0pB_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class\n",
       "0  g0pA_taska.txt    a         0      0\n",
       "1  g0pA_taskb.txt    b         3      1\n",
       "2  g0pA_taskc.txt    c         2      1\n",
       "3  g0pA_taskd.txt    d         1      1\n",
       "4  g0pA_taske.txt    e         0      0\n",
       "5  g0pB_taska.txt    a         0      0\n",
       "6  g0pB_taskb.txt    b         0      0\n",
       "7  g0pB_taskc.txt    c         3      1\n",
       "8  g0pB_taskd.txt    d         2      1\n",
       "9  g0pB_taske.txt    e         1      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# informal testing, print out the results of a called function\n",
    "# create new `transformed_df`\n",
    "transformed_df = numerical_dataframe(csv_file ='data/file_information.csv')\n",
    "\n",
    "# check work\n",
    "# check that all categories of plagiarism have a class label = 1\n",
    "transformed_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n",
      "\n",
      "Example data: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class\n",
       "0  g0pA_taska.txt    a         0      0\n",
       "1  g0pA_taskb.txt    b         3      1\n",
       "2  g0pA_taskc.txt    c         2      1\n",
       "3  g0pA_taskd.txt    d         1      1\n",
       "4  g0pA_taske.txt    e         0      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cell that creates `transformed_df`, if tests are passed\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "# importing tests\n",
    "import problem_unittests as tests\n",
    "\n",
    "# test numerical_dataframe function\n",
    "tests.test_numerical_df(numerical_dataframe)\n",
    "\n",
    "# if above test is passed, create NEW `transformed_df`\n",
    "transformed_df = numerical_dataframe(csv_file ='data/file_information.csv')\n",
    "\n",
    "# check work\n",
    "print('\\nExample data: ')\n",
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing & Splitting Data\n",
    "\n",
    "Recall that the goal of this project is to build a plagiarism classifier. At it's heart, this task is a comparison text; one that looks at a given answer and a source text, compares them and predicts whether an answer has plagiarized from the source. To effectively do this comparison, and train a classifier we'll need to do a few more things: pre-process all of our text data and prepare the text files (in this case, the 95 answer files and 5 original source files) to be easily compared, and split our data into a `train` and `test` set that can be used to train a classifier and evaluate it, respectively. \n",
    "\n",
    "To this end, you've been provided code that adds  additional information to your `transformed_df` from above. The next two cells need not be changed; they add two additional columns to the `transformed_df`:\n",
    "\n",
    "1. A `Text` column; this holds all the lowercase text for a `File`, with extraneous punctuation removed.\n",
    "2. A `Datatype` column; this is a string value `train`, `test`, or `orig` that labels a data point as part of our train or test set\n",
    "\n",
    "The details of how these additional columns are created can be found in the `helpers.py` file in the project directory. You're encouraged to read through that file to see exactly how text is processed and how data is split.\n",
    "\n",
    "Run the cells below to get a `complete_df` that has all the information you need to proceed with plagiarism detection and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept of object orien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>pagerank is a link analysis algorithm used by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the vector space model also called term vector...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem was names after rev thomas bayes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is an algorithm design tec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class  \\\n",
       "0  g0pA_taska.txt    a         0      0   \n",
       "1  g0pA_taskb.txt    b         3      1   \n",
       "2  g0pA_taskc.txt    c         2      1   \n",
       "3  g0pA_taskd.txt    d         1      1   \n",
       "4  g0pA_taske.txt    e         0      0   \n",
       "\n",
       "                                                Text  \n",
       "0  inheritance is a basic concept of object orien...  \n",
       "1  pagerank is a link analysis algorithm used by ...  \n",
       "2  the vector space model also called term vector...  \n",
       "3  bayes theorem was names after rev thomas bayes...  \n",
       "4  dynamic programming is an algorithm design tec...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import helpers \n",
    "\n",
    "# create a text column \n",
    "text_df = helpers.create_text_column(transformed_df)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample processed text:\n",
      "\n",
      " inheritance is a basic concept of object oriented programming where the basic idea is to create new classes that add extra detail to existing classes this is done by allowing the new classes to reuse the methods and variables of the existing classes and new methods and classes are added to specialise the new class inheritance models the is kind of relationship between entities or objects  for example postgraduates and undergraduates are both kinds of student this kind of relationship can be visualised as a tree structure where student would be the more general root node and both postgraduate and undergraduate would be more specialised extensions of the student node or the child nodes  in this relationship student would be known as the superclass or parent class whereas  postgraduate would be known as the subclass or child class because the postgraduate class extends the student class  inheritance can occur on several layers where if visualised would display a larger tree structure for example we could further extend the postgraduate node by adding two extra extended classes to it called  msc student and phd student as both these types of student are kinds of postgraduate student this would mean that both the msc student and phd student classes would inherit methods and variables from both the postgraduate and student classes  \n"
     ]
    }
   ],
   "source": [
    "# after running the cell above\n",
    "# check out the processed text for a single file, by row index\n",
    "row_idx = 0 # feel free to change this index\n",
    "\n",
    "sample_text = text_df.iloc[0]['Text']\n",
    "\n",
    "print('Sample processed text:\\n\\n', sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets\n",
    "\n",
    "The next cell will add a `Datatype` column to a given DataFrame to indicate if the record is: \n",
    "* `train` - Training data, for model training.\n",
    "* `test` - Testing data, for model evaluation.\n",
    "* `orig` - The task's original answer from wikipedia.\n",
    "\n",
    "### Stratified sampling\n",
    "\n",
    "The given code uses a helper function which you can view in the `helpers.py` file in the main project directory. This implements [stratified random sampling](https://en.wikipedia.org/wiki/Stratified_sampling) to randomly split data by task & plagiarism amount. Stratified sampling ensures that we get training and test data that is fairly evenly distributed across task & plagiarism combinations. Approximately 26% of the data is held out for testing and 74% of the data is used for training.\n",
    "\n",
    "The function **train_test_dataframe** takes in a DataFrame that it assumes has `Task` and `Category` columns, and, returns a modified frame that indicates which `Datatype` (train, test, or orig) a file falls into. This sampling will change slightly based on a passed in *random_seed*. Due to a small sample size, this stratified random sampling will provide more stable results for a binary plagiarism classifier. Stability here is smaller *variance* in the accuracy of classifier, given a random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Datatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept of object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>pagerank is a link analysis algorithm used by ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the vector space model also called term vector...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem was names after rev thomas bayes...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is an algorithm design tec...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g0pB_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept in object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g0pB_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pagerank pr refers to both the concept and the...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g0pB_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>vector space model is an algebraic model for r...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g0pB_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem relates the conditional and marg...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g0pB_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dynamic programming is a method for solving ma...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class  \\\n",
       "0  g0pA_taska.txt    a         0      0   \n",
       "1  g0pA_taskb.txt    b         3      1   \n",
       "2  g0pA_taskc.txt    c         2      1   \n",
       "3  g0pA_taskd.txt    d         1      1   \n",
       "4  g0pA_taske.txt    e         0      0   \n",
       "5  g0pB_taska.txt    a         0      0   \n",
       "6  g0pB_taskb.txt    b         0      0   \n",
       "7  g0pB_taskc.txt    c         3      1   \n",
       "8  g0pB_taskd.txt    d         2      1   \n",
       "9  g0pB_taske.txt    e         1      1   \n",
       "\n",
       "                                                Text Datatype  \n",
       "0  inheritance is a basic concept of object orien...    train  \n",
       "1  pagerank is a link analysis algorithm used by ...     test  \n",
       "2  the vector space model also called term vector...    train  \n",
       "3  bayes theorem was names after rev thomas bayes...    train  \n",
       "4  dynamic programming is an algorithm design tec...    train  \n",
       "5  inheritance is a basic concept in object orien...    train  \n",
       "6  pagerank pr refers to both the concept and the...    train  \n",
       "7  vector space model is an algebraic model for r...     test  \n",
       "8  bayes theorem relates the conditional and marg...    train  \n",
       "9  dynamic programming is a method for solving ma...     test  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 1 # can change; set for reproducibility\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import helpers\n",
    "\n",
    "# create new df with Datatype (train, test, orig) column\n",
    "# pass in `text_df` from above to create a complete dataframe, with all the information you need\n",
    "complete_df = helpers.train_test_dataframe(text_df, random_seed=random_seed)\n",
    "\n",
    "# check results\n",
    "complete_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Plagiarism\n",
    "\n",
    "Now that you've prepared this data and created a `complete_df` of information, including the text and class associated with each file, you can move on to the task of extracting similarity features that will be useful for plagiarism classification. \n",
    "\n",
    "> Note: The following code exercises, assume that the `complete_df` as it exists now, will **not** have its existing columns modified. \n",
    "\n",
    "The `complete_df` should always include the columns: `['File', 'Task', 'Category', 'Class', 'Text', 'Datatype']`. You can add additional columns, and you can create any new DataFrames you need by copying the parts of the `complete_df` as long as you do not modify the existing values, directly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Similarity Features \n",
    "\n",
    "One of the ways we might go about detecting plagiarism, is by computing **similarity features** that measure how similar a given answer text is as compared to the original wikipedia source text (for a specific task, a-e). The similarity features you will use are informed by [this paper on plagiarism detection](https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c412841_developing-a-corpus-of-plagiarised-short-answers/developing-a-corpus-of-plagiarised-short-answers.pdf). \n",
    "> In this paper, researchers created features called **containment** and **longest common subsequence**. \n",
    "\n",
    "Using these features as input, you will train a model to distinguish between plagiarized and not-plagiarized text files.\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "Let's talk a bit more about the features we want to include in a plagiarism detection model and how to calculate such features. In the following explanations, I'll refer to a submitted text file as a **Student Answer Text (A)** and the original, wikipedia source file (that we want to compare that answer to) as the **Wikipedia Source Text (S)**.\n",
    "\n",
    "### Containment\n",
    "\n",
    "Your first task will be to create **containment features**. To understand containment, let's first revisit a definition of [n-grams](https://en.wikipedia.org/wiki/N-gram). An *n-gram* is a sequential word grouping. For example, in a line like \"bayes rule gives us a way to combine prior knowledge with new information,\" a 1-gram is just one word, like \"bayes.\" A 2-gram might be \"bayes rule\" and a 3-gram might be \"combine prior knowledge.\"\n",
    "\n",
    "> Containment is defined as the **intersection** of the n-gram word count of the Wikipedia Source Text (S) with the n-gram word count of the Student  Answer Text (S) *divided* by the n-gram word count of the Student Answer Text.\n",
    "\n",
    "$$ \\frac{\\sum{count(\\text{ngram}_{A}) \\cap count(\\text{ngram}_{S})}}{\\sum{count(\\text{ngram}_{A})}} $$\n",
    "\n",
    "If the two texts have no n-grams in common, the containment will be 0, but if _all_ their n-grams intersect then the containment will be 1. Intuitively, you can see how having longer n-gram's in common, might be an indication of cut-and-paste plagiarism. In this project, it will be up to you to decide on the appropriate `n` or several `n`'s to use in your final model.\n",
    "\n",
    "### EXERCISE: Create containment features\n",
    "\n",
    "Given the `complete_df` that you've created, you should have all the information you need to compare any Student  Answer Text (A) with its appropriate Wikipedia Source Text (S). An answer for task A should be compared to the source text for task A, just as answers to tasks B, C, D, and E should be compared to the corresponding original source text.\n",
    "\n",
    "In this exercise, you'll complete the function, `calculate_containment` which calculates containment based upon the following parameters:\n",
    "* A given DataFrame, `df` (which is assumed to be the `complete_df` from above)\n",
    "* An `answer_filename`, such as 'g0pB_taskd.txt' \n",
    "* An n-gram length, `n`\n",
    "\n",
    "### Containment calculation\n",
    "\n",
    "The general steps to complete this function are as follows:\n",
    "1. From *all* of the text files in a given `df`, create an array of n-gram counts; it is suggested that you use a [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) for this purpose.\n",
    "2. Get the processed answer and source texts for the given `answer_filename`.\n",
    "3. Calculate the containment between an answer and source text according to the following equation.\n",
    "\n",
    "    >$$ \\frac{\\sum{count(\\text{ngram}_{A}) \\cap count(\\text{ngram}_{S})}}{\\sum{count(\\text{ngram}_{A})}} $$\n",
    "    \n",
    "4. Return that containment value.\n",
    "\n",
    "You are encouraged to write any helper functions that you need to complete the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ngram containment for one answer file/source file pair in a df\n",
    "from nltk import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "ngram_map = {}\n",
    "\n",
    "def get_grams_from_text(text, n):\n",
    "    tokens = text.split()\n",
    "    grams = set(ngrams(tokens, n))\n",
    "    \n",
    "    return grams\n",
    "\n",
    "\n",
    "#def find_ngrams_in_file(filename, n):\n",
    "#    if filename in ngram_map:\n",
    "#        return ngram_map[filename]\n",
    "#    else:\n",
    "#        with open(filename) as f:\n",
    "#            text = f.read()\n",
    "#            \n",
    "#           ngrams = get_grams_from_text(text, n)\n",
    "#            ngram_map[filename] = ngrams\n",
    "#    return ngram_map[filename] \n",
    "\n",
    "def containment_value(answer, orig, n):\n",
    "    orig_ngrams = get_grams_from_text(orig, n)\n",
    "    answer_ngrams = get_grams_from_text(answer, n)\n",
    "    ins_ngrams = orig_ngrams.intersection(answer_ngrams)\n",
    "    \n",
    "    print(len(orig_ngrams), len(answer_ngrams), len(ins_ngrams))\n",
    "    print(ins_ngrams)\n",
    "\n",
    "    result = len(ins_ngrams) / len(answer_ngrams)\n",
    "    return result\n",
    "\n",
    "def calculate_containment(df, n, answer_filename):\n",
    "    '''Calculates the containment between a given answer text and its associated source text.\n",
    "       This function creates a count of ngrams (of a size, n) for each text file in our data.\n",
    "       Then calculates the containment by finding the ngram count for a given answer text, \n",
    "       and its associated source text, and calculating the normalized intersection of those counts.\n",
    "       :param df: A dataframe with columns,\n",
    "           'File', 'Task', 'Category', 'Class', 'Text', and 'Datatype'\n",
    "       :param n: An integer that defines the ngram size\n",
    "       :param answer_filename: A filename for an answer text in the df, ex. 'g0pB_taskd.txt'\n",
    "       :return: A single containment value that represents the similarity\n",
    "           between an answer text and its source text.\n",
    "    '''\n",
    "    task = df[df['File'] == answer_filename]['Task'].values[0]\n",
    "    text = df[df['File'] == answer_filename]['Text'].values[0]\n",
    "    orig = df[(df['Task'] == task) & (df['Category'] == -1)]['Text'].values[0]\n",
    "    #text, orig = 'this is the answer', 'this is the source'\n",
    "    vectorizer = CountVectorizer(analyzer='word', ngram_range=(n, n))\n",
    "    corpus = [orig, text]\n",
    "    all_ngrams = vectorizer.fit_transform(corpus)\n",
    "    print(orig)\n",
    "    print(text)\n",
    "    print(vectorizer.get_feature_names())\n",
    "    orig_ngram_array = all_ngrams[0].toarray().ravel()\n",
    "    text_ngram_array = all_ngrams[1].toarray().ravel()\n",
    "    print(orig_ngram_array)\n",
    "    print(text_ngram_array)\n",
    "    \n",
    "\n",
    "    text_ngrams = sum(text_ngram_array > 0)\n",
    "    orig_ngrams = sum(orig_ngram_array > 0)\n",
    "    intersect_array = text_ngram_array & orig_ngram_array \n",
    "    inters_ngrams = sum(intersect_array > 0)\n",
    "    \n",
    "    #all_ngrams_count = len(all_ngrams)\n",
    "    \n",
    "    \n",
    "    #task = df[df['File'] == answer_filename]['Task'].values[0]\n",
    "    #text = df[df['File'] == answer_filename]['Text'].values[0]\n",
    "        \n",
    "    #orig = df[(df['Task'] == task) & (df['Category'] == -1)]['Text'].values[0]\n",
    "    #value = containment_value(text, orig, n)\n",
    "\n",
    "    return inters_ngrams / text_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "inheritance is a basic concept of object oriented programming where the basic idea is to create new classes that add extra detail to existing classes this is done by allowing the new classes to reuse the methods and variables of the existing classes and new methods and classes are added to specialise the new class inheritance models the is kind of relationship between entities or objects  for example postgraduates and undergraduates are both kinds of student this kind of relationship can be visualised as a tree structure where student would be the more general root node and both postgraduate and undergraduate would be more specialised extensions of the student node or the child nodes  in this relationship student would be known as the superclass or parent class whereas  postgraduate would be known as the subclass or child class because the postgraduate class extends the student class  inheritance can occur on several layers where if visualised would display a larger tree structure for example we could further extend the postgraduate node by adding two extra extended classes to it called  msc student and phd student as both these types of student are kinds of postgraduate student this would mean that both the msc student and phd student classes would inherit methods and variables from both the postgraduate and student classes  \n",
      "['1967', 'about', 'abstraction', 'accomplished', 'add', 'added', 'adding', 'advantage', 'all', 'allowing', 'already', 'also', 'an', 'ancestor', 'and', 'another', 'apple', 'apples', 'applied', 'are', 'as', 'attributes', 'base', 'basic', 'be', 'because', 'been', 'behavior', 'being', 'belongs', 'between', 'both', 'by', 'called', 'can', 'categorization', 'child', 'class', 'classes', 'code', 'cognitive', 'common', 'complex', 'complexity', 'computer', 'concept', 'consider', 'container', 'control', 'controlled', 'conversely', 'could', 'create', 'crucial', 'defined', 'derived', 'describes', 'design', 'detail', 'display', 'done', 'dual', 'each', 'economy', 'either', 'entities', 'entity', 'established', 'etc', 'example', 'existing', 'exposed', 'extend', 'extended', 'extends', 'extensions', 'extra', 'fleshy', 'for', 'form', 'from', 'fruit', 'further', 'general', 'generalization', 'given', 'group', 'has', 'have', 'help', 'hierarchy', 'human', 'idea', 'if', 'in', 'information', 'inherit', 'inheritance', 'instance', 'instances', 'intended', 'interfaces', 'invented', 'is', 'it', 'its', 'kind', 'kinds', 'known', 'languages', 'larger', 'layers', 'lead', 'learning', 'less', 'little', 'lot', 'mango', 'many', 'mature', 'may', 'mean', 'means', 'mechanism', 'methods', 'models', 'modification', 'modules', 'more', 'msc', 'naturally', 'needs', 'new', 'no', 'node', 'nodes', 'not', 'number', 'object', 'objects', 'occur', 'of', 'on', 'one', 'only', 'or', 'orange', 'oriented', 'others', 'over', 'overriding', 'parent', 'particularities', 'phd', 'pieces', 'plant', 'polymorphism', 'postgraduate', 'postgraduates', 'powerful', 'pre', 'problem', 'processing', 'program', 'programming', 'properties', 'provides', 'reducing', 'referred', 'relation', 'relationship', 'relationships', 'replacing', 'represent', 'representation', 'reuse', 'root', 'seed', 'several', 'share', 'shared', 'similar', 'simula', 'since', 'sometimes', 'specialise', 'specialised', 'specific', 'stored', 'structure', 'student', 'subclass', 'such', 'sufficiently', 'superclass', 'support', 'take', 'that', 'the', 'therefore', 'these', 'this', 'those', 'to', 'tree', 'two', 'types', 'typically', 'undergraduate', 'undergraduates', 'used', 'using', 'variables', 'view', 'visualised', 'was', 'way', 'we', 'what', 'where', 'whereas', 'which', 'wider', 'with', 'within', 'would', 'yo']\n",
      "[ 1  2  1  1  0  0  1  1  2  0  1  1  4  3  3  1  3  2  1  3  3  1  1  0\n",
      "  3  1  1  1  2  1  1  0  7  3  3  2  0  0  8  4  1  1  1  1  1  1  1  1\n",
      "  1  1  1  0  0  1  1  1  1  1  0  0  0  1  1  1  1  1  1  1  1  0  2  2\n",
      "  0  0  0  0  0  1  4  1  0  5  0  0  3  1  1  1  1  1  1  1  0  0  3  2\n",
      "  2  9  1  1  1  1  1 12  1  1  0  0  2  1  0  0  1  1  1  1  1  1  2  1\n",
      "  2  0  1  1  2  0  1  1  1  0  1  1  3  1  0  0  1  1  1  2  0 12  0  2\n",
      "  1  6  2  1  1  1  1  0  1  0  1  1  1  0  0  1  1  1  1  1  1  1  1  1\n",
      "  1  1  0  1  1  1  1  1  0  1  0  1  1  1  1  1  1  0  0  2  1  0  0  0\n",
      "  1  2  0  1  1  3 10  1  0  0  1 10  0  0  0  1  0  0  1  1  0  1  0  1\n",
      "  1  0  1  0  0  3  1  2  1  0  2]\n",
      "[ 0  0  0  0  1  1  1  0  0  1  0  0  0  0 10  0  0  0  0  3  4  0  0  2\n",
      "  5  1  0  0  0  0  1  5  2  1  2  0  2  5  8  0  0  0  0  0  0  1  0  0\n",
      "  0  0  0  1  1  0  0  0  0  0  1  1  1  0  0  0  0  1  0  0  0  2  2  0\n",
      "  1  1  1  1  2  0  2  0  1  0  1  1  0  0  0  0  0  0  0  0  1  1  1  0\n",
      "  1  3  0  0  0  0  0  4  1  0  2  2  2  0  1  1  0  0  0  0  0  0  0  0\n",
      "  0  1  0  0  3  1  0  0  2  2  0  0  4  0  3  1  0  0  1  1  1  8  1  0\n",
      "  0  4  0  1  0  0  0  1  0  2  0  0  0  6  1  0  0  0  0  0  1  0  0  0\n",
      "  0  0  3  0  0  0  0  1  1  0  1  0  0  0  0  0  0  1  1  0  0  2 12  1\n",
      "  0  0  1  0  0  2 16  0  1  4  0  5  2  1  1  0  1  1  0  0  2  0  2  0\n",
      "  0  1  0  3  1  0  0  0  0  7  0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2765957446808511"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_containment(complete_df, 1, 'g0pA_taska.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "After you've implemented the containment function, you can test out its behavior. \n",
    "\n",
    "The cell below iterates through the first few files, and calculates the original category _and_ containment values for a specified n and file.\n",
    "\n",
    ">If you've implemented this correctly, you should see that the non-plagiarized have low or close to 0 containment values and that plagiarized examples have higher containment values, closer to 1.\n",
    "\n",
    "Note what happens when you change the value of n. I recommend applying your code to multiple files and comparing the resultant containment values. You should see that the highest containment values correspond to files with the highest category (`cut`) of plagiarism level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "inheritance is a basic concept of object oriented programming where the basic idea is to create new classes that add extra detail to existing classes this is done by allowing the new classes to reuse the methods and variables of the existing classes and new methods and classes are added to specialise the new class inheritance models the is kind of relationship between entities or objects  for example postgraduates and undergraduates are both kinds of student this kind of relationship can be visualised as a tree structure where student would be the more general root node and both postgraduate and undergraduate would be more specialised extensions of the student node or the child nodes  in this relationship student would be known as the superclass or parent class whereas  postgraduate would be known as the subclass or child class because the postgraduate class extends the student class  inheritance can occur on several layers where if visualised would display a larger tree structure for example we could further extend the postgraduate node by adding two extra extended classes to it called  msc student and phd student as both these types of student are kinds of postgraduate student this would mean that both the msc student and phd student classes would inherit methods and variables from both the postgraduate and student classes  \n",
      "['1967 for simula', 'about each specific', 'about specific entities', 'abstraction of apple', 'accomplished either by', 'add extra detail', 'added to specialise', 'adding new methods', 'adding two extra', 'advantage of inheritance', 'all fruit such', 'all the properties', 'allowing the new', 'already been defined', 'also sometimes called', 'an abstraction of', 'an advantage of', 'an ancestor complex', 'an apple is', 'ancestor classes it', 'ancestor complex inheritance', 'ancestor or by', 'and behavior of', 'and both postgraduate', 'and classes are', 'and cognitive economy', 'and many others', 'and new methods', 'and phd student', 'and student classes', 'and undergraduate would', 'and undergraduates are', 'and variables from', 'and variables of', 'another view dual', 'apple is fruit', 'apple orange etc', 'apple orange mango', 'apples are fruit', 'apples may naturally', 'applied to wider', 'are added to', 'are both kinds', 'are called objects', 'are fruit an', 'are kinds of', 'are referred to', 'as base classes', 'as being fleshy', 'as both these', 'as derived classes', 'as the subclass', 'as the superclass', 'as tree structure', 'attributes and behavior', 'base classes or', 'basic concept of', 'basic idea is', 'be an abstraction', 'be established and', 'be known as', 'be more specialised', 'be stored about', 'be the more', 'be visualised as', 'because the is', 'because the postgraduate', 'been defined the', 'behavior of the', 'being controlled by', 'being fleshy container', 'belongs relation can', 'between classes of', 'between entities or', 'both kinds of', 'both postgraduate and', 'both the msc', 'both the postgraduate', 'both these types', 'by adding new', 'by adding two', 'by allowing the', 'by an ancestor', 'by ancestor or', 'by categorization in', 'by means of', 'by overriding replacing', 'by shared control', 'called generalization because', 'called msc student', 'called objects using', 'called polymorphism which', 'can be established', 'can be visualised', 'can consider fruit', 'can occur on', 'can share lot', 'categorization in computer', 'categorization is powerful', 'child class because', 'child nodes in', 'class because the', 'class extends the', 'class inheritance can', 'class inheritance models', 'class whereas postgraduate', 'classes and new', 'classes are added', 'classes instances of', 'classes it is', 'classes known as', 'classes of objects', 'classes or ancestor', 'classes take over', 'classes that add', 'classes that have', 'classes this is', 'classes to it', 'classes to reuse', 'classes which are', 'classes would inherit', 'code being controlled', 'code inheritance is', 'code reducing the', 'code with little', 'cognitive economy less', 'common to all', 'complex inheritance or', 'complexity of the', 'computer languages categorization', 'concept of object', 'concept was invented', 'consider fruit to', 'container for the', 'control code inheritance', 'controlled by shared', 'conversely since apples', 'could further extend', 'create new classes', 'crucial to human', 'defined the inheritance', 'derived classes take', 'describes many pieces', 'design that is', 'detail to existing', 'display larger tree', 'done by allowing', 'dual called polymorphism', 'each specific entity', 'economy less information', 'either by overriding', 'entities is applied', 'entities or objects', 'entity only its', 'established and cognitive', 'etc conversely since', 'example postgraduates and', 'example we could', 'existing classes and', 'existing classes this', 'existing classes which', 'existing code with', 'exposed by an', 'exposed by ancestor', 'extend the postgraduate', 'extended classes to', 'extends the student', 'extensions of the', 'extra detail to', 'extra extended classes', 'fleshy container for', 'for example postgraduates', 'for example we', 'for instance fruit', 'for representation by', 'for simula the', 'for the seed', 'form new classes', 'from both the', 'fruit an apple', 'fruit apples may', 'fruit is generalization', 'fruit such as', 'fruit to be', 'further extend the', 'general root node', 'generalization because the', 'generalization of apple', 'generalization what is', 'given belongs relation', 'group given belongs', 'has another view', 'have already been', 'help reuse existing', 'hierarchy between classes', 'human learning by', 'idea is to', 'if visualised would', 'in 1967 for', 'in computer languages', 'in object oriented', 'in this relationship', 'information needs to', 'information processing crucial', 'inherit all the', 'inherit attributes and', 'inherit methods and', 'inheritance can occur', 'inheritance concept was', 'inheritance is also', 'inheritance is basic', 'inheritance is that', 'inheritance is typically', 'inheritance is way', 'inheritance models the', 'inheritance or inheritance', 'inheritance provides the', 'inheritance therefore has', 'inheritance used within', 'instance fruit is', 'instances of which', 'intended to help', 'interfaces can share', 'invented in 1967', 'is also sometimes', 'is applied to', 'is basic concept', 'is done by', 'is fruit apples', 'is generalization of', 'is intended to', 'is kind of', 'is known about', 'is not sufficiently', 'is powerful mechanism', 'is relationships represent', 'is that modules', 'is to create', 'is typically accomplished', 'is way to', 'it called msc', 'it is intended', 'its particularities inheritance', 'kind of relationship', 'kinds of postgraduate', 'kinds of student', 'known about specific', 'known as derived', 'known as the', 'languages categorization is', 'larger tree structure', 'layers where if', 'lead to the', 'learning by means', 'less information needs', 'little or no', 'lot of code', 'mango and many', 'many others one', 'many pieces of', 'mature may lead', 'may lead to', 'may naturally inherit', 'mean that both', 'means of generalization', 'mechanism number of', 'methods and classes', 'methods and variables', 'methods exposed by', 'methods to those', 'models the is', 'modification inheritance provides', 'modules with sufficiently', 'more general root', 'more methods exposed', 'more specialised extensions', 'msc student and', 'naturally inherit all', 'needs to be', 'new class inheritance', 'new classes instances', 'new classes known', 'new classes that', 'new classes to', 'new methods and', 'new methods to', 'no modification inheritance', 'node and both', 'node by adding', 'node or the', 'nodes in this', 'not sufficiently mature', 'number of information', 'object oriented programming', 'objects for example', 'objects for instance', 'objects using classes', 'occur on several', 'of apple orange', 'of code being', 'of code reducing', 'of generalization what', 'of information processing', 'of inheritance is', 'of object oriented', 'of objects for', 'of plant an', 'of postgraduate student', 'of relationship between', 'of relationship can', 'of student are', 'of student this', 'of the existing', 'of the pre', 'of the program', 'of the student', 'of which are', 'on several layers', 'one can consider', 'one or more', 'only its particularities', 'or ancestor classes', 'or by adding', 'or child class', 'or inherit attributes', 'or inheritance used', 'or more methods', 'or no modification', 'or objects for', 'or parent class', 'or the child', 'orange etc conversely', 'orange mango and', 'oriented programming inheritance', 'oriented programming where', 'others one can', 'over or inherit', 'overriding replacing one', 'parent class whereas', 'particularities inheritance is', 'phd student as', 'phd student classes', 'pieces of code', 'plant an advantage', 'polymorphism which describes', 'postgraduate and student', 'postgraduate and undergraduate', 'postgraduate class extends', 'postgraduate node by', 'postgraduate student this', 'postgraduate would be', 'postgraduates and undergraduates', 'powerful mechanism number', 'pre existing classes', 'processing crucial to', 'program inheritance therefore', 'programming inheritance is', 'programming where the', 'properties common to', 'provides the support', 'reducing the complexity', 'referred to as', 'relation can be', 'relationship between entities', 'relationship can be', 'relationship student would', 'relationships represent hierarchy', 'replacing one or', 'represent hierarchy between', 'representation by categorization', 'reuse existing code', 'reuse the methods', 'root node and', 'seed of plant', 'several layers where', 'share lot of', 'shared control code', 'similar interfaces can', 'simula the new', 'since apples are', 'sometimes called generalization', 'specialise the new', 'specialised extensions of', 'specific entities is', 'specific entity only', 'stored about each', 'structure for example', 'structure where student', 'student and phd', 'student are kinds', 'student as both', 'student class inheritance', 'student classes would', 'student node or', 'student this kind', 'student this would', 'student would be', 'subclass or child', 'such as being', 'sufficiently mature may', 'sufficiently similar interfaces', 'superclass or parent', 'support for representation', 'take over or', 'that add extra', 'that both the', 'that have already', 'that is not', 'that modules with', 'the basic idea', 'the child nodes', 'the complexity of', 'the existing classes', 'the inheritance concept', 'the is kind', 'the is relationships', 'the methods and', 'the more general', 'the msc student', 'the new class', 'the new classes', 'the postgraduate and', 'the postgraduate class', 'the postgraduate node', 'the pre existing', 'the program inheritance', 'the properties common', 'the seed of', 'the student class', 'the student node', 'the subclass or', 'the superclass or', 'the support for', 'the yo yo', 'therefore has another', 'these types of', 'this is done', 'this kind of', 'this relationship student', 'this would mean', 'those exposed by', 'to all fruit', 'to as base', 'to be an', 'to be stored', 'to create new', 'to existing classes', 'to form new', 'to help reuse', 'to human learning', 'to it called', 'to reuse the', 'to specialise the', 'to the yo', 'to those exposed', 'to wider group', 'tree structure for', 'tree structure where', 'two extra extended', 'types of student', 'typically accomplished either', 'undergraduate would be', 'undergraduates are both', 'used within design', 'using classes that', 'variables from both', 'variables of the', 'view dual called', 'visualised as tree', 'visualised would display', 'was invented in', 'way to form', 'we could further', 'what is known', 'where if visualised', 'where student would', 'where the basic', 'whereas postgraduate would', 'which are called', 'which are referred', 'which describes many', 'wider group given', 'with little or', 'with sufficiently similar', 'within design that', 'would be known', 'would be more', 'would be the', 'would display larger', 'would inherit methods', 'would mean that', 'yo yo problem']\n",
      "[1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0\n",
      " 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1\n",
      " 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 1 0 1\n",
      " 1 0 2 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1\n",
      " 1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1\n",
      " 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 2 1 1 1 1 1 0 0 0\n",
      " 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 0 2 1 0 1 1 0 1 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 2 1 1 0 0 2 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 2 0 0 1 0 0 1 0 1 2 0 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0\n",
      " 0 1 0 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 2 1 1 1 1 1 1 1 2 1 0 0 0 1 0 0 1 1 0\n",
      " 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0\n",
      " 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0\n",
      " 0 0 0 0 2 1 1 1 1 1 0]\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google  the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank  other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm  \n",
      "['10 for each', '2005 for 336', '285 999 however', '336 million google', '999 however the', 'about how important', 'about how other', 'academic papers concerning', 'actual visits to', 'algorithm invented by', 'algorithm may be', 'algorithm used by', 'algorithms for web', 'all pages that', 'all the other', 'also analyzes the', 'also called the', 'also influence the', 'among all the', 'an indicator of', 'an individual page', 'analysis algorithm used', 'analyzes the page', 'and actual visits', 'and brin original', 'and denoted by', 'and depends on', 'and extensive research', 'and help to', 'and not to', 'and now ask', 'and pagerank metric', 'and references the', 'and spamdexing google', 'and the pagerank', 'and the trustrank', 'and ways to', 'any collection of', 'any given element', 'applied to any', 'are no links', 'are themselves important', 'as an indicator', 'as the pagerank', 'as the world', 'as vote by', 'as vote of', 'as well as', 'ask com the', 'assigned to stanford', 'assigns numeric weighting', 'assigns numerical weighting', 'assigns to any', 'at more than', 'ballot among all', 'based ranking algorithms', 'based upon the', 'be applied to', 'be vulnerable to', 'been devoted to', 'been patented patent', 'been published since', 'brin original paper', 'but google looks', 'by jon kleinberg', 'by many pages', 'by page for', 'by pages that', 'by pr it', 'by pr the', 'by teoma and', 'by the google', 'by using its', 'called the pagerank', 'cast by pages', 'casts the vote', 'clever project and', 'collection of entities', 'com the ibm', 'concept has proven', 'concerning pagerank have', 'counts as vote', 'defined recursively and', 'democratic nature of', 'denoted by pr', 'denotes site importance', 'depends on the', 'derived from theoretical', 'describes pagerank pagerank', 'details about how', 'devoted to identifying', 'documents such as', 'documents with falsely', 'each element of', 'each webpage on', 'element is also', 'element of hyperlinked', 'engine that assigns', 'entities with reciprocal', 'essence google interprets', 'exchange for use', 'exclusive license rights', 'extensive research has', 'eyes of google', 'factors influence pagerank', 'factors relevance of', 'falsely inflated pagerank', 'for 336 million', 'for each webpage', 'for page but', 'for that page', 'for use of', 'for web pages', 'from 10 for', 'from ballot among', 'from documents with', 'from page to', 'from stanford university', 'from theoretical probability', 'given element is', 'google and the', 'google assigns numeric', 'google describes pagerank', 'google google has', 'google has exclusive', 'google in exchange', 'google internet search', 'google interprets link', 'google looks at', 'google provides no', 'google the pagerank', 'google toolbar also', 'has been devoted', 'has been patented', 'has exclusive license', 'has proven to', 'have been published', 'heavily and help', 'help to make', 'high pagerank receives', 'high rank itself', 'hits algorithm invented', 'how important page', 'how other factors', 'however the patent', 'hyperlink to page', 'hyperlinked set of', 'ibm clever project', 'identifying falsely inflated', 'if there are', 'ignore links from', 'importance in the', 'importance within the', 'important in other', 'important page is', 'important weigh more', 'in 2005 for', 'in essence google', 'in exchange for', 'in google in', 'in order to', 'in other words', 'in practice the', 'in the eyes', 'inbound links as', 'include the hits', 'incoming links page', 'indicator of an', 'individual page value', 'inflated pagerank and', 'inflated pagerank other', 'influence pagerank numerous', 'influence the pagerank', 'internet search engine', 'internet this pagerank', 'interprets link from', 'invented by jon', 'is also called', 'is assigned to', 'is defined recursively', 'is derived from', 'is hyperlink to', 'is known that', 'is link analysis', 'is linked to', 'is no support', 'is roughly based', 'is trademark of', 'it also analyzes', 'it assigns to', 'it incoming links', 'it is known', 'its relative importance', 'its vast link', 'itself if there', 'jon kleinberg used', 'kleinberg used by', 'known that other', 'license rights on', 'like the richter', 'link analysis algorithm', 'link based ranking', 'link from page', 'link structure as', 'link to it', 'linked to by', 'links as well', 'links from documents', 'links it is', 'links page receives', 'links page that', 'links the algorithm', 'links to web', 'logarithmic scale like', 'looks at more', 'make other pages', 'manipulation and extensive', 'manipulation spoofing and', 'many pages with', 'may be applied', 'measuring its relative', 'metric of all', 'million google describes', 'million shares in', 'more heavily and', 'more than the', 'name pagerank is', 'nature of the', 'no links to', 'no specific details', 'no support for', 'not to google', 'now ask com', 'number and pagerank', 'numeric weighting from', 'numerical weight that', 'numerical weighting to', 'numerous academic papers', 'of all pages', 'of an individual', 'of and denoted', 'of documents such', 'of entities with', 'of google and', 'of google the', 'of hyperlinked set', 'of inbound links', 'of measuring its', 'of page is', 'of particular page', 'of search words', 'of support the', 'of the pages', 'of the patent', 'of the web', 'of votes or', 'on logarithmic scale', 'on the internet', 'on the number', 'on the page', 'on the patent', 'on the uniquely', 'on the world', 'or links page', 'order to prevent', 'original paper in', 'other factors influence', 'other factors relevance', 'other link based', 'other pages important', 'other pages on', 'other words pagerank', 'page and actual', 'page and brin', 'page as vote', 'page but google', 'page counts as', 'page for page', 'page google assigns', 'page is defined', 'page is hyperlink', 'page is roughly', 'page receives it', 'page reported by', 'page that casts', 'page that is', 'page there is', 'page to page', 'page value in', 'pagerank and ways', 'pagerank concept has', 'pagerank denotes site', 'pagerank have been', 'pagerank in order', 'pagerank is derived', 'pagerank is link', 'pagerank is trademark', 'pagerank metric of', 'pagerank numerous academic', 'pagerank of and', 'pagerank of page', 'pagerank of particular', 'pagerank of the', 'pagerank other link', 'pagerank pagerank relies', 'pagerank process has', 'pagerank receives high', 'pagerank relies on', 'pagerank results from', 'pages important in', 'pages include the', 'pages on the', 'pages providing the', 'pages that are', 'pages that link', 'pages with high', 'paper in practice', 'papers concerning pagerank', 'particular page is', 'patent 285 999', 'patent from stanford', 'patent is assigned', 'patent the shares', 'patented patent 285', 'pr it is', 'pr the name', 'practice the pagerank', 'prevent manipulation spoofing', 'probability value on', 'process has been', 'project and the', 'proven to be', 'provides no specific', 'providing the links', 'published since page', 'purpose of measuring', 'quantity of inbound', 'quotations and references', 'rank itself if', 'ranking algorithms for', 'received million shares', 'receives high rank', 'receives it also', 'reciprocal quotations and', 'recursively and depends', 'references the numerical', 'relative importance within', 'relevance of search', 'relies on the', 'reported by the', 'research has been', 'results from ballot', 'richter scale the', 'rights on the', 'roughly based upon', 'scale like the', 'scale the pagerank', 'search engine that', 'search words on', 'set google assigns', 'set of documents', 'set the algorithm', 'shares in google', 'shares were sold', 'sheer volume of', 'since page and', 'site importance in', 'sold in 2005', 'spamdexing google provides', 'specific details about', 'spoofing and spamdexing', 'stanford university and', 'stanford university the', 'structure as an', 'such as the', 'support for that', 'support the pagerank', 'teoma and now', 'than the sheer', 'that are themselves', 'that assigns numerical', 'that casts the', 'that is linked', 'that it assigns', 'that link to', 'that other factors', 'that page google', 'the algorithm may', 'the eyes of', 'the google internet', 'the google toolbar', 'the hits algorithm', 'the ibm clever', 'the internet this', 'the links it', 'the links the', 'the name pagerank', 'the number and', 'the numerical weight', 'the other pages', 'the page and', 'the page reported', 'the page that', 'the pagerank concept', 'the pagerank in', 'the pagerank is', 'the pagerank of', 'the pagerank other', 'the pagerank process', 'the pages providing', 'the patent from', 'the patent is', 'the patent the', 'the purpose of', 'the quantity of', 'the richter scale', 'the set google', 'the set the', 'the shares were', 'the sheer volume', 'the trustrank algorithm', 'the uniquely democratic', 'the university received', 'the vote votes', 'the web by', 'the world wide', 'themselves important weigh', 'theoretical probability value', 'there are no', 'there is no', 'this pagerank denotes', 'to any collection', 'to any given', 'to be vulnerable', 'to by many', 'to each element', 'to google google', 'to identifying falsely', 'to ignore links', 'to it incoming', 'to make other', 'to manipulation and', 'to page as', 'to page counts', 'to prevent manipulation', 'to stanford university', 'to the page', 'to web page', 'toolbar also influence', 'trademark of google', 'uniquely democratic nature', 'university and not', 'university received million', 'university the university', 'upon the quantity', 'use of the', 'used by teoma', 'used by the', 'using its vast', 'value in essence', 'value on logarithmic', 'vast link structure', 'visits to the', 'volume of votes', 'vote by page', 'vote of support', 'vote votes cast', 'votes cast by', 'votes or links', 'vulnerable to manipulation', 'ways to ignore', 'web about how', 'web by using', 'web page there', 'web pages include', 'web with the', 'webpage on the', 'weigh more heavily', 'weight that it', 'weighting from 10', 'weighting to each', 'well as the', 'were sold in', 'wide web about', 'wide web with', 'with falsely inflated', 'with high pagerank', 'with reciprocal quotations', 'with the purpose', 'within the set', 'words on the', 'words pagerank results', 'world wide web']\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 2 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 4\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2]\n",
      "[1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0\n",
      " 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 2 0 1\n",
      " 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0\n",
      " 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0\n",
      " 0 1 0 0 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 3\n",
      " 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1\n",
      " 1 0 0 1 0 0 1 1 1 1 0 1]\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "the vector space model also called term vector model is an algebraic model used to represent text documents as well as any objects in general as vectors of identifiers it is used in information retrieval and was first used in the smart information retrieval system  a document is represented as a vector and each dimension corresponds to a separate term if a term appears in the document then its value in the vector is non zero many different ways of calculating these values also known as term weights have been developed one of the best known methods is called tf idf weighting  the definition of term depends on the application but generally terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary which is the number of distinct words occurring in the corpus  the vector space model has several disadvantages firstly long documents are represented badly because they have poor similarity values secondly search keywords must accurately match document terms and substrings of words might result in a false positive match  thirdly documents with similar context but different term vocabulary will not be associated resulting in a false negative match  finally the order in which the terms appear in the document is lost in the vector space representation  \n",
      "['accurately match document', 'algebraic model for', 'algebraic model used', 'also called term', 'also known as', 'an algebraic model', 'and any objects', 'and each dimension', 'and large dimensionality', 'and relevancy rankings', 'and substrings of', 'and was first', 'any objects in', 'appear in the', 'appears in the', 'application but generally', 'application typically terms', 'are chosen to', 'are poorly represented', 'are represented badly', 'are single words', 'as any objects', 'as for example', 'as term weights', 'as vector and', 'as vector each', 'as vectors of', 'as well as', 'associated resulting in', 'badly because they', 'be associated resulting', 'be the terms', 'because they have', 'been developed one', 'below the definition', 'best known methods', 'best known schemes', 'but different term', 'but generally terms', 'calculating these values', 'called term vector', 'called tf idf', 'chosen to be', 'computing these values', 'context but different', 'corpus the vector', 'corresponds to separate', 'definition of term', 'depends on the', 'developed one of', 'different term vocabulary', 'different ways of', 'dimension corresponds to', 'dimensionality of the', 'dimensionality search keywords', 'disadvantages firstly long', 'distinct words occurring', 'document is lost', 'document is represented', 'document its value', 'document terms and', 'document terms word', 'document then its', 'documents and any', 'documents are poorly', 'documents are represented', 'documents as well', 'documents with similar', 'each dimension corresponds', 'example below the', 'example index terms', 'false negative match', 'false positive match', 'filtering information retrieval', 'finally the order', 'first use was', 'first used in', 'firstly long documents', 'following limitations long', 'for example index', 'for representing text', 'general as vectors', 'generally terms are', 'has several disadvantages', 'has the following', 'have been developed', 'have poor similarity', 'identifiers it is', 'identifiers such as', 'idf weighting see', 'idf weighting the', 'if term appears', 'if term occurs', 'if the words', 'in false negative', 'in false positive', 'in general as', 'in information filtering', 'in information retrieval', 'in the corpus', 'in the document', 'in the smart', 'in the vector', 'in the vocabulary', 'in which the', 'index terms it', 'indexing and relevancy', 'information filtering information', 'information retrieval and', 'information retrieval indexing', 'information retrieval system', 'is an algebraic', 'is called tf', 'is lost in', 'is non zero', 'is represented as', 'is tf idf', 'is the number', 'is used in', 'it is used', 'its first use', 'its value in', 'keywords must accurately', 'keywords must precisely', 'keywords or longer', 'known as term', 'known methods is', 'known schemes is', 'large dimensionality search', 'limitations long documents', 'long documents are', 'longer phrases if', 'lost in the', 'many different ways', 'match document terms', 'match finally the', 'match semantic sensitivity', 'match the order', 'match thirdly documents', 'methods is called', 'might result in', 'model also called', 'model for representing', 'model has several', 'model has the', 'model is an', 'model or term', 'model used to', 'must accurately match', 'must precisely match', 'negative match finally', 'negative match the', 'non zero many', 'non zero several', 'not be associated', 'number of distinct', 'number of words', 'objects in general', 'occurring in the', 'occurs in the', 'of calculating these', 'of computing these', 'of distinct words', 'of identifiers it', 'of identifiers such', 'of term depends', 'of the best', 'of the vector', 'of words in', 'of words might', 'on the application', 'one of the', 'or longer phrases', 'or term vector', 'order in which', 'phrases if the', 'poor similarity values', 'poorly represented because', 'positive match semantic', 'positive match thirdly', 'precisely match document', 'product and large', 'rankings its first', 'relevancy rankings its', 'represent text documents', 'represented as vector', 'represented badly because', 'represented because they', 'representing text documents', 'result in false', 'resulting in false', 'retrieval and was', 'retrieval indexing and', 'retrieval system document', 'scalar product and', 'schemes is tf', 'search keywords must', 'secondly search keywords', 'see the example', 'semantic sensitivity documents', 'sensitivity documents with', 'separate term if', 'several different ways', 'several disadvantages firstly', 'similar context but', 'similarity values secondly', 'similarity values small', 'single words keywords', 'small scalar product', 'smart information retrieval', 'space model also', 'space model has', 'space model or', 'substrings might result', 'substrings of words', 'such as for', 'system document is', 'term appears in', 'term depends on', 'term if term', 'term occurs in', 'term vector model', 'term vocabulary will', 'term vocabulary won', 'term weights have', 'terms and substrings', 'terms appear in', 'terms are single', 'terms it is', 'terms the dimensionality', 'terms word substrings', 'text documents and', 'text documents as', 'tf idf weighting', 'the application but', 'the application typically', 'the best known', 'the corpus the', 'the definition of', 'the dimensionality of', 'the document is', 'the document its', 'the document then', 'the example below', 'the following limitations', 'the number of', 'the order in', 'the smart information', 'the terms appear', 'the terms the', 'the vector is', 'the vector space', 'the vocabulary the', 'the vocabulary which', 'the words are', 'then its value', 'these values also', 'they have poor', 'thirdly documents with', 'to be the', 'to represent text', 'to separate term', 'typically terms are', 'use was in', 'used in information', 'used in the', 'used to represent', 'value in the', 'values also known', 'values secondly search', 'values small scalar', 'vector and each', 'vector each dimension', 'vector is non', 'vector is the', 'vector model is', 'vector space model', 'vector space representation', 'vectors of identifiers', 'vocabulary the number', 'vocabulary which is', 'vocabulary will not', 'vocabulary won be', 'was first used', 'was in the', 'ways of calculating', 'ways of computing', 'weighting see the', 'weighting the definition', 'weights have been', 'well as any', 'which is the', 'which the terms', 'will not be', 'with similar context', 'won be associated', 'word substrings might', 'words are chosen', 'words in the', 'words keywords or', 'words might result', 'words occurring in', 'zero many different', 'zero several different']\n",
      "[0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1\n",
      " 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1\n",
      " 0 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 2 1 2 1 1 1 1 1 0 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0\n",
      " 0 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0\n",
      " 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1\n",
      " 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 2 1 1 1 1 2 2 1 0 1 0 1 1 0\n",
      " 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 2 1 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1\n",
      " 1 1 1 1 0 1 0 1]\n",
      "[1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0\n",
      " 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 2 1 2 1 1 0 0 0 1 0 1\n",
      " 1 1 1 1 1 0 2 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1\n",
      " 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 0 1\n",
      " 1 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1\n",
      " 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 2 1 1 1 1 2 3 0 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 2 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0\n",
      " 0 1 1 1 1 1 1 0]\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "bayes theorem was names after rev thomas bayes and is a method used in probability theory this theorem aims to relate the conditional and marginal probabilities of two random events occuring and given various observations is frequently used to compute subsequent probabilities bayes theorem is also often known as bayes law  an example of where bayes theorem may be used is in the following extract  suppose there exists a school with forty percent females and sixty percent males as students the female students can only wear skirts or trousers in equal numbers whereas all the male students can only wear trousers an observer randomly sees a student from a distance and all he can see is that this student is wearing trousers what is the probability this student is female  there is a debate amongst frequentists and bayesians about how bayes theorem plays a major role around the beginnings of statistical mathematics frequentist and bayesian explanations do not agree about the ways in which probabilities should be assigned this is primarily because bayesians assign probabilities in terms of beliefs whereas frequentists assign probabilities to random events according to the frequencies of them occurring \n",
      "['about how bayes', 'about is the', 'about observing are', 'about the ways', 'according to the', 'according to their', 'account any information', 'acts as normalizing', 'after rev thomas', 'agree about the', 'aims to relate', 'all common interpretations', 'all he can', 'all the male', 'also called the', 'also often known', 'amongst frequentists and', 'an example of', 'an observer randomly', 'and acts as', 'and all he', 'and bayesian explanations', 'and bayesian interpretations', 'and bayesians about', 'and degrees of', 'and frequentist probability', 'and given various', 'and is method', 'and marginal probabilities', 'and sixty percent', 'and where has', 'any information about', 'applications frequentists assign', 'are updated by', 'around the beginnings', 'around the foundations', 'articles on bayesian', 'as bayes law', 'as formal theorem', 'as normalizing constant', 'as proportions of', 'as students the', 'assign probabilities in', 'assign probabilities to', 'assigned in applications', 'assigned this is', 'bayes and is', 'bayes law after', 'bayes law an', 'bayes relates the', 'bayes theorem can', 'bayes theorem has', 'bayes theorem in', 'bayes theorem is', 'bayes theorem may', 'bayes theorem often', 'bayes theorem plays', 'bayes theorem relates', 'bayes theorem was', 'bayesian explanations do', 'bayesian interpretations disagree', 'bayesian probability and', 'bayesians about how', 'bayesians assign probabilities', 'bayesians describe probabilities', 'be assigned in', 'be assigned this', 'be observed to', 'be used is', 'be used to', 'because bayesians assign', 'because it is', 'beginnings of statistical', 'beliefs about observing', 'beliefs and degrees', 'beliefs whereas frequentists', 'by having observed', 'called bayes law', 'called the posterior', 'can be used', 'can only wear', 'can see is', 'central role in', 'certain symptoms bayes', 'common interpretations of', 'compute posterior probabilities', 'compute subsequent probabilities', 'compute the probability', 'conditional and marginal', 'conditional probability of', 'constant intuitively bayes', 'conventional name is', 'correct given that', 'debate amongst frequentists', 'debate around the', 'debates in greater', 'degrees of uncertainty', 'depends upon the', 'derived from or', 'describe probabilities in', 'describes the way', 'detail bayes theorem', 'diagnosis is correct', 'disagree about the', 'discuss these debates', 'distance and all', 'do not agree', 'does not take', 'each term in', 'equal numbers whereas', 'events according to', 'events and where', 'events it is', 'events occuring and', 'example as formal', 'example of where', 'example patient may', 'exists school with', 'explanations do not', 'extract suppose there', 'female students can', 'female there is', 'females and sixty', 'following extract suppose', 'for example patient', 'form describes the', 'formal theorem bayes', 'forty percent females', 'foundations of statistics', 'frac each term', 'frequencies of occurrence', 'frequencies of them', 'frequentist and bayesian', 'frequentist probability discuss', 'frequentists and bayesians', 'frequentists assign probabilities', 'frequently used to', 'from distance and', 'from or depends', 'given is the', 'given it is', 'given observations for', 'given that observation', 'given various observations', 'greater detail bayes', 'has conventional name', 'has non vanishing', 'have certain symptoms', 'he can see', 'how bayes theorem', 'however it plays', 'in all common', 'in applications frequentists', 'in bayes theorem', 'in equal numbers', 'in greater detail', 'in probability theory', 'in terms of', 'in the debate', 'in the following', 'in the sense', 'in this form', 'in which one', 'in which probabilities', 'information about is', 'interpretations disagree about', 'interpretations of probability', 'into account any', 'intuitively bayes theorem', 'is also called', 'is also often', 'is correct given', 'is debate amongst', 'is derived from', 'is female there', 'is frequently used', 'is in the', 'is method used', 'is often used', 'is primarily because', 'is prior in', 'is that this', 'is the conditional', 'is the prior', 'is the probability', 'is valid in', 'is wearing trousers', 'it does not', 'it is also', 'it is derived', 'it is often', 'it is prior', 'it plays central', 'known as bayes', 'law after rev', 'law an example', 'major role around', 'male students can', 'males as students', 'marginal probabilities of', 'marginal probability of', 'mathematics frequentist and', 'may be observed', 'may be used', 'method used in', 'name is the', 'names after rev', 'non vanishing probability', 'normalizing constant intuitively', 'not agree about', 'not take into', 'numbers whereas all', 'observation see example', 'observations for example', 'observations is frequently', 'observed to have', 'observer randomly sees', 'observing are updated', 'occuring and given', 'occurrence or to', 'of and acts', 'of beliefs and', 'of beliefs whereas', 'of events and', 'of given is', 'of given it', 'of is the', 'of it is', 'of occurrence or', 'of populations as', 'of probability however', 'of statistical mathematics', 'of statistics frequentist', 'of the whole', 'of them occurring', 'of two random', 'of uncertainty the', 'of where bayes', 'often called bayes', 'often known as', 'often used to', 'on bayesian probability', 'one beliefs about', 'only wear skirts', 'only wear trousers', 'or depends upon', 'or marginal probability', 'or to subsets', 'or trousers in', 'patient may be', 'percent females and', 'percent males as', 'plays central role', 'plays major role', 'populations as proportions', 'posterior probabilities given', 'posterior probability because', 'primarily because bayesians', 'prior in the', 'prior or marginal', 'prior probability or', 'probabilities bayes theorem', 'probabilities given observations', 'probabilities in terms', 'probabilities of events', 'probabilities of two', 'probabilities should be', 'probabilities to random', 'probability and frequentist', 'probability because it', 'probability discuss these', 'probability frac each', 'probability however it', 'probability of and', 'probability of given', 'probability of it', 'probability or marginal', 'probability that proposed', 'probability theory bayes', 'probability theory this', 'probability this student', 'proportions of the', 'proposed diagnosis is', 'random events according', 'random events it', 'random events occuring', 'randomly sees student', 'relate the conditional', 'relates the conditional', 'rev thomas bayes', 'role around the', 'role in the', 'school with forty', 'see example as', 'see is that', 'sees student from', 'sense that it', 'should be assigned', 'sixty percent males', 'skirts or trousers', 'specified value of', 'statistical mathematics frequentist', 'statistics frequentist and', 'student from distance', 'student is female', 'student is wearing', 'students can only', 'students the female', 'subsequent probabilities bayes', 'subsets of populations', 'suppose there exists', 'symptoms bayes theorem', 'take into account', 'term in bayes', 'terms of beliefs', 'that it does', 'that observation see', 'that proposed diagnosis', 'that this student', 'the articles on', 'the beginnings of', 'the conditional and', 'the conditional probability', 'the debate around', 'the female students', 'the following extract', 'the foundations of', 'the frequencies of', 'the male students', 'the posterior probability', 'the prior or', 'the prior probability', 'the probability that', 'the probability this', 'the sense that', 'the specified value', 'the way in', 'the ways in', 'the whole while', 'their frequencies of', 'theorem aims to', 'theorem bayes theorem', 'theorem can be', 'theorem has conventional', 'theorem in this', 'theorem is also', 'theorem is valid', 'theorem may be', 'theorem often called', 'theorem plays major', 'theorem relates the', 'theorem was names', 'theory bayes theorem', 'theory this theorem', 'there exists school', 'there is debate', 'these debates in', 'this form describes', 'this is primarily', 'this student is', 'this theorem aims', 'thomas bayes and', 'thomas bayes relates', 'to compute posterior', 'to compute subsequent', 'to compute the', 'to have certain', 'to random events', 'to relate the', 'to subsets of', 'to the frequencies', 'to their frequencies', 'trousers an observer', 'trousers in equal', 'trousers what is', 'two random events', 'uncertainty the articles', 'updated by having', 'upon the specified', 'used in probability', 'used is in', 'used to compute', 'valid in all', 'value of is', 'vanishing probability frac', 'various observations is', 'was names after', 'way in which', 'ways in which', 'wear skirts or', 'wear trousers an', 'wearing trousers what', 'what is the', 'where bayes theorem', 'where has non', 'whereas all the', 'whereas frequentists assign', 'which one beliefs', 'which probabilities should', 'while bayesians describe', 'whole while bayesians', 'with forty percent']\n",
      "[0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 2 0 1 1 1 1 0 1 1\n",
      " 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1\n",
      " 1 0 1 1 1 1 0 0 1 1 1 1 0 1 2 2 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1\n",
      " 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 2 2 0\n",
      " 1 0 1 1 1 1 1 1 0 1 0 0 0 0 2 2 0 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 2 1 0 1 0 0 1 0 1 1 1 0 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 0 0 1 1 1 1 0 0 0 2 1 0 1 0 1 0 0\n",
      " 1 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 2 2 1 0 0 1 0 0 1 1 1 1\n",
      " 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1\n",
      " 0 1 0 0 0 1 1 1 1 0 0 2 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 0]\n",
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0\n",
      " 0 1 0 0 0 0 2 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1\n",
      " 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0\n",
      " 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 1\n",
      " 0 1 1 1 0 1 0 1 1 1 2 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 2 1 1 0 0 1 0 0 1 1 0\n",
      " 1 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1]\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "dynamic programming is an algorithm design technique used for optimisation problems such as minimising or maximising like divide and conquer dynamic programming solves problems by combining solutions to sub problems however unlike divide and conquer sub problems are not always independent as sub problems may share sub sub problems but solution to one sub problem may not affect the solutions to other sub problems of the same problem  there are four steps in dynamic programming  1 characterise structure of an optimal solution  2 define value of optimal solution recursively  3 compute optimal solution values either top down with caching or bottom up in a table  4 construct an optimal solution from computed values  an example of the type of problem for which dynamic programming may be used is given two sequences x x1 xm and y y1 yn find a common subsequence whose length is maximum  dynamic programming reduces computation by solving sub problems in a bottom up fashion and by storing solution to a sub problem the first time it is solved also looking up the solution when a sub problem is encountered again helps reduce computation however the key in dynamic programming is to determine the structure of optimal solutions  \n",
      "['1940s by richard', '1953 he had', 'acceptable plan of', 'action an algorithm', 'action that is', 'adjacent vertices and', 'affect the solutions', 'after another by', 'again helps reduce', 'algorithm design technique', 'algorithm optimal substructure', 'all adjacent vertices', 'all and instead', 'already computed solution', 'already solved in', 'already solved then', 'also fits if', 'also looking up', 'although this term', 'always independent as', 'an acceptable plan', 'an algorithm design', 'an algorithm optimal', 'an example of', 'an exhibition is', 'an optimal solution', 'an optimization problem', 'analysis and engineering', 'and by storing', 'and computer science', 'and conquer dynamic', 'and conquer sub', 'and engineering topic', 'and f4 are', 'and f4 f2', 'and instead comes', 'and optimal substructure', 'and reuse our', 'and so on', 'and then using', 'and y1 yn', 'another by 1953', 'anymore we can', 'applies whenever overlapping', 'approach is called', 'approach may waste', 'approach to computing', 'are four steps', 'are needed to', 'are not always', 'are present naive', 'are sure we', 'are themselves solved', 'are used to', 'as minimising or', 'as shown in', 'as sub problems', 'as systems analysis', 'at all and', 'at an exhibition', 'avoid this we', 'away to save', 'be found by', 'be used is', 'be used to', 'because both f3', 'bellman contribution is', 'bellman equation central', 'bellman to describe', 'below the method', 'best decisions one', 'best overall path', 'both f3 and', 'bottom up fashion', 'bottom up in', 'break the problem', 'but dag indicates', 'but solution to', 'by 1953 he', 'by combining solutions', 'by dividing them', 'by first computing', 'by richard bellman', 'by solving sub', 'by storing solution', 'by the ieee', 'caching or bottom', 'called memoization not', 'called program programming', 'can be found', 'can be used', 'can even compute', 'can retrieve and', 'can solve problem', 'can throw it', 'case that is', 'cases we can', 'central result of', 'characterise structure of', 'combining solutions to', 'comes from the', 'common subsequence whose', 'computation by solving', 'computation however the', 'compute f5 naive', 'compute optimal solution', 'compute the solutions', 'computed solution this', 'computed values an', 'computer programming at', 'computer science dynamic', 'computing each number', 'computing f2 because', 'computing f2 twice', 'computing f5 may', 'computing the shortest', 'connection to computer', 'conquer dynamic programming', 'conquer sub problems', 'constant time figure', 'construct an optimal', 'contribution is remembered', 'dag indicates overlapping', 'decisions one after', 'define value of', 'describe the process', 'described below the', 'design technique used', 'determine the structure', 'different larger problems', 'divide and conquer', 'dividing them into', 'down with caching', 'dynamic programming characterise', 'dynamic programming has', 'dynamic programming is', 'dynamic programming may', 'dynamic programming reduces', 'dynamic programming solves', 'dynamic programming which', 'each number involves', 'either top down', 'encountered again helps', 'end up computing', 'engineering topic that', 'equation central result', 'even compute the', 'events at an', 'example in the', 'example of the', 'example the shortest', 'exhibit the properties', 'exhibition is sometimes', 'f1 f2 and', 'f2 and f4', 'f2 because both', 'f2 f3 computing', 'f2 twice or', 'f3 and f4', 'f3 computing each', 'f3 f1 f2', 'f4 are needed', 'f4 f2 f3', 'f5 may end', 'f5 naive approach', 'fashion and by', 'fibonacci sequence f3', 'fibonacci sequence that', 'field was founded', 'figure in general', 'figure the subproblem', 'finalized schedule of', 'find common subsequence', 'find the best', 'find the optimal', 'finding an acceptable', 'first computing the', 'first time it', 'fits if we', 'for action that', 'for example in', 'for example the', 'for instance finalized', 'for optimisation problems', 'for optimization thus', 'for the fibonacci', 'for the original', 'for which dynamic', 'form the word', 'found by first', 'founded as systems', 'four steps in', 'from all adjacent', 'from computed values', 'from the term', 'from vertex in', 'general we can', 'given two sequences', 'goal from all', 'goal from vertex', 'graph can be', 'graph for the', 'had refined this', 'has already solved', 'has no particular', 'has overlapping subproblems', 'have already solved', 'he had refined', 'helps reduce computation', 'however the key', 'however unlike divide', 'ieee bellman contribution', 'if we are', 'if we need', 'in bottom up', 'in constant time', 'in dynamic programming', 'in figure in', 'in general we', 'in graph can', 'in mathematics and', 'in order to', 'in recursive form', 'in some cases', 'in table construct', 'in the 1940s', 'in the fibonacci', 'in the name', 'in this sense', 'independent as sub', 'indicates overlapping subproblems', 'instance finalized schedule', 'instead comes from', 'instead save the', 'into smaller subproblems', 'into sub subproblems', 'involves computing f2', 'is an algorithm', 'is called memoization', 'is encountered again', 'is given two', 'is maximum dynamic', 'is method of', 'is not tree', 'is produced for', 'is recognized by', 'is remembered in', 'is solvable in', 'is solved also', 'is sometimes called', 'is the optimal', 'is to determine', 'is to say', 'it away to', 'it has already', 'it is not', 'it is solved', 'key in dynamic', 'know that we', 'larger problems for', 'later we can', 'length is maximum', 'less time than', 'like divide and', 'll need in', 'looking up the', 'many different larger', 'mathematical programming synonym', 'mathematics and computer', 'maximising like divide', 'maximum dynamic programming', 'may be used', 'may end up', 'may not affect', 'may share sub', 'may waste time', 'meaning the field', 'means finding an', 'means that optimal', 'memoization not memorization', 'memorization although this', 'method of solving', 'method takes much', 'methods the term', 'minimising or maximising', 'modern meaning the', 'more this applies', 'much less time', 'naive approach may', 'naive approach to', 'naive methods the', 'name of the', 'need in advance', 'need particular solution', 'need to solve', 'needed to compute', 'needs to find', 'no particular connection', 'not affect the', 'not always independent', 'not memorization although', 'not tree but', 'number involves computing', 'of action an', 'of an optimal', 'of dynamic programming', 'of events at', 'of optimal solution', 'of optimal solutions', 'of overlapping subproblems', 'of problem for', 'of solving problems', 'of subproblems can', 'of the bellman', 'of the overall', 'of the same', 'of the type', 'on until we', 'one after another', 'one needs to', 'one sub problem', 'optimal plan for', 'optimal solution define', 'optimal solution for', 'optimal solution from', 'optimal solution recursively', 'optimal solution values', 'optimal solutions of', 'optimal solutions to', 'optimal substructure described', 'optimal substructure means', 'optimal substructure using', 'optimally using this', 'optimisation problems such', 'optimization problem in', 'optimization thus the', 'or bottom up', 'or maximising like', 'or more this', 'order to avoid', 'original problem the', 'originally used in', 'other sub problems', 'our already computed', 'overall path as', 'overall problem for', 'overlapping subproblems and', 'overlapping subproblems are', 'overlapping subproblems is', 'overlapping subproblems to', 'particular connection to', 'particular solution anymore', 'path as shown', 'path to goal', 'path to the', 'pick the best', 'plan for action', 'plan of action', 'present naive approach', 'problem for example', 'problem for which', 'problem has overlapping', 'problem in recursive', 'problem into smaller', 'problem is encountered', 'problem later we', 'problem may not', 'problem the first', 'problem the subproblems', 'problem there are', 'problem with optimal', 'problems are not', 'problems but solution', 'problems by combining', 'problems for example', 'problems however unlike', 'problems in bottom', 'problems may share', 'problems of the', 'problems optimally using', 'problems such as', 'problems that exhibit', 'problems we have', 'problems where one', 'process break the', 'process of solving', 'process recursively use', 'produced for instance', 'program is the', 'program programming in', 'programming at all', 'programming characterise structure', 'programming has no', 'programming in dynamic', 'programming in this', 'programming is an', 'programming is method', 'programming is to', 'programming may be', 'programming reduces computation', 'programming solves problems', 'programming synonym for', 'programming which restates', 'properties of overlapping', 'reach some simple', 'recognized by the', 'recomputing optimal solutions', 'recursive form the', 'recursively compute optimal', 'recursively use these', 'reduce computation however', 'reduces computation by', 'refined this to', 'remembered in the', 'restates an optimization', 'result of dynamic', 'retrieve and reuse', 'reuse our already', 'richard bellman to', 'same problem later', 'same problem there', 'same subproblems are', 'save space in', 'save the solutions', 'say that problem', 'say that the', 'schedule of events', 'science dynamic programming', 'sense means finding', 'sequence f3 f1', 'sequence that it', 'sequences x1 xm', 'share sub sub', 'shortest path to', 'shown in figure', 'simple case that', 'smaller subproblems solve', 'so on until', 'solution anymore we', 'solution define value', 'solution for the', 'solution from computed', 'solution recursively compute', 'solution this approach', 'solution to one', 'solution to sub', 'solution values either', 'solution when sub', 'solutions of subproblems', 'solutions of the', 'solutions to construct', 'solutions to other', 'solutions to problems', 'solutions to sub', 'solutions to subproblems', 'solvable in constant', 'solve many different', 'solve problem with', 'solve the same', 'solve these problems', 'solved also looking', 'solved by dividing', 'solved in order', 'solved then if', 'solves problems by', 'solving problems that', 'solving problems where', 'solving sub problems', 'some cases we', 'some simple case', 'sometimes called program', 'space in some', 'step process break', 'step process recursively', 'steps in dynamic', 'storing solution to', 'structure of an', 'structure of optimal', 'sub problem is', 'sub problem may', 'sub problem the', 'sub problems are', 'sub problems but', 'sub problems however', 'sub problems in', 'sub problems may', 'sub problems of', 'sub sub problems', 'sub subproblems and', 'subproblem graph for', 'subproblems and optimal', 'subproblems and so', 'subproblems are present', 'subproblems are themselves', 'subproblems are used', 'subproblems can be', 'subproblems is to', 'subproblems it has', 'subproblems solve these', 'subproblems to say', 'subproblems we know', 'subsequence whose length', 'substructure described below', 'substructure means that', 'substructure using three', 'such as minimising', 'sure we won', 'synonym for optimization', 'systems analysis and', 'table construct an', 'takes much less', 'technique used for', 'term also fits', 'term mathematical programming', 'term was originally', 'than naive methods', 'that exhibit the', 'that is produced', 'that is recognized', 'that is solvable', 'that it is', 'that optimal solutions', 'that problem has', 'that the same', 'that we ll', 'the 1940s by', 'the bellman equation', 'the best decisions', 'the best overall', 'the fibonacci sequence', 'the field was', 'the first time', 'the goal from', 'the ieee bellman', 'the key in', 'the method takes', 'the modern meaning', 'the name of', 'the optimal plan', 'the optimal solutions', 'the original problem', 'the overall problem', 'the problem into', 'the process of', 'the program is', 'the properties of', 'the same problem', 'the same subproblems', 'the shortest path', 'the solution when', 'the solutions to', 'the structure of', 'the subproblem graph', 'the subproblems are', 'the term mathematical', 'the term was', 'the type of', 'the word programming', 'them into sub', 'themselves solved by', 'then if we', 'then using this', 'there are four', 'these optimal solutions', 'these problems optimally', 'this applies whenever', 'this approach is', 'this sense means', 'this term also', 'this three step', 'this to pick', 'this to the', 'this we instead', 'three step process', 'throw it away', 'thus the program', 'time figure the', 'time it is', 'time recomputing optimal', 'time than naive', 'to avoid this', 'to compute f5', 'to computer programming', 'to computing f5', 'to construct an', 'to describe the', 'to determine the', 'to find the', 'to goal from', 'to one sub', 'to other sub', 'to pick the', 'to problems we', 'to save space', 'to say that', 'to solve many', 'to solve the', 'to sub problem', 'to sub problems', 'to subproblems it', 'to subproblems we', 'to the goal', 'to the modern', 'top down with', 'topic that is', 'tree but dag', 'twice or more', 'two sequences x1', 'type of problem', 'unlike divide and', 'until we reach', 'up computing f2', 'up fashion and', 'up in table', 'up the solution', 'use these optimal', 'used for optimisation', 'used in the', 'used is given', 'used to find', 'used to solve', 'using this three', 'using this to', 'using three step', 'value of optimal', 'values an example', 'values either top', 'vertex in graph', 'vertices and then', 'was founded as', 'was originally used', 'waste time recomputing', 'we are sure', 'we can even', 'we can retrieve', 'we can solve', 'we can throw', 'we have already', 'we instead save', 'we know that', 'we ll need', 'we need to', 'we reach some', 'we won need', 'when sub problem', 'whenever overlapping subproblems', 'where one needs', 'which dynamic programming', 'which restates an', 'whose length is', 'with caching or', 'with optimal substructure', 'won need particular', 'word programming in', 'x1 xm and', 'xm and y1', 'y1 yn find', 'yn find common']\n",
      "[1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1\n",
      " 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 2 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 2 2 1 1 1 1\n",
      " 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1\n",
      " 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 2 1 1 1 1 1 0 1 0 0 1\n",
      " 0 0 0 0 1 1 1 0 1 0 2 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 0 2 0 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 2 1 1 1 0 1 1 1 1 1 1 1 1 0 2 1 0 0 1\n",
      " 1 1 2 1 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 2 0 0 1 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 2 0 1 1 0 2 1 1 1 0 0 1 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 2 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0\n",
      " 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 1]\n",
      "Original category values: \n",
      " [0, 3, 2, 1, 0]\n",
      "\n",
      "3-gram containment values: \n",
      " [0.00975609756097561, 0.9479166666666666, 0.6037735849056604, 0.13186813186813187, 0.010810810810810811]\n"
     ]
    }
   ],
   "source": [
    "# select a value for n\n",
    "n = 3\n",
    "\n",
    "# indices for first few files\n",
    "test_indices = range(5)\n",
    "\n",
    "# iterate through files and calculate containment\n",
    "category_vals = []\n",
    "containment_vals = []\n",
    "for i in test_indices:\n",
    "    # get level of plagiarism for a given file index\n",
    "    category_vals.append(complete_df.loc[i, 'Category'])\n",
    "    # calculate containment for given file and n\n",
    "    filename = complete_df.loc[i, 'File']\n",
    "    c = calculate_containment(complete_df, n, filename)\n",
    "    containment_vals.append(c)\n",
    "\n",
    "# print out result, does it make sense?\n",
    "print('Original category values: \\n', category_vals)\n",
    "print()\n",
    "print(str(n)+'-gram containment values: \\n', containment_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "dynamic programming is an algorithm design technique used for optimisation problems such as minimising or maximising like divide and conquer dynamic programming solves problems by combining solutions to sub problems however unlike divide and conquer sub problems are not always independent as sub problems may share sub sub problems but solution to one sub problem may not affect the solutions to other sub problems of the same problem  there are four steps in dynamic programming  1 characterise structure of an optimal solution  2 define value of optimal solution recursively  3 compute optimal solution values either top down with caching or bottom up in a table  4 construct an optimal solution from computed values  an example of the type of problem for which dynamic programming may be used is given two sequences x x1 xm and y y1 yn find a common subsequence whose length is maximum  dynamic programming reduces computation by solving sub problems in a bottom up fashion and by storing solution to a sub problem the first time it is solved also looking up the solution when a sub problem is encountered again helps reduce computation however the key in dynamic programming is to determine the structure of optimal solutions  \n",
      "['1940s', '1953', 'acceptable', 'action', 'adjacent', 'advance', 'affect', 'after', 'again', 'algorithm', 'all', 'already', 'also', 'although', 'always', 'an', 'analysis', 'and', 'another', 'anymore', 'applies', 'approach', 'are', 'as', 'at', 'avoid', 'away', 'be', 'because', 'bellman', 'below', 'best', 'both', 'bottom', 'break', 'but', 'by', 'caching', 'called', 'can', 'case', 'cases', 'central', 'characterise', 'combining', 'comes', 'common', 'computation', 'compute', 'computed', 'computer', 'computing', 'connection', 'conquer', 'constant', 'construct', 'contribution', 'dag', 'decisions', 'define', 'describe', 'described', 'design', 'determine', 'different', 'divide', 'dividing', 'down', 'dynamic', 'each', 'either', 'encountered', 'end', 'engineering', 'equation', 'even', 'events', 'example', 'exhibit', 'exhibition', 'f1', 'f2', 'f3', 'f4', 'f5', 'fashion', 'fibonacci', 'field', 'figure', 'finalized', 'find', 'finding', 'first', 'fits', 'for', 'form', 'found', 'founded', 'four', 'from', 'general', 'given', 'goal', 'graph', 'had', 'has', 'have', 'he', 'helps', 'however', 'ieee', 'if', 'in', 'independent', 'indicates', 'instance', 'instead', 'into', 'involves', 'is', 'it', 'key', 'know', 'larger', 'later', 'length', 'less', 'like', 'll', 'looking', 'many', 'mathematical', 'mathematics', 'maximising', 'maximum', 'may', 'meaning', 'means', 'memoization', 'memorization', 'method', 'methods', 'minimising', 'modern', 'more', 'much', 'naive', 'name', 'need', 'needed', 'needs', 'no', 'not', 'number', 'of', 'on', 'one', 'optimal', 'optimally', 'optimisation', 'optimization', 'or', 'order', 'original', 'originally', 'other', 'our', 'overall', 'overlapping', 'particular', 'path', 'pick', 'plan', 'present', 'problem', 'problems', 'process', 'produced', 'program', 'programming', 'properties', 'reach', 'recognized', 'recomputing', 'recursive', 'recursively', 'reduce', 'reduces', 'refined', 'remembered', 'restates', 'result', 'retrieve', 'reuse', 'richard', 'same', 'save', 'say', 'schedule', 'science', 'sense', 'sequence', 'sequences', 'share', 'shortest', 'shown', 'simple', 'smaller', 'so', 'solution', 'solutions', 'solvable', 'solve', 'solved', 'solves', 'solving', 'some', 'sometimes', 'space', 'step', 'steps', 'storing', 'structure', 'sub', 'subproblem', 'subproblems', 'subsequence', 'substructure', 'such', 'sure', 'synonym', 'systems', 'table', 'takes', 'technique', 'term', 'than', 'that', 'the', 'them', 'themselves', 'then', 'there', 'these', 'this', 'three', 'throw', 'thus', 'time', 'to', 'top', 'topic', 'tree', 'twice', 'two', 'type', 'unlike', 'until', 'up', 'use', 'used', 'using', 'value', 'values', 'vertex', 'vertices', 'was', 'waste', 'we', 'when', 'whenever', 'where', 'which', 'whose', 'with', 'won', 'word', 'x1', 'xm', 'y1', 'yn']\n",
      "[ 1  1  1  2  1  1  0  1  0  1  2  3  1  1  0  5  1  9  1  1  1  3  5  2\n",
      "  2  1  1  2  1  3  1  2  1  0  1  1  5  0  2  6  1  1  1  0  0  1  0  0\n",
      "  2  1  2  5  1  0  1  1  1  1  1  0  1  1  0  0  1  0  1  0  3  1  0  0\n",
      "  1  1  1  1  1  2  1  1  1  4  3  2  2  0  2  1  2  1  2  1  1  1  7  1\n",
      "  1  1  0  3  1  0  2  2  1  3  1  1  0  0  1  2 14  0  1  1  2  2  1 10\n",
      "  3  0  1  1  1  0  1  0  1  0  1  1  1  0  0  2  1  2  1  1  2  1  0  1\n",
      "  1  1  3  1  3  1  1  1  2  1  9  1  2  9  1  0  2  1  1  1  1  0  1  2\n",
      "  4  2  3  1  2  1  7  5  3  1  2  7  1  1  1  1  1  1  0  0  1  1  1  1\n",
      "  1  1  1  2  2  2  1  1  1  2  0  0  2  1  1  1  1  3  6  1  4  3  0  2\n",
      "  2  1  1  2  0  0  0  1  1 11  0  3  0  1  1  1  0  1  0  3  1  9 31  1\n",
      "  1  2  0  2  8  2  1  1  3 20  0  1  1  1  0  0  0  1  1  1  3  3  0  0\n",
      "  1  1  2  1 12  0  1  1  1  0  1  1  1  0  0  0  0]\n",
      "[ 0  0  0  0  0  0  1  0  1  1  0  0  1  0  1  4  0  4  0  0  0  0  2  2\n",
      "  0  0  0  1  0  0  0  0  0  2  0  1  3  1  0  0  0  0  0  1  1  0  1  2\n",
      "  1  1  0  0  0  2  0  1  0  0  0  1  0  0  1  1  0  2  0  1  6  0  1  1\n",
      "  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  1  0  1  0  2  0\n",
      "  0  0  1  1  0  1  0  0  0  0  0  0  1  2  0  0  4  1  0  0  0  0  0  6\n",
      "  1  1  0  0  0  1  0  1  0  1  0  0  0  1  1  3  0  0  0  0  0  0  1  0\n",
      "  0  0  0  0  0  0  0  0  2  0  6  0  1  5  0  1  0  2  0  0  0  1  0  0\n",
      "  0  0  0  0  0  0  5  8  0  0  0  6  0  0  0  0  0  1  1  1  0  0  0  0\n",
      "  0  0  0  1  0  0  0  0  0  0  1  1  0  0  0  0  0  7  3  0  0  1  1  1\n",
      "  0  0  0  0  1  1  2 10  0  0  1  0  1  0  0  0  1  0  1  0  0  0  7  0\n",
      "  0  0  1  0  0  0  0  0  1  5  1  0  0  0  1  1  1  0  3  0  2  0  1  2\n",
      "  0  0  0  0  0  1  0  0  1  1  1  0  0  1  1  1  1]\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "inheritance is a basic concept of object oriented programming where the basic idea is to create new classes that add extra detail to existing classes this is done by allowing the new classes to reuse the methods and variables of the existing classes and new methods and classes are added to specialise the new class inheritance models the is kind of relationship between entities or objects  for example postgraduates and undergraduates are both kinds of student this kind of relationship can be visualised as a tree structure where student would be the more general root node and both postgraduate and undergraduate would be more specialised extensions of the student node or the child nodes  in this relationship student would be known as the superclass or parent class whereas  postgraduate would be known as the subclass or child class because the postgraduate class extends the student class  inheritance can occur on several layers where if visualised would display a larger tree structure for example we could further extend the postgraduate node by adding two extra extended classes to it called  msc student and phd student as both these types of student are kinds of postgraduate student this would mean that both the msc student and phd student classes would inherit methods and variables from both the postgraduate and student classes  \n",
      "['1967', 'about', 'abstraction', 'accomplished', 'add', 'added', 'adding', 'advantage', 'all', 'allowing', 'already', 'also', 'an', 'ancestor', 'and', 'another', 'apple', 'apples', 'applied', 'are', 'as', 'attributes', 'base', 'basic', 'be', 'because', 'been', 'behavior', 'being', 'belongs', 'between', 'both', 'by', 'called', 'can', 'categorization', 'child', 'class', 'classes', 'code', 'cognitive', 'common', 'complex', 'complexity', 'computer', 'concept', 'consider', 'container', 'control', 'controlled', 'conversely', 'could', 'create', 'crucial', 'defined', 'derived', 'describes', 'design', 'detail', 'display', 'done', 'dual', 'each', 'economy', 'either', 'entities', 'entity', 'established', 'etc', 'example', 'existing', 'exposed', 'extend', 'extended', 'extends', 'extensions', 'extra', 'fleshy', 'for', 'form', 'from', 'fruit', 'further', 'general', 'generalization', 'given', 'group', 'has', 'have', 'help', 'hierarchy', 'human', 'idea', 'if', 'in', 'information', 'inherit', 'inheritance', 'instance', 'instances', 'intended', 'interfaces', 'invented', 'is', 'it', 'its', 'kind', 'kinds', 'known', 'languages', 'larger', 'layers', 'lead', 'learning', 'less', 'little', 'lot', 'mango', 'many', 'mature', 'may', 'mean', 'means', 'mechanism', 'methods', 'models', 'modification', 'modules', 'more', 'msc', 'naturally', 'needs', 'new', 'no', 'node', 'nodes', 'not', 'number', 'object', 'objects', 'occur', 'of', 'on', 'one', 'only', 'or', 'orange', 'oriented', 'others', 'over', 'overriding', 'parent', 'particularities', 'phd', 'pieces', 'plant', 'polymorphism', 'postgraduate', 'postgraduates', 'powerful', 'pre', 'problem', 'processing', 'program', 'programming', 'properties', 'provides', 'reducing', 'referred', 'relation', 'relationship', 'relationships', 'replacing', 'represent', 'representation', 'reuse', 'root', 'seed', 'several', 'share', 'shared', 'similar', 'simula', 'since', 'sometimes', 'specialise', 'specialised', 'specific', 'stored', 'structure', 'student', 'subclass', 'such', 'sufficiently', 'superclass', 'support', 'take', 'that', 'the', 'therefore', 'these', 'this', 'those', 'to', 'tree', 'two', 'types', 'typically', 'undergraduate', 'undergraduates', 'used', 'using', 'variables', 'view', 'visualised', 'was', 'way', 'we', 'what', 'where', 'whereas', 'which', 'wider', 'with', 'within', 'would', 'yo']\n",
      "[ 1  2  1  1  0  0  1  1  2  0  1  1  4  3  3  1  3  2  1  3  3  1  1  0\n",
      "  3  1  1  1  2  1  1  0  7  3  3  2  0  0  8  4  1  1  1  1  1  1  1  1\n",
      "  1  1  1  0  0  1  1  1  1  1  0  0  0  1  1  1  1  1  1  1  1  0  2  2\n",
      "  0  0  0  0  0  1  4  1  0  5  0  0  3  1  1  1  1  1  1  1  0  0  3  2\n",
      "  2  9  1  1  1  1  1 12  1  1  0  0  2  1  0  0  1  1  1  1  1  1  2  1\n",
      "  2  0  1  1  2  0  1  1  1  0  1  1  3  1  0  0  1  1  1  2  0 12  0  2\n",
      "  1  6  2  1  1  1  1  0  1  0  1  1  1  0  0  1  1  1  1  1  1  1  1  1\n",
      "  1  1  0  1  1  1  1  1  0  1  0  1  1  1  1  1  1  0  0  2  1  0  0  0\n",
      "  1  2  0  1  1  3 10  1  0  0  1 10  0  0  0  1  0  0  1  1  0  1  0  1\n",
      "  1  0  1  0  0  3  1  2  1  0  2]\n",
      "[ 0  0  0  0  1  1  1  0  0  1  0  0  0  0 10  0  0  0  0  3  4  0  0  2\n",
      "  5  1  0  0  0  0  1  5  2  1  2  0  2  5  8  0  0  0  0  0  0  1  0  0\n",
      "  0  0  0  1  1  0  0  0  0  0  1  1  1  0  0  0  0  1  0  0  0  2  2  0\n",
      "  1  1  1  1  2  0  2  0  1  0  1  1  0  0  0  0  0  0  0  0  1  1  1  0\n",
      "  1  3  0  0  0  0  0  4  1  0  2  2  2  0  1  1  0  0  0  0  0  0  0  0\n",
      "  0  1  0  0  3  1  0  0  2  2  0  0  4  0  3  1  0  0  1  1  1  8  1  0\n",
      "  0  4  0  1  0  0  0  1  0  2  0  0  0  6  1  0  0  0  0  0  1  0  0  0\n",
      "  0  0  3  0  0  0  0  1  1  0  1  0  0  0  0  0  0  1  1  0  0  2 12  1\n",
      "  0  0  1  0  0  2 16  0  1  4  0  5  2  1  1  0  1  1  0  0  2  0  2  0\n",
      "  0  1  0  3  1  0  0  0  0  7  0]\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "inheritance is a basic concept of object oriented programming where the basic idea is to create new classes that add extra detail to existing classes this is done by allowing the new classes to reuse the methods and variables of the existing classes and new methods and classes are added to specialise the new class inheritance models the is kind of relationship between entities or objects  for example postgraduates and undergraduates are both kinds of student this kind of relationship can be visualised as a tree structure where student would be the more general root node and both postgraduate and undergraduate would be more specialised extensions of the student node or the child nodes  in this relationship student would be known as the superclass or parent class whereas  postgraduate would be known as the subclass or child class because the postgraduate class extends the student class  inheritance can occur on several layers where if visualised would display a larger tree structure for example we could further extend the postgraduate node by adding two extra extended classes to it called  msc student and phd student as both these types of student are kinds of postgraduate student this would mean that both the msc student and phd student classes would inherit methods and variables from both the postgraduate and student classes  \n",
      "['1967 for simula', 'about each specific', 'about specific entities', 'abstraction of apple', 'accomplished either by', 'add extra detail', 'added to specialise', 'adding new methods', 'adding two extra', 'advantage of inheritance', 'all fruit such', 'all the properties', 'allowing the new', 'already been defined', 'also sometimes called', 'an abstraction of', 'an advantage of', 'an ancestor complex', 'an apple is', 'ancestor classes it', 'ancestor complex inheritance', 'ancestor or by', 'and behavior of', 'and both postgraduate', 'and classes are', 'and cognitive economy', 'and many others', 'and new methods', 'and phd student', 'and student classes', 'and undergraduate would', 'and undergraduates are', 'and variables from', 'and variables of', 'another view dual', 'apple is fruit', 'apple orange etc', 'apple orange mango', 'apples are fruit', 'apples may naturally', 'applied to wider', 'are added to', 'are both kinds', 'are called objects', 'are fruit an', 'are kinds of', 'are referred to', 'as base classes', 'as being fleshy', 'as both these', 'as derived classes', 'as the subclass', 'as the superclass', 'as tree structure', 'attributes and behavior', 'base classes or', 'basic concept of', 'basic idea is', 'be an abstraction', 'be established and', 'be known as', 'be more specialised', 'be stored about', 'be the more', 'be visualised as', 'because the is', 'because the postgraduate', 'been defined the', 'behavior of the', 'being controlled by', 'being fleshy container', 'belongs relation can', 'between classes of', 'between entities or', 'both kinds of', 'both postgraduate and', 'both the msc', 'both the postgraduate', 'both these types', 'by adding new', 'by adding two', 'by allowing the', 'by an ancestor', 'by ancestor or', 'by categorization in', 'by means of', 'by overriding replacing', 'by shared control', 'called generalization because', 'called msc student', 'called objects using', 'called polymorphism which', 'can be established', 'can be visualised', 'can consider fruit', 'can occur on', 'can share lot', 'categorization in computer', 'categorization is powerful', 'child class because', 'child nodes in', 'class because the', 'class extends the', 'class inheritance can', 'class inheritance models', 'class whereas postgraduate', 'classes and new', 'classes are added', 'classes instances of', 'classes it is', 'classes known as', 'classes of objects', 'classes or ancestor', 'classes take over', 'classes that add', 'classes that have', 'classes this is', 'classes to it', 'classes to reuse', 'classes which are', 'classes would inherit', 'code being controlled', 'code inheritance is', 'code reducing the', 'code with little', 'cognitive economy less', 'common to all', 'complex inheritance or', 'complexity of the', 'computer languages categorization', 'concept of object', 'concept was invented', 'consider fruit to', 'container for the', 'control code inheritance', 'controlled by shared', 'conversely since apples', 'could further extend', 'create new classes', 'crucial to human', 'defined the inheritance', 'derived classes take', 'describes many pieces', 'design that is', 'detail to existing', 'display larger tree', 'done by allowing', 'dual called polymorphism', 'each specific entity', 'economy less information', 'either by overriding', 'entities is applied', 'entities or objects', 'entity only its', 'established and cognitive', 'etc conversely since', 'example postgraduates and', 'example we could', 'existing classes and', 'existing classes this', 'existing classes which', 'existing code with', 'exposed by an', 'exposed by ancestor', 'extend the postgraduate', 'extended classes to', 'extends the student', 'extensions of the', 'extra detail to', 'extra extended classes', 'fleshy container for', 'for example postgraduates', 'for example we', 'for instance fruit', 'for representation by', 'for simula the', 'for the seed', 'form new classes', 'from both the', 'fruit an apple', 'fruit apples may', 'fruit is generalization', 'fruit such as', 'fruit to be', 'further extend the', 'general root node', 'generalization because the', 'generalization of apple', 'generalization what is', 'given belongs relation', 'group given belongs', 'has another view', 'have already been', 'help reuse existing', 'hierarchy between classes', 'human learning by', 'idea is to', 'if visualised would', 'in 1967 for', 'in computer languages', 'in object oriented', 'in this relationship', 'information needs to', 'information processing crucial', 'inherit all the', 'inherit attributes and', 'inherit methods and', 'inheritance can occur', 'inheritance concept was', 'inheritance is also', 'inheritance is basic', 'inheritance is that', 'inheritance is typically', 'inheritance is way', 'inheritance models the', 'inheritance or inheritance', 'inheritance provides the', 'inheritance therefore has', 'inheritance used within', 'instance fruit is', 'instances of which', 'intended to help', 'interfaces can share', 'invented in 1967', 'is also sometimes', 'is applied to', 'is basic concept', 'is done by', 'is fruit apples', 'is generalization of', 'is intended to', 'is kind of', 'is known about', 'is not sufficiently', 'is powerful mechanism', 'is relationships represent', 'is that modules', 'is to create', 'is typically accomplished', 'is way to', 'it called msc', 'it is intended', 'its particularities inheritance', 'kind of relationship', 'kinds of postgraduate', 'kinds of student', 'known about specific', 'known as derived', 'known as the', 'languages categorization is', 'larger tree structure', 'layers where if', 'lead to the', 'learning by means', 'less information needs', 'little or no', 'lot of code', 'mango and many', 'many others one', 'many pieces of', 'mature may lead', 'may lead to', 'may naturally inherit', 'mean that both', 'means of generalization', 'mechanism number of', 'methods and classes', 'methods and variables', 'methods exposed by', 'methods to those', 'models the is', 'modification inheritance provides', 'modules with sufficiently', 'more general root', 'more methods exposed', 'more specialised extensions', 'msc student and', 'naturally inherit all', 'needs to be', 'new class inheritance', 'new classes instances', 'new classes known', 'new classes that', 'new classes to', 'new methods and', 'new methods to', 'no modification inheritance', 'node and both', 'node by adding', 'node or the', 'nodes in this', 'not sufficiently mature', 'number of information', 'object oriented programming', 'objects for example', 'objects for instance', 'objects using classes', 'occur on several', 'of apple orange', 'of code being', 'of code reducing', 'of generalization what', 'of information processing', 'of inheritance is', 'of object oriented', 'of objects for', 'of plant an', 'of postgraduate student', 'of relationship between', 'of relationship can', 'of student are', 'of student this', 'of the existing', 'of the pre', 'of the program', 'of the student', 'of which are', 'on several layers', 'one can consider', 'one or more', 'only its particularities', 'or ancestor classes', 'or by adding', 'or child class', 'or inherit attributes', 'or inheritance used', 'or more methods', 'or no modification', 'or objects for', 'or parent class', 'or the child', 'orange etc conversely', 'orange mango and', 'oriented programming inheritance', 'oriented programming where', 'others one can', 'over or inherit', 'overriding replacing one', 'parent class whereas', 'particularities inheritance is', 'phd student as', 'phd student classes', 'pieces of code', 'plant an advantage', 'polymorphism which describes', 'postgraduate and student', 'postgraduate and undergraduate', 'postgraduate class extends', 'postgraduate node by', 'postgraduate student this', 'postgraduate would be', 'postgraduates and undergraduates', 'powerful mechanism number', 'pre existing classes', 'processing crucial to', 'program inheritance therefore', 'programming inheritance is', 'programming where the', 'properties common to', 'provides the support', 'reducing the complexity', 'referred to as', 'relation can be', 'relationship between entities', 'relationship can be', 'relationship student would', 'relationships represent hierarchy', 'replacing one or', 'represent hierarchy between', 'representation by categorization', 'reuse existing code', 'reuse the methods', 'root node and', 'seed of plant', 'several layers where', 'share lot of', 'shared control code', 'similar interfaces can', 'simula the new', 'since apples are', 'sometimes called generalization', 'specialise the new', 'specialised extensions of', 'specific entities is', 'specific entity only', 'stored about each', 'structure for example', 'structure where student', 'student and phd', 'student are kinds', 'student as both', 'student class inheritance', 'student classes would', 'student node or', 'student this kind', 'student this would', 'student would be', 'subclass or child', 'such as being', 'sufficiently mature may', 'sufficiently similar interfaces', 'superclass or parent', 'support for representation', 'take over or', 'that add extra', 'that both the', 'that have already', 'that is not', 'that modules with', 'the basic idea', 'the child nodes', 'the complexity of', 'the existing classes', 'the inheritance concept', 'the is kind', 'the is relationships', 'the methods and', 'the more general', 'the msc student', 'the new class', 'the new classes', 'the postgraduate and', 'the postgraduate class', 'the postgraduate node', 'the pre existing', 'the program inheritance', 'the properties common', 'the seed of', 'the student class', 'the student node', 'the subclass or', 'the superclass or', 'the support for', 'the yo yo', 'therefore has another', 'these types of', 'this is done', 'this kind of', 'this relationship student', 'this would mean', 'those exposed by', 'to all fruit', 'to as base', 'to be an', 'to be stored', 'to create new', 'to existing classes', 'to form new', 'to help reuse', 'to human learning', 'to it called', 'to reuse the', 'to specialise the', 'to the yo', 'to those exposed', 'to wider group', 'tree structure for', 'tree structure where', 'two extra extended', 'types of student', 'typically accomplished either', 'undergraduate would be', 'undergraduates are both', 'used within design', 'using classes that', 'variables from both', 'variables of the', 'view dual called', 'visualised as tree', 'visualised would display', 'was invented in', 'way to form', 'we could further', 'what is known', 'where if visualised', 'where student would', 'where the basic', 'whereas postgraduate would', 'which are called', 'which are referred', 'which describes many', 'wider group given', 'with little or', 'with sufficiently similar', 'within design that', 'would be known', 'would be more', 'would be the', 'would display larger', 'would inherit methods', 'would mean that', 'yo yo problem']\n",
      "[1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0\n",
      " 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1\n",
      " 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 1 0 1\n",
      " 1 0 2 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1\n",
      " 1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1\n",
      " 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 2 1 1 1 1 1 0 0 0\n",
      " 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 0 2 1 0 1 1 0 1 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 2 1 1 0 0 2 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 2 0 0 1 0 0 1 0 1 2 0 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0\n",
      " 0 1 0 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 2 1 1 1 1 1 1 1 2 1 0 0 0 1 0 0 1 1 0\n",
      " 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0\n",
      " 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0\n",
      " 0 0 0 0 2 1 1 1 1 1 0]\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google  the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank  other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm  \n",
      "['10', '2005', '285', '336', '999', 'about', 'academic', 'actual', 'algorithm', 'algorithms', 'all', 'also', 'among', 'an', 'analysis', 'analyzes', 'and', 'any', 'applied', 'are', 'as', 'ask', 'assigned', 'assigns', 'at', 'ballot', 'based', 'be', 'been', 'brin', 'but', 'by', 'called', 'cast', 'casts', 'clever', 'collection', 'com', 'concept', 'concerning', 'counts', 'defined', 'democratic', 'denoted', 'denotes', 'depends', 'derived', 'describes', 'details', 'devoted', 'documents', 'each', 'element', 'engine', 'entities', 'essence', 'exchange', 'exclusive', 'extensive', 'eyes', 'factors', 'falsely', 'for', 'from', 'given', 'google', 'has', 'have', 'heavily', 'help', 'high', 'hits', 'how', 'however', 'hyperlink', 'hyperlinked', 'ibm', 'identifying', 'if', 'ignore', 'importance', 'important', 'in', 'inbound', 'include', 'incoming', 'indicator', 'individual', 'inflated', 'influence', 'internet', 'interprets', 'invented', 'is', 'it', 'its', 'itself', 'jon', 'kleinberg', 'known', 'license', 'like', 'link', 'linked', 'links', 'logarithmic', 'looks', 'make', 'manipulation', 'many', 'may', 'measuring', 'metric', 'million', 'more', 'name', 'nature', 'no', 'not', 'now', 'number', 'numeric', 'numerical', 'numerous', 'of', 'on', 'or', 'order', 'original', 'other', 'page', 'pagerank', 'pages', 'paper', 'papers', 'particular', 'patent', 'patented', 'pr', 'practice', 'prevent', 'probability', 'process', 'project', 'proven', 'provides', 'providing', 'published', 'purpose', 'quantity', 'quotations', 'rank', 'ranking', 'received', 'receives', 'reciprocal', 'recursively', 'references', 'relative', 'relevance', 'relies', 'reported', 'research', 'results', 'richter', 'rights', 'roughly', 'scale', 'search', 'set', 'shares', 'sheer', 'since', 'site', 'sold', 'spamdexing', 'specific', 'spoofing', 'stanford', 'structure', 'such', 'support', 'teoma', 'than', 'that', 'the', 'themselves', 'theoretical', 'there', 'this', 'to', 'toolbar', 'trademark', 'trustrank', 'uniquely', 'university', 'upon', 'use', 'used', 'using', 'value', 'vast', 'visits', 'volume', 'vote', 'votes', 'vulnerable', 'ways', 'web', 'webpage', 'weigh', 'weight', 'weighting', 'well', 'were', 'wide', 'with', 'within', 'words', 'world']\n",
      "[ 1  1  1  1  1  2  1  1  4  1  2  3  1  2  1  1 14  2  1  2  6  1  1  3\n",
      "  1  1  2  2  3  1  1  9  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  2  2  2  1  1  1  1  1  1  1  2  2  6  6  1 12  4  1  1  1  2  1\n",
      "  2  1  1  1  1  1  1  1  2  3  8  1  1  1  1  1  2  2  2  1  1 11  4  2\n",
      "  1  1  1  1  1  1  5  1  6  1  1  1  2  1  1  1  1  2  2  1  1  3  1  1\n",
      "  1  1  2  1 18  7  1  1  1  6 17 20  7  1  1  1  4  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  2  1  1  1  1  1  1  1  1  1  1  1  1  2\n",
      "  2  2  2  1  1  1  1  1  1  1  2  1  1  2  1  1  8 40  1  1  2  1 17  1\n",
      "  1  1  1  3  1  1  2  1  2  1  1  1  3  2  1  1  5  1  1  1  2  1  1  2\n",
      "  4  1  2  2]\n",
      "[ 1  0  0  0  0  0  0  1  4  1  0  2  0  0  1  0  5  2  1  0  3  1  0  3\n",
      "  0  0  2  1  0  0  0  5  1  0  0  1  1  1  0  0  0  0  0  1  1  0  1  0\n",
      "  0  0  1  2  2  1  1  0  0  0  0  1  1  0  2  2  1  4  0  0  0  0  0  1\n",
      "  0  0  0  1  1  0  0  0  2  0  1  1  1  0  0  0  0  1  2  0  1  5  2  1\n",
      "  0  1  1  1  0  1  2  0  2  1  0  0  0  0  1  1  0  0  0  0  0  0  0  1\n",
      "  0  1  2  0 10  3  0  0  0  2  3  7  2  0  0  1  0  0  1  0  0  1  0  1\n",
      "  0  0  1  0  1  1  1  0  1  0  0  1  0  1  1  1  0  1  0  0  1  0  1  2\n",
      "  2  2  0  0  0  1  0  0  0  0  0  0  1  0  1  0  3 23  0  1  0  1  4  1\n",
      "  0  1  0  0  1  0  2  0  1  0  1  0  0  0  0  0  2  1  0  1  2  1  0  1\n",
      "  2  1  1  1]\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google  the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank  other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm  \n",
      "['10 for each', '2005 for 336', '285 999 however', '336 million google', '999 however the', 'about how important', 'about how other', 'academic papers concerning', 'actual visits to', 'algorithm invented by', 'algorithm may be', 'algorithm used by', 'algorithms for web', 'all pages that', 'all the other', 'also analyzes the', 'also called the', 'also influence the', 'among all the', 'an indicator of', 'an individual page', 'analysis algorithm used', 'analyzes the page', 'and actual visits', 'and brin original', 'and denoted by', 'and depends on', 'and extensive research', 'and help to', 'and not to', 'and now ask', 'and pagerank metric', 'and references the', 'and spamdexing google', 'and the pagerank', 'and the trustrank', 'and ways to', 'any collection of', 'any given element', 'applied to any', 'are no links', 'are themselves important', 'as an indicator', 'as the pagerank', 'as the world', 'as vote by', 'as vote of', 'as well as', 'ask com the', 'assigned to stanford', 'assigns numeric weighting', 'assigns numerical weighting', 'assigns to any', 'at more than', 'ballot among all', 'based ranking algorithms', 'based upon the', 'be applied to', 'be vulnerable to', 'been devoted to', 'been patented patent', 'been published since', 'brin original paper', 'but google looks', 'by jon kleinberg', 'by many pages', 'by page for', 'by pages that', 'by pr it', 'by pr the', 'by teoma and', 'by the google', 'by using its', 'called the pagerank', 'cast by pages', 'casts the vote', 'clever project and', 'collection of entities', 'com the ibm', 'concept has proven', 'concerning pagerank have', 'counts as vote', 'defined recursively and', 'democratic nature of', 'denoted by pr', 'denotes site importance', 'depends on the', 'derived from theoretical', 'describes pagerank pagerank', 'details about how', 'devoted to identifying', 'documents such as', 'documents with falsely', 'each element of', 'each webpage on', 'element is also', 'element of hyperlinked', 'engine that assigns', 'entities with reciprocal', 'essence google interprets', 'exchange for use', 'exclusive license rights', 'extensive research has', 'eyes of google', 'factors influence pagerank', 'factors relevance of', 'falsely inflated pagerank', 'for 336 million', 'for each webpage', 'for page but', 'for that page', 'for use of', 'for web pages', 'from 10 for', 'from ballot among', 'from documents with', 'from page to', 'from stanford university', 'from theoretical probability', 'given element is', 'google and the', 'google assigns numeric', 'google describes pagerank', 'google google has', 'google has exclusive', 'google in exchange', 'google internet search', 'google interprets link', 'google looks at', 'google provides no', 'google the pagerank', 'google toolbar also', 'has been devoted', 'has been patented', 'has exclusive license', 'has proven to', 'have been published', 'heavily and help', 'help to make', 'high pagerank receives', 'high rank itself', 'hits algorithm invented', 'how important page', 'how other factors', 'however the patent', 'hyperlink to page', 'hyperlinked set of', 'ibm clever project', 'identifying falsely inflated', 'if there are', 'ignore links from', 'importance in the', 'importance within the', 'important in other', 'important page is', 'important weigh more', 'in 2005 for', 'in essence google', 'in exchange for', 'in google in', 'in order to', 'in other words', 'in practice the', 'in the eyes', 'inbound links as', 'include the hits', 'incoming links page', 'indicator of an', 'individual page value', 'inflated pagerank and', 'inflated pagerank other', 'influence pagerank numerous', 'influence the pagerank', 'internet search engine', 'internet this pagerank', 'interprets link from', 'invented by jon', 'is also called', 'is assigned to', 'is defined recursively', 'is derived from', 'is hyperlink to', 'is known that', 'is link analysis', 'is linked to', 'is no support', 'is roughly based', 'is trademark of', 'it also analyzes', 'it assigns to', 'it incoming links', 'it is known', 'its relative importance', 'its vast link', 'itself if there', 'jon kleinberg used', 'kleinberg used by', 'known that other', 'license rights on', 'like the richter', 'link analysis algorithm', 'link based ranking', 'link from page', 'link structure as', 'link to it', 'linked to by', 'links as well', 'links from documents', 'links it is', 'links page receives', 'links page that', 'links the algorithm', 'links to web', 'logarithmic scale like', 'looks at more', 'make other pages', 'manipulation and extensive', 'manipulation spoofing and', 'many pages with', 'may be applied', 'measuring its relative', 'metric of all', 'million google describes', 'million shares in', 'more heavily and', 'more than the', 'name pagerank is', 'nature of the', 'no links to', 'no specific details', 'no support for', 'not to google', 'now ask com', 'number and pagerank', 'numeric weighting from', 'numerical weight that', 'numerical weighting to', 'numerous academic papers', 'of all pages', 'of an individual', 'of and denoted', 'of documents such', 'of entities with', 'of google and', 'of google the', 'of hyperlinked set', 'of inbound links', 'of measuring its', 'of page is', 'of particular page', 'of search words', 'of support the', 'of the pages', 'of the patent', 'of the web', 'of votes or', 'on logarithmic scale', 'on the internet', 'on the number', 'on the page', 'on the patent', 'on the uniquely', 'on the world', 'or links page', 'order to prevent', 'original paper in', 'other factors influence', 'other factors relevance', 'other link based', 'other pages important', 'other pages on', 'other words pagerank', 'page and actual', 'page and brin', 'page as vote', 'page but google', 'page counts as', 'page for page', 'page google assigns', 'page is defined', 'page is hyperlink', 'page is roughly', 'page receives it', 'page reported by', 'page that casts', 'page that is', 'page there is', 'page to page', 'page value in', 'pagerank and ways', 'pagerank concept has', 'pagerank denotes site', 'pagerank have been', 'pagerank in order', 'pagerank is derived', 'pagerank is link', 'pagerank is trademark', 'pagerank metric of', 'pagerank numerous academic', 'pagerank of and', 'pagerank of page', 'pagerank of particular', 'pagerank of the', 'pagerank other link', 'pagerank pagerank relies', 'pagerank process has', 'pagerank receives high', 'pagerank relies on', 'pagerank results from', 'pages important in', 'pages include the', 'pages on the', 'pages providing the', 'pages that are', 'pages that link', 'pages with high', 'paper in practice', 'papers concerning pagerank', 'particular page is', 'patent 285 999', 'patent from stanford', 'patent is assigned', 'patent the shares', 'patented patent 285', 'pr it is', 'pr the name', 'practice the pagerank', 'prevent manipulation spoofing', 'probability value on', 'process has been', 'project and the', 'proven to be', 'provides no specific', 'providing the links', 'published since page', 'purpose of measuring', 'quantity of inbound', 'quotations and references', 'rank itself if', 'ranking algorithms for', 'received million shares', 'receives high rank', 'receives it also', 'reciprocal quotations and', 'recursively and depends', 'references the numerical', 'relative importance within', 'relevance of search', 'relies on the', 'reported by the', 'research has been', 'results from ballot', 'richter scale the', 'rights on the', 'roughly based upon', 'scale like the', 'scale the pagerank', 'search engine that', 'search words on', 'set google assigns', 'set of documents', 'set the algorithm', 'shares in google', 'shares were sold', 'sheer volume of', 'since page and', 'site importance in', 'sold in 2005', 'spamdexing google provides', 'specific details about', 'spoofing and spamdexing', 'stanford university and', 'stanford university the', 'structure as an', 'such as the', 'support for that', 'support the pagerank', 'teoma and now', 'than the sheer', 'that are themselves', 'that assigns numerical', 'that casts the', 'that is linked', 'that it assigns', 'that link to', 'that other factors', 'that page google', 'the algorithm may', 'the eyes of', 'the google internet', 'the google toolbar', 'the hits algorithm', 'the ibm clever', 'the internet this', 'the links it', 'the links the', 'the name pagerank', 'the number and', 'the numerical weight', 'the other pages', 'the page and', 'the page reported', 'the page that', 'the pagerank concept', 'the pagerank in', 'the pagerank is', 'the pagerank of', 'the pagerank other', 'the pagerank process', 'the pages providing', 'the patent from', 'the patent is', 'the patent the', 'the purpose of', 'the quantity of', 'the richter scale', 'the set google', 'the set the', 'the shares were', 'the sheer volume', 'the trustrank algorithm', 'the uniquely democratic', 'the university received', 'the vote votes', 'the web by', 'the world wide', 'themselves important weigh', 'theoretical probability value', 'there are no', 'there is no', 'this pagerank denotes', 'to any collection', 'to any given', 'to be vulnerable', 'to by many', 'to each element', 'to google google', 'to identifying falsely', 'to ignore links', 'to it incoming', 'to make other', 'to manipulation and', 'to page as', 'to page counts', 'to prevent manipulation', 'to stanford university', 'to the page', 'to web page', 'toolbar also influence', 'trademark of google', 'uniquely democratic nature', 'university and not', 'university received million', 'university the university', 'upon the quantity', 'use of the', 'used by teoma', 'used by the', 'using its vast', 'value in essence', 'value on logarithmic', 'vast link structure', 'visits to the', 'volume of votes', 'vote by page', 'vote of support', 'vote votes cast', 'votes cast by', 'votes or links', 'vulnerable to manipulation', 'ways to ignore', 'web about how', 'web by using', 'web page there', 'web pages include', 'web with the', 'webpage on the', 'weigh more heavily', 'weight that it', 'weighting from 10', 'weighting to each', 'well as the', 'were sold in', 'wide web about', 'wide web with', 'with falsely inflated', 'with high pagerank', 'with reciprocal quotations', 'with the purpose', 'within the set', 'words on the', 'words pagerank results', 'world wide web']\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 2 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 4\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2]\n",
      "[1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0\n",
      " 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 2 0 1\n",
      " 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0\n",
      " 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0\n",
      " 0 1 0 0 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 3\n",
      " 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1\n",
      " 1 0 0 1 0 0 1 1 1 1 0 1]\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "the vector space model also called term vector model is an algebraic model used to represent text documents as well as any objects in general as vectors of identifiers it is used in information retrieval and was first used in the smart information retrieval system  a document is represented as a vector and each dimension corresponds to a separate term if a term appears in the document then its value in the vector is non zero many different ways of calculating these values also known as term weights have been developed one of the best known methods is called tf idf weighting  the definition of term depends on the application but generally terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary which is the number of distinct words occurring in the corpus  the vector space model has several disadvantages firstly long documents are represented badly because they have poor similarity values secondly search keywords must accurately match document terms and substrings of words might result in a false positive match  thirdly documents with similar context but different term vocabulary will not be associated resulting in a false negative match  finally the order in which the terms appear in the document is lost in the vector space representation  \n",
      "['accurately', 'algebraic', 'also', 'an', 'and', 'any', 'appear', 'appears', 'application', 'are', 'as', 'associated', 'badly', 'be', 'because', 'been', 'below', 'best', 'but', 'calculating', 'called', 'chosen', 'computing', 'context', 'corpus', 'corresponds', 'definition', 'depends', 'developed', 'different', 'dimension', 'dimensionality', 'disadvantages', 'distinct', 'document', 'documents', 'each', 'example', 'false', 'filtering', 'finally', 'first', 'firstly', 'following', 'for', 'general', 'generally', 'has', 'have', 'identifiers', 'idf', 'if', 'in', 'index', 'indexing', 'information', 'is', 'it', 'its', 'keywords', 'known', 'large', 'limitations', 'long', 'longer', 'lost', 'many', 'match', 'methods', 'might', 'model', 'must', 'negative', 'non', 'not', 'number', 'objects', 'occurring', 'occurs', 'of', 'on', 'one', 'or', 'order', 'phrases', 'poor', 'poorly', 'positive', 'precisely', 'product', 'rankings', 'relevancy', 'represent', 'representation', 'represented', 'representing', 'result', 'resulting', 'retrieval', 'scalar', 'schemes', 'search', 'secondly', 'see', 'semantic', 'sensitivity', 'separate', 'several', 'similar', 'similarity', 'single', 'small', 'smart', 'space', 'substrings', 'such', 'system', 'term', 'terms', 'text', 'tf', 'the', 'then', 'these', 'they', 'thirdly', 'to', 'typically', 'use', 'used', 'value', 'values', 'vector', 'vectors', 'vocabulary', 'was', 'ways', 'weighting', 'weights', 'well', 'which', 'will', 'with', 'won', 'word', 'words', 'zero']\n",
      "[ 0  1  1  1  3  1  1  0  1  3  4  1  0  2  1  1  1  1  1  0  0  1  1  1\n",
      "  1  1  1  1  1  2  1  2  0  1  4  3  1  2  2  1  0  1  0  1  2  1  0  1\n",
      "  2  1  1  2 12  1  1  3  7  1  2  2  2  1  1  1  1  1  0  3  0  1  4  1\n",
      "  1  1  0  2  1  1  1  7  1  1  2  1  1  1  1  1  1  1  1  1  0  1  2  1\n",
      "  1  1  2  1  1  1  0  1  1  1  1  1  1  1  1  1  1  3  1  1  1  6  5  1\n",
      "  1 21  0  1  1  0  2  1  1  1  1  2  7  1  2  1  1  1  1  0  1  0  1  1\n",
      "  1  4  1]\n",
      "[ 1  1  2  1  3  1  1  1  1  3  5  1  1  2  1  1  0  1  2  1  2  1  0  1\n",
      "  1  1  1  1  1  2  1  1  1  1  4  3  1  0  2  0  1  1  1  0  0  1  1  1\n",
      "  2  1  1  2 12  0  0  2  8  1  1  2  2  0  0  1  1  1  1  3  1  1  4  1\n",
      "  1  1  1  2  1  1  0  8  1  1  1  1  1  1  0  1  0  0  0  0  1  1  2  0\n",
      "  1  1  2  0  0  1  1  0  0  0  1  1  1  1  1  0  1  3  1  0  1  6  4  1\n",
      "  1 20  1  1  1  1  3  0  0  3  1  2  7  1  2  1  1  1  1  1  2  1  1  0\n",
      "  0  5  1]\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "the vector space model also called term vector model is an algebraic model used to represent text documents as well as any objects in general as vectors of identifiers it is used in information retrieval and was first used in the smart information retrieval system  a document is represented as a vector and each dimension corresponds to a separate term if a term appears in the document then its value in the vector is non zero many different ways of calculating these values also known as term weights have been developed one of the best known methods is called tf idf weighting  the definition of term depends on the application but generally terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary which is the number of distinct words occurring in the corpus  the vector space model has several disadvantages firstly long documents are represented badly because they have poor similarity values secondly search keywords must accurately match document terms and substrings of words might result in a false positive match  thirdly documents with similar context but different term vocabulary will not be associated resulting in a false negative match  finally the order in which the terms appear in the document is lost in the vector space representation  \n",
      "['accurately match document', 'algebraic model for', 'algebraic model used', 'also called term', 'also known as', 'an algebraic model', 'and any objects', 'and each dimension', 'and large dimensionality', 'and relevancy rankings', 'and substrings of', 'and was first', 'any objects in', 'appear in the', 'appears in the', 'application but generally', 'application typically terms', 'are chosen to', 'are poorly represented', 'are represented badly', 'are single words', 'as any objects', 'as for example', 'as term weights', 'as vector and', 'as vector each', 'as vectors of', 'as well as', 'associated resulting in', 'badly because they', 'be associated resulting', 'be the terms', 'because they have', 'been developed one', 'below the definition', 'best known methods', 'best known schemes', 'but different term', 'but generally terms', 'calculating these values', 'called term vector', 'called tf idf', 'chosen to be', 'computing these values', 'context but different', 'corpus the vector', 'corresponds to separate', 'definition of term', 'depends on the', 'developed one of', 'different term vocabulary', 'different ways of', 'dimension corresponds to', 'dimensionality of the', 'dimensionality search keywords', 'disadvantages firstly long', 'distinct words occurring', 'document is lost', 'document is represented', 'document its value', 'document terms and', 'document terms word', 'document then its', 'documents and any', 'documents are poorly', 'documents are represented', 'documents as well', 'documents with similar', 'each dimension corresponds', 'example below the', 'example index terms', 'false negative match', 'false positive match', 'filtering information retrieval', 'finally the order', 'first use was', 'first used in', 'firstly long documents', 'following limitations long', 'for example index', 'for representing text', 'general as vectors', 'generally terms are', 'has several disadvantages', 'has the following', 'have been developed', 'have poor similarity', 'identifiers it is', 'identifiers such as', 'idf weighting see', 'idf weighting the', 'if term appears', 'if term occurs', 'if the words', 'in false negative', 'in false positive', 'in general as', 'in information filtering', 'in information retrieval', 'in the corpus', 'in the document', 'in the smart', 'in the vector', 'in the vocabulary', 'in which the', 'index terms it', 'indexing and relevancy', 'information filtering information', 'information retrieval and', 'information retrieval indexing', 'information retrieval system', 'is an algebraic', 'is called tf', 'is lost in', 'is non zero', 'is represented as', 'is tf idf', 'is the number', 'is used in', 'it is used', 'its first use', 'its value in', 'keywords must accurately', 'keywords must precisely', 'keywords or longer', 'known as term', 'known methods is', 'known schemes is', 'large dimensionality search', 'limitations long documents', 'long documents are', 'longer phrases if', 'lost in the', 'many different ways', 'match document terms', 'match finally the', 'match semantic sensitivity', 'match the order', 'match thirdly documents', 'methods is called', 'might result in', 'model also called', 'model for representing', 'model has several', 'model has the', 'model is an', 'model or term', 'model used to', 'must accurately match', 'must precisely match', 'negative match finally', 'negative match the', 'non zero many', 'non zero several', 'not be associated', 'number of distinct', 'number of words', 'objects in general', 'occurring in the', 'occurs in the', 'of calculating these', 'of computing these', 'of distinct words', 'of identifiers it', 'of identifiers such', 'of term depends', 'of the best', 'of the vector', 'of words in', 'of words might', 'on the application', 'one of the', 'or longer phrases', 'or term vector', 'order in which', 'phrases if the', 'poor similarity values', 'poorly represented because', 'positive match semantic', 'positive match thirdly', 'precisely match document', 'product and large', 'rankings its first', 'relevancy rankings its', 'represent text documents', 'represented as vector', 'represented badly because', 'represented because they', 'representing text documents', 'result in false', 'resulting in false', 'retrieval and was', 'retrieval indexing and', 'retrieval system document', 'scalar product and', 'schemes is tf', 'search keywords must', 'secondly search keywords', 'see the example', 'semantic sensitivity documents', 'sensitivity documents with', 'separate term if', 'several different ways', 'several disadvantages firstly', 'similar context but', 'similarity values secondly', 'similarity values small', 'single words keywords', 'small scalar product', 'smart information retrieval', 'space model also', 'space model has', 'space model or', 'substrings might result', 'substrings of words', 'such as for', 'system document is', 'term appears in', 'term depends on', 'term if term', 'term occurs in', 'term vector model', 'term vocabulary will', 'term vocabulary won', 'term weights have', 'terms and substrings', 'terms appear in', 'terms are single', 'terms it is', 'terms the dimensionality', 'terms word substrings', 'text documents and', 'text documents as', 'tf idf weighting', 'the application but', 'the application typically', 'the best known', 'the corpus the', 'the definition of', 'the dimensionality of', 'the document is', 'the document its', 'the document then', 'the example below', 'the following limitations', 'the number of', 'the order in', 'the smart information', 'the terms appear', 'the terms the', 'the vector is', 'the vector space', 'the vocabulary the', 'the vocabulary which', 'the words are', 'then its value', 'these values also', 'they have poor', 'thirdly documents with', 'to be the', 'to represent text', 'to separate term', 'typically terms are', 'use was in', 'used in information', 'used in the', 'used to represent', 'value in the', 'values also known', 'values secondly search', 'values small scalar', 'vector and each', 'vector each dimension', 'vector is non', 'vector is the', 'vector model is', 'vector space model', 'vector space representation', 'vectors of identifiers', 'vocabulary the number', 'vocabulary which is', 'vocabulary will not', 'vocabulary won be', 'was first used', 'was in the', 'ways of calculating', 'ways of computing', 'weighting see the', 'weighting the definition', 'weights have been', 'well as any', 'which is the', 'which the terms', 'will not be', 'with similar context', 'won be associated', 'word substrings might', 'words are chosen', 'words in the', 'words keywords or', 'words might result', 'words occurring in', 'zero many different', 'zero several different']\n",
      "[0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1\n",
      " 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1\n",
      " 0 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 2 1 2 1 1 1 1 1 0 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0\n",
      " 0 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0\n",
      " 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1\n",
      " 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 2 1 1 1 1 2 2 1 0 1 0 1 1 0\n",
      " 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 2 1 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1\n",
      " 1 1 1 1 0 1 0 1]\n",
      "[1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0\n",
      " 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 2 1 2 1 1 0 0 0 1 0 1\n",
      " 1 1 1 1 1 0 2 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1\n",
      " 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 0 1\n",
      " 1 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1\n",
      " 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 2 1 1 1 1 2 3 0 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 2 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0\n",
      " 0 1 1 1 1 1 1 0]\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "bayes theorem was names after rev thomas bayes and is a method used in probability theory this theorem aims to relate the conditional and marginal probabilities of two random events occuring and given various observations is frequently used to compute subsequent probabilities bayes theorem is also often known as bayes law  an example of where bayes theorem may be used is in the following extract  suppose there exists a school with forty percent females and sixty percent males as students the female students can only wear skirts or trousers in equal numbers whereas all the male students can only wear trousers an observer randomly sees a student from a distance and all he can see is that this student is wearing trousers what is the probability this student is female  there is a debate amongst frequentists and bayesians about how bayes theorem plays a major role around the beginnings of statistical mathematics frequentist and bayesian explanations do not agree about the ways in which probabilities should be assigned this is primarily because bayesians assign probabilities in terms of beliefs whereas frequentists assign probabilities to random events according to the frequencies of them occurring \n",
      "['about', 'according', 'account', 'acts', 'after', 'agree', 'aims', 'all', 'also', 'amongst', 'an', 'and', 'any', 'applications', 'are', 'around', 'articles', 'as', 'assign', 'assigned', 'bayes', 'bayesian', 'bayesians', 'be', 'because', 'beginnings', 'beliefs', 'by', 'called', 'can', 'central', 'certain', 'common', 'compute', 'conditional', 'constant', 'conventional', 'correct', 'debate', 'debates', 'degrees', 'depends', 'derived', 'describe', 'describes', 'detail', 'diagnosis', 'disagree', 'discuss', 'distance', 'do', 'does', 'each', 'equal', 'events', 'example', 'exists', 'explanations', 'extract', 'female', 'females', 'following', 'for', 'form', 'formal', 'forty', 'foundations', 'frac', 'frequencies', 'frequentist', 'frequentists', 'frequently', 'from', 'given', 'greater', 'has', 'have', 'having', 'he', 'how', 'however', 'in', 'information', 'interpretations', 'into', 'intuitively', 'is', 'it', 'known', 'law', 'major', 'male', 'males', 'marginal', 'mathematics', 'may', 'method', 'name', 'names', 'non', 'normalizing', 'not', 'numbers', 'observation', 'observations', 'observed', 'observer', 'observing', 'occuring', 'occurrence', 'occurring', 'of', 'often', 'on', 'one', 'only', 'or', 'patient', 'percent', 'plays', 'populations', 'posterior', 'primarily', 'prior', 'probabilities', 'probability', 'proportions', 'proposed', 'random', 'randomly', 'relate', 'relates', 'rev', 'role', 'school', 'see', 'sees', 'sense', 'should', 'sixty', 'skirts', 'specified', 'statistical', 'statistics', 'student', 'students', 'subsequent', 'subsets', 'suppose', 'symptoms', 'take', 'term', 'terms', 'that', 'the', 'their', 'them', 'theorem', 'theory', 'there', 'these', 'this', 'thomas', 'to', 'trousers', 'two', 'uncertainty', 'updated', 'upon', 'used', 'valid', 'value', 'vanishing', 'various', 'was', 'way', 'ways', 'wear', 'wearing', 'what', 'where', 'whereas', 'which', 'while', 'whole', 'with']\n",
      "[ 3  1  1  1  1  0  0  1  1  0  0  7  1  1  1  1  1  3  1  1  8  2  1  3\n",
      "  1  0  2  1  2  1  1  1  1  2  4  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  0  0  1  1  0  3  2  0  0  0  0  0  0  1  1  1  0  1  1  1  2  1  0\n",
      "  1  4  1  2  1  1  0  0  1 11  1  2  1  1 10  6  0  1  0  0  0  4  0  1\n",
      "  0  1  0  1  1  1  0  1  1  2  0  1  0  1  0 14  2  1  1  0  4  1  0  1\n",
      "  1  2  0  3  6 12  1  1  2  0  0  2  1  1  0  1  0  1  1  0  0  1  0  1\n",
      "  0  0  0  1  0  1  1  1  1  3 16  1  0  7  1  0  1  1  1  6  0  1  1  1\n",
      "  1  2  1  1  1  0  0  1  1  0  0  0  1  0  2  1  1  0]\n",
      "[ 2  1  0  0  1  1  1  2  1  1  2  7  0  0  0  1  0  2  2  1  6  1  2  2\n",
      "  1  1  1  0  0  3  0  0  0  1  1  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "  0  1  1  0  0  1  2  1  1  1  1  2  1  1  0  0  0  1  0  0  1  1  2  1\n",
      "  1  1  0  0  0  0  1  1  0  5  0  0  0  0 10  0  1  1  1  1  1  1  1  1\n",
      "  1  0  1  0  0  1  1  0  1  0  1  0  1  0  1  5  1  0  0  2  1  0  2  1\n",
      "  0  0  1  0  5  2  0  0  2  1  1  0  1  1  1  1  1  0  1  1  1  0  1  0\n",
      "  3  3  1  0  1  0  0  0  1  1  8  0  1  5  1  2  0  4  1  4  3  1  0  0\n",
      "  0  3  0  0  0  1  1  0  1  2  1  1  1  2  1  0  0  1]\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "bayes theorem was names after rev thomas bayes and is a method used in probability theory this theorem aims to relate the conditional and marginal probabilities of two random events occuring and given various observations is frequently used to compute subsequent probabilities bayes theorem is also often known as bayes law  an example of where bayes theorem may be used is in the following extract  suppose there exists a school with forty percent females and sixty percent males as students the female students can only wear skirts or trousers in equal numbers whereas all the male students can only wear trousers an observer randomly sees a student from a distance and all he can see is that this student is wearing trousers what is the probability this student is female  there is a debate amongst frequentists and bayesians about how bayes theorem plays a major role around the beginnings of statistical mathematics frequentist and bayesian explanations do not agree about the ways in which probabilities should be assigned this is primarily because bayesians assign probabilities in terms of beliefs whereas frequentists assign probabilities to random events according to the frequencies of them occurring \n",
      "['about how bayes', 'about is the', 'about observing are', 'about the ways', 'according to the', 'according to their', 'account any information', 'acts as normalizing', 'after rev thomas', 'agree about the', 'aims to relate', 'all common interpretations', 'all he can', 'all the male', 'also called the', 'also often known', 'amongst frequentists and', 'an example of', 'an observer randomly', 'and acts as', 'and all he', 'and bayesian explanations', 'and bayesian interpretations', 'and bayesians about', 'and degrees of', 'and frequentist probability', 'and given various', 'and is method', 'and marginal probabilities', 'and sixty percent', 'and where has', 'any information about', 'applications frequentists assign', 'are updated by', 'around the beginnings', 'around the foundations', 'articles on bayesian', 'as bayes law', 'as formal theorem', 'as normalizing constant', 'as proportions of', 'as students the', 'assign probabilities in', 'assign probabilities to', 'assigned in applications', 'assigned this is', 'bayes and is', 'bayes law after', 'bayes law an', 'bayes relates the', 'bayes theorem can', 'bayes theorem has', 'bayes theorem in', 'bayes theorem is', 'bayes theorem may', 'bayes theorem often', 'bayes theorem plays', 'bayes theorem relates', 'bayes theorem was', 'bayesian explanations do', 'bayesian interpretations disagree', 'bayesian probability and', 'bayesians about how', 'bayesians assign probabilities', 'bayesians describe probabilities', 'be assigned in', 'be assigned this', 'be observed to', 'be used is', 'be used to', 'because bayesians assign', 'because it is', 'beginnings of statistical', 'beliefs about observing', 'beliefs and degrees', 'beliefs whereas frequentists', 'by having observed', 'called bayes law', 'called the posterior', 'can be used', 'can only wear', 'can see is', 'central role in', 'certain symptoms bayes', 'common interpretations of', 'compute posterior probabilities', 'compute subsequent probabilities', 'compute the probability', 'conditional and marginal', 'conditional probability of', 'constant intuitively bayes', 'conventional name is', 'correct given that', 'debate amongst frequentists', 'debate around the', 'debates in greater', 'degrees of uncertainty', 'depends upon the', 'derived from or', 'describe probabilities in', 'describes the way', 'detail bayes theorem', 'diagnosis is correct', 'disagree about the', 'discuss these debates', 'distance and all', 'do not agree', 'does not take', 'each term in', 'equal numbers whereas', 'events according to', 'events and where', 'events it is', 'events occuring and', 'example as formal', 'example of where', 'example patient may', 'exists school with', 'explanations do not', 'extract suppose there', 'female students can', 'female there is', 'females and sixty', 'following extract suppose', 'for example patient', 'form describes the', 'formal theorem bayes', 'forty percent females', 'foundations of statistics', 'frac each term', 'frequencies of occurrence', 'frequencies of them', 'frequentist and bayesian', 'frequentist probability discuss', 'frequentists and bayesians', 'frequentists assign probabilities', 'frequently used to', 'from distance and', 'from or depends', 'given is the', 'given it is', 'given observations for', 'given that observation', 'given various observations', 'greater detail bayes', 'has conventional name', 'has non vanishing', 'have certain symptoms', 'he can see', 'how bayes theorem', 'however it plays', 'in all common', 'in applications frequentists', 'in bayes theorem', 'in equal numbers', 'in greater detail', 'in probability theory', 'in terms of', 'in the debate', 'in the following', 'in the sense', 'in this form', 'in which one', 'in which probabilities', 'information about is', 'interpretations disagree about', 'interpretations of probability', 'into account any', 'intuitively bayes theorem', 'is also called', 'is also often', 'is correct given', 'is debate amongst', 'is derived from', 'is female there', 'is frequently used', 'is in the', 'is method used', 'is often used', 'is primarily because', 'is prior in', 'is that this', 'is the conditional', 'is the prior', 'is the probability', 'is valid in', 'is wearing trousers', 'it does not', 'it is also', 'it is derived', 'it is often', 'it is prior', 'it plays central', 'known as bayes', 'law after rev', 'law an example', 'major role around', 'male students can', 'males as students', 'marginal probabilities of', 'marginal probability of', 'mathematics frequentist and', 'may be observed', 'may be used', 'method used in', 'name is the', 'names after rev', 'non vanishing probability', 'normalizing constant intuitively', 'not agree about', 'not take into', 'numbers whereas all', 'observation see example', 'observations for example', 'observations is frequently', 'observed to have', 'observer randomly sees', 'observing are updated', 'occuring and given', 'occurrence or to', 'of and acts', 'of beliefs and', 'of beliefs whereas', 'of events and', 'of given is', 'of given it', 'of is the', 'of it is', 'of occurrence or', 'of populations as', 'of probability however', 'of statistical mathematics', 'of statistics frequentist', 'of the whole', 'of them occurring', 'of two random', 'of uncertainty the', 'of where bayes', 'often called bayes', 'often known as', 'often used to', 'on bayesian probability', 'one beliefs about', 'only wear skirts', 'only wear trousers', 'or depends upon', 'or marginal probability', 'or to subsets', 'or trousers in', 'patient may be', 'percent females and', 'percent males as', 'plays central role', 'plays major role', 'populations as proportions', 'posterior probabilities given', 'posterior probability because', 'primarily because bayesians', 'prior in the', 'prior or marginal', 'prior probability or', 'probabilities bayes theorem', 'probabilities given observations', 'probabilities in terms', 'probabilities of events', 'probabilities of two', 'probabilities should be', 'probabilities to random', 'probability and frequentist', 'probability because it', 'probability discuss these', 'probability frac each', 'probability however it', 'probability of and', 'probability of given', 'probability of it', 'probability or marginal', 'probability that proposed', 'probability theory bayes', 'probability theory this', 'probability this student', 'proportions of the', 'proposed diagnosis is', 'random events according', 'random events it', 'random events occuring', 'randomly sees student', 'relate the conditional', 'relates the conditional', 'rev thomas bayes', 'role around the', 'role in the', 'school with forty', 'see example as', 'see is that', 'sees student from', 'sense that it', 'should be assigned', 'sixty percent males', 'skirts or trousers', 'specified value of', 'statistical mathematics frequentist', 'statistics frequentist and', 'student from distance', 'student is female', 'student is wearing', 'students can only', 'students the female', 'subsequent probabilities bayes', 'subsets of populations', 'suppose there exists', 'symptoms bayes theorem', 'take into account', 'term in bayes', 'terms of beliefs', 'that it does', 'that observation see', 'that proposed diagnosis', 'that this student', 'the articles on', 'the beginnings of', 'the conditional and', 'the conditional probability', 'the debate around', 'the female students', 'the following extract', 'the foundations of', 'the frequencies of', 'the male students', 'the posterior probability', 'the prior or', 'the prior probability', 'the probability that', 'the probability this', 'the sense that', 'the specified value', 'the way in', 'the ways in', 'the whole while', 'their frequencies of', 'theorem aims to', 'theorem bayes theorem', 'theorem can be', 'theorem has conventional', 'theorem in this', 'theorem is also', 'theorem is valid', 'theorem may be', 'theorem often called', 'theorem plays major', 'theorem relates the', 'theorem was names', 'theory bayes theorem', 'theory this theorem', 'there exists school', 'there is debate', 'these debates in', 'this form describes', 'this is primarily', 'this student is', 'this theorem aims', 'thomas bayes and', 'thomas bayes relates', 'to compute posterior', 'to compute subsequent', 'to compute the', 'to have certain', 'to random events', 'to relate the', 'to subsets of', 'to the frequencies', 'to their frequencies', 'trousers an observer', 'trousers in equal', 'trousers what is', 'two random events', 'uncertainty the articles', 'updated by having', 'upon the specified', 'used in probability', 'used is in', 'used to compute', 'valid in all', 'value of is', 'vanishing probability frac', 'various observations is', 'was names after', 'way in which', 'ways in which', 'wear skirts or', 'wear trousers an', 'wearing trousers what', 'what is the', 'where bayes theorem', 'where has non', 'whereas all the', 'whereas frequentists assign', 'which one beliefs', 'which probabilities should', 'while bayesians describe', 'whole while bayesians', 'with forty percent']\n",
      "[0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 2 0 1 1 1 1 0 1 1\n",
      " 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1\n",
      " 1 0 1 1 1 1 0 0 1 1 1 1 0 1 2 2 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1\n",
      " 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 2 2 0\n",
      " 1 0 1 1 1 1 1 1 0 1 0 0 0 0 2 2 0 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 2 1 0 1 0 0 1 0 1 1 1 0 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 0 0 1 1 1 1 0 0 0 2 1 0 1 0 1 0 0\n",
      " 1 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 2 2 1 0 0 1 0 0 1 1 1 1\n",
      " 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1\n",
      " 0 1 0 0 0 1 1 1 1 0 0 2 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 0]\n",
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0\n",
      " 0 1 0 0 0 0 2 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1\n",
      " 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0\n",
      " 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 1\n",
      " 0 1 1 1 0 1 0 1 1 1 2 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 2 1 1 0 0 1 0 0 1 1 0\n",
      " 1 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "n=1 calculations are incorrect. Double check the intersection calculation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-cacba0005ac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# test containment calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# params: complete_df from before, and containment function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_containment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplete_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_containment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/ML_SageMaker_Studies/Project_Plagiarism_Detection/problem_unittests.py\u001b[0m in \u001b[0;36mtest_containment\u001b[0;34m(complete_df, containment_fn)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_1gram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_3gram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: n=1 calculations are incorrect. Double check the intersection calculation."
     ]
    }
   ],
   "source": [
    "# run this test cell\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# test containment calculation\n",
    "# params: complete_df from before, and containment function\n",
    "tests.test_containment(complete_df, calculate_containment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1: Why can we calculate containment features across *all* data (training & test), prior to splitting the DataFrame for modeling? That is, what about the containment calculation means that the test and training data do not influence each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Longest Common Subsequence\n",
    "\n",
    "Containment a good way to find overlap in word usage between two documents; it may help identify cases of cut-and-paste as well as paraphrased levels of plagiarism. Since plagiarism is a fairly complex task with varying levels, it's often useful to include other measures of similarity. The paper also discusses a feature called **longest common subsequence**.\n",
    "\n",
    "> The longest common subsequence is the longest string of words (or letters) that are *the same* between the Wikipedia Source Text (S) and the Student Answer Text (A). This value is also normalized by dividing by the total number of words (or letters) in the  Student Answer Text. \n",
    "\n",
    "In this exercise, we'll ask you to calculate the longest common subsequence of words between two texts.\n",
    "\n",
    "### EXERCISE: Calculate the longest common subsequence\n",
    "\n",
    "Complete the function `lcs_norm_word`; this should calculate the *longest common subsequence* of words between a Student Answer Text and corresponding Wikipedia Source Text. \n",
    "\n",
    "It may be helpful to think of this in a concrete example. A Longest Common Subsequence (LCS) problem may look as follows:\n",
    "* Given two texts: text A (answer text) of length n, and string S (original source text) of length m. Our goal is to produce their longest common subsequence of words: the longest sequence of words that appear left-to-right in both texts (though the words don't have to be in continuous order).\n",
    "* Consider:\n",
    "    * A = \"i think pagerank is a link analysis algorithm used by google that uses a system of weights attached to each element of a hyperlinked set of documents\"\n",
    "    * S = \"pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents\"\n",
    "\n",
    "* In this case, we can see that the start of each sentence of fairly similar, having overlap in the sequence of words, \"pagerank is a link analysis algorithm used by\" before diverging slightly. Then we **continue moving left -to-right along both texts** until we see the next common sequence; in this case it is only one word, \"google\". Next we find \"that\" and \"a\" and finally the same ending \"to each element of a hyperlinked set of documents\".\n",
    "* Below, is a clear visual of how these sequences were found, sequentially, in each text.\n",
    "\n",
    "<img src='notebook_ims/common_subseq_words.png' width=40% />\n",
    "\n",
    "* Now, those words appear in left-to-right order in each document, sequentially, and even though there are some words in between, we count this as the longest common subsequence between the two texts. \n",
    "* If I count up each word that I found in common I get the value 20. **So, LCS has length 20**. \n",
    "* Next, to normalize this value, divide by the total length of the student answer; in this example that length is only 27. **So, the function `lcs_norm_word` should return the value `20/27` or about `0.7408`.**\n",
    "\n",
    "In this way, LCS is a great indicator of cut-and-paste plagiarism or if someone has referenced the same source text multiple times in an answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCS, dynamic programming\n",
    "\n",
    "If you read through the scenario above, you can see that this algorithm depends on looking at two texts and comparing them word by word. You can solve this problem in multiple ways. First, it may be useful to `.split()` each text into lists of comma separated words to compare. Then, you can iterate through each word in the texts and compare them, adding to your value for LCS as you go. \n",
    "\n",
    "The method I recommend for implementing an efficient LCS algorithm is: using a matrix and dynamic programming. **Dynamic programming** is all about breaking a larger problem into a smaller set of subproblems, and building up a complete result without having to repeat any subproblems. \n",
    "\n",
    "This approach assumes that you can split up a large LCS task into a combination of smaller LCS tasks. Let's look at a simple example that compares letters:\n",
    "\n",
    "* A = \"ABCD\"\n",
    "* S = \"BD\"\n",
    "\n",
    "We can see right away that the longest subsequence of _letters_ here is 2 (B and D are in sequence in both strings). And we can calculate this by looking at relationships between each letter in the two strings, A and S.\n",
    "\n",
    "Here, I have a matrix with the letters of A on top and the letters of S on the left side:\n",
    "\n",
    "<img src='notebook_ims/matrix_1.png' width=40% />\n",
    "\n",
    "This starts out as a matrix that has as many columns and rows as letters in the strings S and O **+1** additional row and column, filled with zeros on the top and left sides. So, in this case, instead of a 2x4 matrix it is a 3x5.\n",
    "\n",
    "Now, we can fill this matrix up by breaking it into smaller LCS problems. For example, let's first look at the shortest substrings: the starting letter of A and S. We'll first ask, what is the Longest Common Subsequence between these two letters \"A\" and \"B\"? \n",
    "\n",
    "**Here, the answer is zero and we fill in the corresponding grid cell with that value.**\n",
    "\n",
    "<img src='notebook_ims/matrix_2.png' width=30% />\n",
    "\n",
    "Then, we ask the next question, what is the LCS between \"AB\" and \"B\"?\n",
    "\n",
    "**Here, we have a match, and can fill in the appropriate value 1**.\n",
    "\n",
    "<img src='notebook_ims/matrix_3_match.png' width=25% />\n",
    "\n",
    "If we continue, we get to a final matrix that looks as follows, with a **2** in the bottom right corner.\n",
    "\n",
    "<img src='notebook_ims/matrix_6_complete.png' width=25% />\n",
    "\n",
    "The final LCS will be that value **2** *normalized* by the number of n-grams in A. So, our normalized value is 2/4 = **0.5**.\n",
    "\n",
    "### The matrix rules\n",
    "\n",
    "One thing to notice here is that, you can efficiently fill up this matrix one cell at a time. Each grid cell only depends on the values in the grid cells that are directly on top and to the left of it, or on the diagonal/top-left. The rules are as follows:\n",
    "* Start with a matrix that has one extra row and column of zeros.\n",
    "* As you traverse your string:\n",
    "    * If there is a match, fill that grid cell with the value to the top-left of that cell *plus* one. So, in our case, when we found a matching B-B, we added +1 to the value in the top-left of the matching cell, 0.\n",
    "    * If there is not a match, take the *maximum* value from either directly to the left or the top cell, and carry that value over to the non-match cell.\n",
    "\n",
    "<img src='notebook_ims/matrix_rules.png' width=50% />\n",
    "\n",
    "After completely filling the matrix, **the bottom-right cell will hold the non-normalized LCS value**.\n",
    "\n",
    "This matrix treatment can be applied to a set of words instead of letters. Your function should apply this to the words in two texts and return the normalized LCS value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Compute the normalized LCS given an answer text and a source text\n",
    "def lcs_norm_word(answer_text, source_text):\n",
    "    '''Computes the longest common subsequence of words in two texts; returns a normalized value.\n",
    "       :param answer_text: The pre-processed text for an answer text\n",
    "       :param source_text: The pre-processed text for an answer's associated source text\n",
    "       :return: A normalized LCS value'''\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "Let's start by testing out your code on the example given in the initial description.\n",
    "\n",
    "In the below cell, we have specified strings A (answer text) and S (original source text). We know that these texts have 20 words in common and the submitted answer is 27 words long, so the normalized, longest common subsequence should be 20/27.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Run the test scenario from above\n",
    "# does your function return the expected value?\n",
    "\n",
    "A = \"i think pagerank is a link analysis algorithm used by google that uses a system of weights attached to each element of a hyperlinked set of documents\"\n",
    "S = \"pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents\"\n",
    "\n",
    "# calculate LCS\n",
    "lcs = lcs_norm_word(A, S)\n",
    "print('LCS = ', lcs)\n",
    "\n",
    "\n",
    "# expected value test\n",
    "assert lcs==20/27., \"Incorrect LCS value, expected about 0.7408, got \"+str(lcs)\n",
    "\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell runs a more rigorous test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# run test cell\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# test lcs implementation\n",
    "# params: complete_df from before, and lcs_norm_word function\n",
    "tests.test_lcs(complete_df, lcs_norm_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, take a look at a few resultant values for `lcs_norm_word`. Just like before, you should see that higher values correspond to higher levels of plagiarism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# test on your own\n",
    "test_indices = range(5) # look at first few files\n",
    "\n",
    "category_vals = []\n",
    "lcs_norm_vals = []\n",
    "# iterate through first few docs and calculate LCS\n",
    "for i in test_indices:\n",
    "    category_vals.append(complete_df.loc[i, 'Category'])\n",
    "    # get texts to compare\n",
    "    answer_text = complete_df.loc[i, 'Text'] \n",
    "    task = complete_df.loc[i, 'Task']\n",
    "    # we know that source texts have Class = -1\n",
    "    orig_rows = complete_df[(complete_df['Class'] == -1)]\n",
    "    orig_row = orig_rows[(orig_rows['Task'] == task)]\n",
    "    source_text = orig_row['Text'].values[0]\n",
    "    \n",
    "    # calculate lcs\n",
    "    lcs_val = lcs_norm_word(answer_text, source_text)\n",
    "    lcs_norm_vals.append(lcs_val)\n",
    "\n",
    "# print out result, does it make sense?\n",
    "print('Original category values: \\n', category_vals)\n",
    "print()\n",
    "print('Normalized LCS values: \\n', lcs_norm_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create All Features\n",
    "\n",
    "Now that you've completed the feature calculation functions, it's time to actually create multiple features and decide on which ones to use in your final model! In the below cells, you're provided two helper functions to help you create multiple features and store those in a DataFrame, `features_df`.\n",
    "\n",
    "### Creating multiple containment features\n",
    "\n",
    "Your completed `calculate_containment` function will be called in the next cell, which defines the helper function `create_containment_features`. \n",
    "\n",
    "> This function returns a list of containment features, calculated for a given `n` and for *all* files in a df (assumed to the the `complete_df`).\n",
    "\n",
    "For our original files, the containment value is set to a special value, -1.\n",
    "\n",
    "This function gives you the ability to easily create several containment features, of different n-gram lengths, for each of our text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Function returns a list of containment features, calculated for a given n \n",
    "# Should return a list of length 100 for all files in a complete_df\n",
    "def create_containment_features(df, n, column_name=None):\n",
    "    \n",
    "    containment_values = []\n",
    "    \n",
    "    if(column_name==None):\n",
    "        column_name = 'c_'+str(n) # c_1, c_2, .. c_n\n",
    "    \n",
    "    # iterates through dataframe rows\n",
    "    for i in df.index:\n",
    "        file = df.loc[i, 'File']\n",
    "        # Computes features using calculate_containment function\n",
    "        if df.loc[i,'Category'] > -1:\n",
    "            c = calculate_containment(df, n, file)\n",
    "            containment_values.append(c)\n",
    "        # Sets value to -1 for original tasks \n",
    "        else:\n",
    "            containment_values.append(-1)\n",
    "    \n",
    "    print(str(n)+'-gram containment features created!')\n",
    "    return containment_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating LCS features\n",
    "\n",
    "Below, your complete `lcs_norm_word` function is used to create a list of LCS features for all the answer files in a given DataFrame (again, this assumes you are passing in the `complete_df`. It assigns a special value for our original, source files, -1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Function creates lcs feature and add it to the dataframe\n",
    "def create_lcs_features(df, column_name='lcs_word'):\n",
    "    \n",
    "    lcs_values = []\n",
    "    \n",
    "    # iterate through files in dataframe\n",
    "    for i in df.index:\n",
    "        # Computes LCS_norm words feature using function above for answer tasks\n",
    "        if df.loc[i,'Category'] > -1:\n",
    "            # get texts to compare\n",
    "            answer_text = df.loc[i, 'Text'] \n",
    "            task = df.loc[i, 'Task']\n",
    "            # we know that source texts have Class = -1\n",
    "            orig_rows = df[(df['Class'] == -1)]\n",
    "            orig_row = orig_rows[(orig_rows['Task'] == task)]\n",
    "            source_text = orig_row['Text'].values[0]\n",
    "\n",
    "            # calculate lcs\n",
    "            lcs = lcs_norm_word(answer_text, source_text)\n",
    "            lcs_values.append(lcs)\n",
    "        # Sets to -1 for original tasks \n",
    "        else:\n",
    "            lcs_values.append(-1)\n",
    "\n",
    "    print('LCS features created!')\n",
    "    return lcs_values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Create a features DataFrame by selecting an `ngram_range`\n",
    "\n",
    "The paper suggests calculating the following features: containment *1-gram to 5-gram* and *longest common subsequence*. \n",
    "> In this exercise, you can choose to create even more features, for example from *1-gram to 7-gram* containment features and *longest common subsequence*. \n",
    "\n",
    "You'll want to create at least 6 features to choose from as you think about which to give to your final, classification model. Defining and comparing at least 6 different features allows you to discard any features that seem redundant, and choose to use the best features for your final model!\n",
    "\n",
    "In the below cell **define an n-gram range**; these will be the n's you use to create n-gram containment features. The rest of the feature creation code is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define an ngram range\n",
    "ngram_range = range(1,7)\n",
    "\n",
    "\n",
    "# The following code may take a minute to run, depending on your ngram_range\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "features_list = []\n",
    "\n",
    "# Create features in a features_df\n",
    "all_features = np.zeros((len(ngram_range)+1, len(complete_df)))\n",
    "\n",
    "# Calculate features for containment for ngrams in range\n",
    "i=0\n",
    "for n in ngram_range:\n",
    "    column_name = 'c_'+str(n)\n",
    "    features_list.append(column_name)\n",
    "    # create containment features\n",
    "    all_features[i]=np.squeeze(create_containment_features(complete_df, n))\n",
    "    i+=1\n",
    "\n",
    "# Calculate features for LCS_Norm Words \n",
    "features_list.append('lcs_word')\n",
    "all_features[i]= np.squeeze(create_lcs_features(complete_df))\n",
    "\n",
    "# create a features dataframe\n",
    "features_df = pd.DataFrame(np.transpose(all_features), columns=features_list)\n",
    "\n",
    "# Print all features/columns\n",
    "print()\n",
    "print('Features: ', features_list)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# print some results \n",
    "features_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Features\n",
    "\n",
    "You should use feature correlation across the *entire* dataset to determine which features are ***too*** **highly-correlated** with each other to include both features in a single model. For this analysis, you can use the *entire* dataset due to the small sample size we have. \n",
    "\n",
    "All of our features try to measure the similarity between two texts. Since our features are designed to measure similarity, it is expected that these features will be highly-correlated. Many classification models, for example a Naive Bayes classifier, rely on the assumption that features are *not* highly correlated; highly-correlated features may over-inflate the importance of a single feature. \n",
    "\n",
    "So, you'll want to choose your features based on which pairings have the lowest correlation. These correlation values range between 0 and 1; from low to high correlation, and are displayed in a [correlation matrix](https://www.displayr.com/what-is-a-correlation-matrix/), below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Create correlation matrix for just Features to determine different models to test\n",
    "corr_matrix = features_df.corr().abs().round(2)\n",
    "\n",
    "# display shows all of a dataframe\n",
    "display(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Create selected train/test data\n",
    "\n",
    "Complete the `train_test_data` function below. This function should take in the following parameters:\n",
    "* `complete_df`: A DataFrame that contains all of our processed text data, file info, datatypes, and class labels\n",
    "* `features_df`: A DataFrame of all calculated features, such as containment for ngrams, n= 1-5, and lcs values for each text file listed in the `complete_df` (this was created in the above cells)\n",
    "* `selected_features`: A list of feature column names,  ex. `['c_1', 'lcs_word']`, which will be used to select the final features in creating train/test sets of data.\n",
    "\n",
    "It should return two tuples:\n",
    "* `(train_x, train_y)`, selected training features and their corresponding class labels (0/1)\n",
    "* `(test_x, test_y)`, selected training features and their corresponding class labels (0/1)\n",
    "\n",
    "** Note: x and y should be arrays of feature values and numerical class labels, respectively; not DataFrames.**\n",
    "\n",
    "Looking at the above correlation matrix, you should decide on a **cutoff** correlation value, less than 1.0, to determine which sets of features are *too* highly-correlated to be included in the final training and test data. If you cannot find features that are less correlated than some cutoff value, it is suggested that you increase the number of features (longer n-grams) to choose from or use *only one or two* features in your final model to avoid introducing highly-correlated features.\n",
    "\n",
    "Recall that the `complete_df` has a `Datatype` column that indicates whether data should be `train` or `test` data; this should help you split the data appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Takes in dataframes and a list of selected features (column names) \n",
    "# and returns (train_x, train_y), (test_x, test_y)\n",
    "def train_test_data(complete_df, features_df, selected_features):\n",
    "    '''Gets selected training and test features from given dataframes, and \n",
    "       returns tuples for training and test features and their corresponding class labels.\n",
    "       :param complete_df: A dataframe with all of our processed text data, datatypes, and labels\n",
    "       :param features_df: A dataframe of all computed, similarity features\n",
    "       :param selected_features: An array of selected features that correspond to certain columns in `features_df`\n",
    "       :return: training and test features and labels: (train_x, train_y), (test_x, test_y)'''\n",
    "    \n",
    "    # get the training features\n",
    "    train_x = None\n",
    "    # And training class labels (0 or 1)\n",
    "    train_y = None\n",
    "    \n",
    "    # get the test features and labels\n",
    "    test_x = None\n",
    "    test_y = None\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "Below, test out your implementation and create the final train/test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "test_selection = list(features_df)[:2] # first couple columns as a test\n",
    "# test that the correct train/test data is created\n",
    "(train_x, train_y), (test_x, test_y) = train_test_data(complete_df, features_df, test_selection)\n",
    "\n",
    "# params: generated train/test data\n",
    "tests.test_data_split(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Select \"good\" features\n",
    "\n",
    "If you passed the test above, you can create your own train/test data, below. \n",
    "\n",
    "Define a list of features you'd like to include in your final mode, `selected_features`; this is a list of the features names you want to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Select your list of features, this should be column names from features_df\n",
    "# ex. ['c_1', 'lcs_word']\n",
    "selected_features = ['c_1', 'c_5', 'lcs_word']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = train_test_data(complete_df, features_df, selected_features)\n",
    "\n",
    "# check that division of samples seems correct\n",
    "# these should add up to 95 (100 - 5 original files)\n",
    "print('Training size: ', len(train_x))\n",
    "print('Test size: ', len(test_x))\n",
    "print()\n",
    "print('Training df sample: \\n', train_x[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: How did you decide on which features to include in your final model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Creating Final Data Files\n",
    "\n",
    "Now, you are almost ready to move on to training a model in SageMaker!\n",
    "\n",
    "You'll want to access your train and test data in SageMaker and upload it to S3. In this project, SageMaker will expect the following format for your train/test data:\n",
    "* Training and test data should be saved in one `.csv` file each, ex `train.csv` and `test.csv`\n",
    "* These files should have class  labels in the first column and features in the rest of the columns\n",
    "\n",
    "This format follows the practice, outlined in the [SageMaker documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html), which reads: \"Amazon SageMaker requires that a CSV file doesn't have a header record and that the target variable [class label] is in the first column.\"\n",
    "\n",
    "## EXERCISE: Create csv files\n",
    "\n",
    "Define a function that takes in x (features) and y (labels) and saves them to one `.csv` file at the path `data_dir/filename`.\n",
    "\n",
    "It may be useful to use pandas to merge your features and labels into one DataFrame and then convert that into a csv file. You can make sure to get rid of any incomplete rows, in a DataFrame, by using `dropna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_csv(x, y, filename, data_dir):\n",
    "    '''Merges features and labels and converts them into one csv file with labels in the first column.\n",
    "       :param x: Data features\n",
    "       :param y: Data labels\n",
    "       :param file_name: Name of csv file, ex. 'train.csv'\n",
    "       :param data_dir: The directory where files will be saved\n",
    "       '''\n",
    "    # make data dir, if it does not exist\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    \n",
    "    # nothing is returned, but a print statement indicates that the function has run\n",
    "    print('Path created: '+str(data_dir)+'/'+str(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "Test that your code produces the correct format for a `.csv` file, given some text features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "fake_x = [ [0.39814815, 0.0001, 0.19178082], \n",
    "           [0.86936937, 0.44954128, 0.84649123], \n",
    "           [0.44086022, 0., 0.22395833] ]\n",
    "\n",
    "fake_y = [0, 1, 1]\n",
    "\n",
    "make_csv(fake_x, fake_y, filename='to_delete.csv', data_dir='test_csv')\n",
    "\n",
    "# read in and test dimensions\n",
    "fake_df = pd.read_csv('test_csv/to_delete.csv', header=None)\n",
    "\n",
    "# check shape\n",
    "assert fake_df.shape==(3, 4), \\\n",
    "      'The file should have as many rows as data_points and as many columns as features+1 (for indices).'\n",
    "# check that first column = labels\n",
    "assert np.all(fake_df.iloc[:,0].values==fake_y), 'First column is not equal to the labels, fake_y.'\n",
    "print('Tests passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# delete the test csv file, generated above\n",
    "! rm -rf test_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've passed the tests above, run the following cell to create `train.csv` and `test.csv` files in a directory that you specify! This will save the data in a local directory. Remember the name of this directory because you will reference it again when uploading this data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# can change directory, if you want\n",
    "data_dir = 'plagiarism_data'\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "make_csv(train_x, train_y, filename='train.csv', data_dir=data_dir)\n",
    "make_csv(test_x, test_y, filename='test.csv', data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "Now that you've done some feature engineering and created some training and test data, you are ready to train and deploy a plagiarism classification model. The next notebook will utilize SageMaker resources to train and test a model that you design."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
