{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plagiarism Detection, Feature Engineering\n",
    "\n",
    "In this project, you will be tasked with building a plagiarism detector that examines an answer text file and performs binary classification; labeling that file as either plagiarized or not, depending on how similar that text file is to a provided, source text. \n",
    "\n",
    "Your first task will be to create some features that can then be used to train a classification model. This task will be broken down into a few discrete steps:\n",
    "\n",
    "* Clean and pre-process the data.\n",
    "* Define features for comparing the similarity of an answer text and a source text, and extract similarity features.\n",
    "* Select \"good\" features, by analyzing the correlations between different features.\n",
    "* Create train/test `.csv` files that hold the relevant features and class labels for train/test data points.\n",
    "\n",
    "In the _next_ notebook, Notebook 3, you'll use the features and `.csv` files you create in _this_ notebook to train a binary classification model in a SageMaker notebook instance.\n",
    "\n",
    "You'll be defining a few different similarity features, as outlined in [this paper](https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c412841_developing-a-corpus-of-plagiarised-short-answers/developing-a-corpus-of-plagiarised-short-answers.pdf), which should help you build a robust plagiarism detector!\n",
    "\n",
    "To complete this notebook, you'll have to complete all given exercises and answer all the questions in this notebook.\n",
    "> All your tasks will be clearly labeled **EXERCISE** and questions as **QUESTION**.\n",
    "\n",
    "It will be up to you to decide on the features to include in your final training and test data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Data\n",
    "\n",
    "The cell below will download the necessary, project data and extract the files into the folder `data/`.\n",
    "\n",
    "This data is a slightly modified version of a dataset created by Paul Clough (Information Studies) and Mark Stevenson (Computer Science), at the University of Sheffield. You can read all about the data collection and corpus, at [their university webpage](https://ir.shef.ac.uk/cloughie/resources/plagiarism_corpus.html). \n",
    "\n",
    "> **Citation for data**: Clough, P. and Stevenson, M. Developing A Corpus of Plagiarised Short Answers, Language Resources and Evaluation: Special Issue on Plagiarism and Authorship Analysis, In Press. [Download]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# you only need to run this cell if you have not yet downloaded the data\n",
    "# otherwise you may skip this cell or comment it out\n",
    "\n",
    "#!wget https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c4147f9_data/data.zip\n",
    "#!unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plagiarism dataset is made of multiple text files; each of these files has characteristics that are is summarized in a `.csv` file named `file_information.csv`, which we can read in using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>heavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task Category\n",
       "0  g0pA_taska.txt    a      non\n",
       "1  g0pA_taskb.txt    b      cut\n",
       "2  g0pA_taskc.txt    c    light\n",
       "3  g0pA_taskd.txt    d    heavy\n",
       "4  g0pA_taske.txt    e      non"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'data/file_information.csv'\n",
    "plagiarism_df = pd.read_csv(csv_file)\n",
    "\n",
    "# print out the first few rows of data info\n",
    "plagiarism_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Plagiarism\n",
    "\n",
    "Each text file is associated with one **Task** (task A-E) and one **Category** of plagiarism, which you can see in the above DataFrame.\n",
    "\n",
    "###  Tasks, A-E\n",
    "\n",
    "Each text file contains an answer to one short question; these questions are labeled as tasks A-E. For example, Task A asks the question: \"What is inheritance in object oriented programming?\"\n",
    "\n",
    "### Categories of plagiarism \n",
    "\n",
    "Each text file has an associated plagiarism label/category:\n",
    "\n",
    "**1. Plagiarized categories: `cut`, `light`, and `heavy`.**\n",
    "* These categories represent different levels of plagiarized answer texts. `cut` answers copy directly from a source text, `light` answers are based on the source text but include some light rephrasing, and `heavy` answers are based on the source text, but *heavily* rephrased (and will likely be the most challenging kind of plagiarism to detect).\n",
    "     \n",
    "**2. Non-plagiarized category: `non`.** \n",
    "* `non` indicates that an answer is not plagiarized; the Wikipedia source text is not used to create this answer.\n",
    "    \n",
    "**3. Special, source text category: `orig`.**\n",
    "* This is a specific category for the original, Wikipedia source text. We will use these files only for comparison purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pre-Process the Data\n",
    "\n",
    "In the next few cells, you'll be tasked with creating a new DataFrame of desired information about all of the files in the `data/` directory. This will prepare the data for feature extraction and for training a binary, plagiarism classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Convert categorical to numerical data\n",
    "\n",
    "You'll notice that the `Category` column in the data, contains string or categorical values, and to prepare these for feature extraction, we'll want to convert these into numerical values. Additionally, our goal is to create a binary classifier and so we'll need a binary class label that indicates whether an answer text is plagiarized (1) or not (0). Complete the below function `numerical_dataframe` that reads in a `file_information.csv` file by name, and returns a *new* DataFrame with a numerical `Category` column and a new `Class` column that labels each answer as plagiarized or not. \n",
    "\n",
    "Your function should return a new DataFrame with the following properties:\n",
    "\n",
    "* 4 columns: `File`, `Task`, `Category`, `Class`. The `File` and `Task` columns can remain unchanged from the original `.csv` file.\n",
    "* Convert all `Category` labels to numerical labels according to the following rules (a higher value indicates a higher degree of plagiarism):\n",
    "    * 0 = `non`\n",
    "    * 1 = `heavy`\n",
    "    * 2 = `light`\n",
    "    * 3 = `cut`\n",
    "    * -1 = `orig`, this is a special value that indicates an original file.\n",
    "* For the new `Class` column\n",
    "    * Any answer text that is not plagiarized (`non`) should have the class label `0`. \n",
    "    * Any plagiarized answer texts should have the class label `1`. \n",
    "    * And any `orig` texts will have a special label `-1`. \n",
    "\n",
    "### Expected output\n",
    "\n",
    "After running your function, you should get a DataFrame with rows that looks like the following: \n",
    "```\n",
    "\n",
    "        File\t     Task  Category  Class\n",
    "0\tg0pA_taska.txt\ta\t  0   \t0\n",
    "1\tg0pA_taskb.txt\tb\t  3   \t1\n",
    "2\tg0pA_taskc.txt\tc\t  2   \t1\n",
    "3\tg0pA_taskd.txt\td\t  1   \t1\n",
    "4\tg0pA_taske.txt\te\t  0\t   0\n",
    "...\n",
    "...\n",
    "99   orig_taske.txt    e     -1      -1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a csv file and return a transformed dataframe\n",
    "def numerical_dataframe(csv_file='data/file_information.csv'):\n",
    "    '''Reads in a csv file which is assumed to have `File`, `Category` and `Task` columns.\n",
    "       This function does two things: \n",
    "       1) converts `Category` column values to numerical values \n",
    "       2) Adds a new, numerical `Class` label column.\n",
    "       The `Class` column will label plagiarized answers as 1 and non-plagiarized as 0.\n",
    "       Source texts have a special label, -1.\n",
    "       :param csv_file: The directory for the file_information.csv file\n",
    "       :return: A dataframe with numerical categories and a new `Class` label column'''\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['Category'] = df['Category'].map({'non': 0, 'heavy': 1, 'light': 2, 'cut':3, 'orig': -1})\n",
    "    df['Class'] = df['Category'].map({0: 0, 1: 1, 2: 1, 3:1, -1: -1})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "Below are a couple of test cells. The first is an informal test where you can check that your code is working as expected by calling your function and printing out the returned result.\n",
    "\n",
    "The **second** cell below is a more rigorous test cell. The goal of a cell like this is to ensure that your code is working as expected, and to form any variables that might be used in _later_ tests/code, in this case, the data frame, `transformed_df`.\n",
    "\n",
    "> The cells in this notebook should be run in chronological order (the order they appear in the notebook). This is especially important for test cells.\n",
    "\n",
    "Often, later cells rely on the functions, imports, or variables defined in earlier cells. For example, some tests rely on previous tests to work.\n",
    "\n",
    "These tests do not test all cases, but they are a great way to check that you are on the right track!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g0pB_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g0pB_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g0pB_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g0pB_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g0pB_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class\n",
       "0  g0pA_taska.txt    a         0      0\n",
       "1  g0pA_taskb.txt    b         3      1\n",
       "2  g0pA_taskc.txt    c         2      1\n",
       "3  g0pA_taskd.txt    d         1      1\n",
       "4  g0pA_taske.txt    e         0      0\n",
       "5  g0pB_taska.txt    a         0      0\n",
       "6  g0pB_taskb.txt    b         0      0\n",
       "7  g0pB_taskc.txt    c         3      1\n",
       "8  g0pB_taskd.txt    d         2      1\n",
       "9  g0pB_taske.txt    e         1      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# informal testing, print out the results of a called function\n",
    "# create new `transformed_df`\n",
    "transformed_df = numerical_dataframe(csv_file ='data/file_information.csv')\n",
    "\n",
    "# check work\n",
    "# check that all categories of plagiarism have a class label = 1\n",
    "transformed_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n",
      "\n",
      "Example data: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class\n",
       "0  g0pA_taska.txt    a         0      0\n",
       "1  g0pA_taskb.txt    b         3      1\n",
       "2  g0pA_taskc.txt    c         2      1\n",
       "3  g0pA_taskd.txt    d         1      1\n",
       "4  g0pA_taske.txt    e         0      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cell that creates `transformed_df`, if tests are passed\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "# importing tests\n",
    "import problem_unittests as tests\n",
    "\n",
    "# test numerical_dataframe function\n",
    "tests.test_numerical_df(numerical_dataframe)\n",
    "\n",
    "# if above test is passed, create NEW `transformed_df`\n",
    "transformed_df = numerical_dataframe(csv_file ='data/file_information.csv')\n",
    "\n",
    "# check work\n",
    "print('\\nExample data: ')\n",
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing & Splitting Data\n",
    "\n",
    "Recall that the goal of this project is to build a plagiarism classifier. At it's heart, this task is a comparison text; one that looks at a given answer and a source text, compares them and predicts whether an answer has plagiarized from the source. To effectively do this comparison, and train a classifier we'll need to do a few more things: pre-process all of our text data and prepare the text files (in this case, the 95 answer files and 5 original source files) to be easily compared, and split our data into a `train` and `test` set that can be used to train a classifier and evaluate it, respectively. \n",
    "\n",
    "To this end, you've been provided code that adds  additional information to your `transformed_df` from above. The next two cells need not be changed; they add two additional columns to the `transformed_df`:\n",
    "\n",
    "1. A `Text` column; this holds all the lowercase text for a `File`, with extraneous punctuation removed.\n",
    "2. A `Datatype` column; this is a string value `train`, `test`, or `orig` that labels a data point as part of our train or test set\n",
    "\n",
    "The details of how these additional columns are created can be found in the `helpers.py` file in the project directory. You're encouraged to read through that file to see exactly how text is processed and how data is split.\n",
    "\n",
    "Run the cells below to get a `complete_df` that has all the information you need to proceed with plagiarism detection and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept of object orien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>pagerank is a link analysis algorithm used by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the vector space model also called term vector...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem was names after rev thomas bayes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is an algorithm design tec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class  \\\n",
       "0  g0pA_taska.txt    a         0      0   \n",
       "1  g0pA_taskb.txt    b         3      1   \n",
       "2  g0pA_taskc.txt    c         2      1   \n",
       "3  g0pA_taskd.txt    d         1      1   \n",
       "4  g0pA_taske.txt    e         0      0   \n",
       "\n",
       "                                                Text  \n",
       "0  inheritance is a basic concept of object orien...  \n",
       "1  pagerank is a link analysis algorithm used by ...  \n",
       "2  the vector space model also called term vector...  \n",
       "3  bayes theorem was names after rev thomas bayes...  \n",
       "4  dynamic programming is an algorithm design tec...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import helpers \n",
    "\n",
    "# create a text column \n",
    "text_df = helpers.create_text_column(transformed_df)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample processed text:\n",
      "\n",
      " inheritance is a basic concept of object oriented programming where the basic idea is to create new classes that add extra detail to existing classes this is done by allowing the new classes to reuse the methods and variables of the existing classes and new methods and classes are added to specialise the new class inheritance models the is kind of relationship between entities or objects  for example postgraduates and undergraduates are both kinds of student this kind of relationship can be visualised as a tree structure where student would be the more general root node and both postgraduate and undergraduate would be more specialised extensions of the student node or the child nodes  in this relationship student would be known as the superclass or parent class whereas  postgraduate would be known as the subclass or child class because the postgraduate class extends the student class  inheritance can occur on several layers where if visualised would display a larger tree structure for example we could further extend the postgraduate node by adding two extra extended classes to it called  msc student and phd student as both these types of student are kinds of postgraduate student this would mean that both the msc student and phd student classes would inherit methods and variables from both the postgraduate and student classes  \n"
     ]
    }
   ],
   "source": [
    "# after running the cell above\n",
    "# check out the processed text for a single file, by row index\n",
    "row_idx = 0 # feel free to change this index\n",
    "\n",
    "sample_text = text_df.iloc[0]['Text']\n",
    "\n",
    "print('Sample processed text:\\n\\n', sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets\n",
    "\n",
    "The next cell will add a `Datatype` column to a given DataFrame to indicate if the record is: \n",
    "* `train` - Training data, for model training.\n",
    "* `test` - Testing data, for model evaluation.\n",
    "* `orig` - The task's original answer from wikipedia.\n",
    "\n",
    "### Stratified sampling\n",
    "\n",
    "The given code uses a helper function which you can view in the `helpers.py` file in the main project directory. This implements [stratified random sampling](https://en.wikipedia.org/wiki/Stratified_sampling) to randomly split data by task & plagiarism amount. Stratified sampling ensures that we get training and test data that is fairly evenly distributed across task & plagiarism combinations. Approximately 26% of the data is held out for testing and 74% of the data is used for training.\n",
    "\n",
    "The function **train_test_dataframe** takes in a DataFrame that it assumes has `Task` and `Category` columns, and, returns a modified frame that indicates which `Datatype` (train, test, or orig) a file falls into. This sampling will change slightly based on a passed in *random_seed*. Due to a small sample size, this stratified random sampling will provide more stable results for a binary plagiarism classifier. Stability here is smaller *variance* in the accuracy of classifier, given a random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Datatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept of object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>pagerank is a link analysis algorithm used by ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the vector space model also called term vector...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem was names after rev thomas bayes...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is an algorithm design tec...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g0pB_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept in object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g0pB_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pagerank pr refers to both the concept and the...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g0pB_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>vector space model is an algebraic model for r...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g0pB_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem relates the conditional and marg...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g0pB_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dynamic programming is a method for solving ma...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class  \\\n",
       "0  g0pA_taska.txt    a         0      0   \n",
       "1  g0pA_taskb.txt    b         3      1   \n",
       "2  g0pA_taskc.txt    c         2      1   \n",
       "3  g0pA_taskd.txt    d         1      1   \n",
       "4  g0pA_taske.txt    e         0      0   \n",
       "5  g0pB_taska.txt    a         0      0   \n",
       "6  g0pB_taskb.txt    b         0      0   \n",
       "7  g0pB_taskc.txt    c         3      1   \n",
       "8  g0pB_taskd.txt    d         2      1   \n",
       "9  g0pB_taske.txt    e         1      1   \n",
       "\n",
       "                                                Text Datatype  \n",
       "0  inheritance is a basic concept of object orien...    train  \n",
       "1  pagerank is a link analysis algorithm used by ...     test  \n",
       "2  the vector space model also called term vector...    train  \n",
       "3  bayes theorem was names after rev thomas bayes...    train  \n",
       "4  dynamic programming is an algorithm design tec...    train  \n",
       "5  inheritance is a basic concept in object orien...    train  \n",
       "6  pagerank pr refers to both the concept and the...    train  \n",
       "7  vector space model is an algebraic model for r...     test  \n",
       "8  bayes theorem relates the conditional and marg...    train  \n",
       "9  dynamic programming is a method for solving ma...     test  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 1 # can change; set for reproducibility\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import helpers\n",
    "\n",
    "# create new df with Datatype (train, test, orig) column\n",
    "# pass in `text_df` from above to create a complete dataframe, with all the information you need\n",
    "complete_df = helpers.train_test_dataframe(text_df, random_seed=random_seed)\n",
    "\n",
    "# check results\n",
    "complete_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Plagiarism\n",
    "\n",
    "Now that you've prepared this data and created a `complete_df` of information, including the text and class associated with each file, you can move on to the task of extracting similarity features that will be useful for plagiarism classification. \n",
    "\n",
    "> Note: The following code exercises, assume that the `complete_df` as it exists now, will **not** have its existing columns modified. \n",
    "\n",
    "The `complete_df` should always include the columns: `['File', 'Task', 'Category', 'Class', 'Text', 'Datatype']`. You can add additional columns, and you can create any new DataFrames you need by copying the parts of the `complete_df` as long as you do not modify the existing values, directly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Similarity Features \n",
    "\n",
    "One of the ways we might go about detecting plagiarism, is by computing **similarity features** that measure how similar a given answer text is as compared to the original wikipedia source text (for a specific task, a-e). The similarity features you will use are informed by [this paper on plagiarism detection](https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c412841_developing-a-corpus-of-plagiarised-short-answers/developing-a-corpus-of-plagiarised-short-answers.pdf). \n",
    "> In this paper, researchers created features called **containment** and **longest common subsequence**. \n",
    "\n",
    "Using these features as input, you will train a model to distinguish between plagiarized and not-plagiarized text files.\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "Let's talk a bit more about the features we want to include in a plagiarism detection model and how to calculate such features. In the following explanations, I'll refer to a submitted text file as a **Student Answer Text (A)** and the original, wikipedia source file (that we want to compare that answer to) as the **Wikipedia Source Text (S)**.\n",
    "\n",
    "### Containment\n",
    "\n",
    "Your first task will be to create **containment features**. To understand containment, let's first revisit a definition of [n-grams](https://en.wikipedia.org/wiki/N-gram). An *n-gram* is a sequential word grouping. For example, in a line like \"bayes rule gives us a way to combine prior knowledge with new information,\" a 1-gram is just one word, like \"bayes.\" A 2-gram might be \"bayes rule\" and a 3-gram might be \"combine prior knowledge.\"\n",
    "\n",
    "> Containment is defined as the **intersection** of the n-gram word count of the Wikipedia Source Text (S) with the n-gram word count of the Student  Answer Text (S) *divided* by the n-gram word count of the Student Answer Text.\n",
    "\n",
    "$$ \\frac{\\sum{count(\\text{ngram}_{A}) \\cap count(\\text{ngram}_{S})}}{\\sum{count(\\text{ngram}_{A})}} $$\n",
    "\n",
    "If the two texts have no n-grams in common, the containment will be 0, but if _all_ their n-grams intersect then the containment will be 1. Intuitively, you can see how having longer n-gram's in common, might be an indication of cut-and-paste plagiarism. In this project, it will be up to you to decide on the appropriate `n` or several `n`'s to use in your final model.\n",
    "\n",
    "### EXERCISE: Create containment features\n",
    "\n",
    "Given the `complete_df` that you've created, you should have all the information you need to compare any Student  Answer Text (A) with its appropriate Wikipedia Source Text (S). An answer for task A should be compared to the source text for task A, just as answers to tasks B, C, D, and E should be compared to the corresponding original source text.\n",
    "\n",
    "In this exercise, you'll complete the function, `calculate_containment` which calculates containment based upon the following parameters:\n",
    "* A given DataFrame, `df` (which is assumed to be the `complete_df` from above)\n",
    "* An `answer_filename`, such as 'g0pB_taskd.txt' \n",
    "* An n-gram length, `n`\n",
    "\n",
    "### Containment calculation\n",
    "\n",
    "The general steps to complete this function are as follows:\n",
    "1. From *all* of the text files in a given `df`, create an array of n-gram counts; it is suggested that you use a [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) for this purpose.\n",
    "2. Get the processed answer and source texts for the given `answer_filename`.\n",
    "3. Calculate the containment between an answer and source text according to the following equation.\n",
    "\n",
    "    >$$ \\frac{\\sum{count(\\text{ngram}_{A}) \\cap count(\\text{ngram}_{S})}}{\\sum{count(\\text{ngram}_{A})}} $$\n",
    "    \n",
    "4. Return that containment value.\n",
    "\n",
    "You are encouraged to write any helper functions that you need to complete the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ngram containment for one answer file/source file pair in a df\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def containment_value(answer, orig, n):\n",
    "    orig_ngrams = get_grams_from_text(orig, n)\n",
    "    answer_ngrams = get_grams_from_text(answer, n)\n",
    "    ins_ngrams = orig_ngrams.intersection(answer_ngrams)\n",
    "    \n",
    "    print(len(orig_ngrams), len(answer_ngrams), len(ins_ngrams))\n",
    "    print(ins_ngrams)\n",
    "\n",
    "    result = len(ins_ngrams) / len(answer_ngrams)\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_containment_simple(df, n, answer_filename):\n",
    "    task = df[df['File'] == answer_filename]['Task'].values[0]\n",
    "    answer = df[df['File'] == answer_filename]['Text'].values[0]\n",
    "    source = df[(df['Task'] == task) & (df['Category'] == -1)]['Text'].values[0]\n",
    "    source_filename = df[(df['Task'] == task) & (df['Category'] == -1)]['File'].values[0]\n",
    "    answer_wds = set(answer.split())\n",
    "    source_wds = set(source.split())\n",
    "    answer_ngrams = len(answer_wds)\n",
    "    source_ngrams = len(source_wds)\n",
    "    intersect_wds = answer_wds.intersection(source_wds)\n",
    "    intersect_ngrams = len(intersect_wds)\n",
    "    print(sorted(list(intersect_wds)), len(intersect_wds))\n",
    "    print(sorted(list(answer_wds)), len(answer_wds))\n",
    "    print(sorted(list(source_wds)), len(source_wds))\n",
    "    \n",
    "    return intersect_ngrams / answer_ngrams\n",
    "\n",
    "def calculate_containment_bad(df, n, answer_filename):\n",
    "    '''Calculates the containment between a given answer text and its associated source text.\n",
    "       This function creates a count of ngrams (of a size, n) for each text file in our data.\n",
    "       Then calculates the containment by finding the ngram count for a given answer text, \n",
    "       and its associated source text, and calculating the normalized intersection of those counts.\n",
    "       :param df: A dataframe with columns,\n",
    "           'File', 'Task', 'Category', 'Class', 'Text', and 'Datatype'\n",
    "       :param n: An integer that defines the ngram size\n",
    "       :param answer_filename: A filename for an answer text in the df, ex. 'g0pB_taskd.txt'\n",
    "       :return: A single containment value that represents the similarity\n",
    "           between an answer text and its source text.\n",
    "    '''\n",
    "    task = df[df['File'] == answer_filename]['Task'].values[0]\n",
    "    \n",
    "    text = df[df['File'] == answer_filename]['Text'].values[0]\n",
    "    orig = df[(df['Task'] == task) & (df['Category'] == -1)]['Text'].values[0]\n",
    "    source_filename = df[(df['Task'] == task) & (df['Category'] == -1)]['File'].values[0]\n",
    "    \n",
    "\n",
    "    orig_ngram_array = (all_ngrams[0].toarray().ravel() > 0).astype(int)\n",
    "    text_ngram_array = (all_ngrams[1].toarray().ravel() > 0).astype(int)\n",
    "    #print(text_ngram_array)\n",
    "    #print(orig_ngram_array)\n",
    "    \n",
    "\n",
    "    text_ngrams = sum(text_ngram_array)\n",
    "    orig_ngrams = sum(orig_ngram_array)\n",
    "    intersect_array = text_ngram_array * orig_ngram_array \n",
    "    #print(intersect_array)\n",
    "    \n",
    "    inters_ngrams = sum(intersect_array)\n",
    "\n",
    "    return inters_ngrams / text_ngrams\n",
    "\n",
    "def calculate_containment(df, n, answer_filename):\n",
    "    '''Calculates the containment between a given answer text and its associated source text.\n",
    "       This function creates a count of ngrams (of a size, n) for each text file in our data.\n",
    "       Then calculates the containment by finding the ngram count for a given answer text, \n",
    "       and its associated source text, and calculating the normalized intersection of those counts.\n",
    "       :param df: A dataframe with columns,\n",
    "           'File', 'Task', 'Category', 'Class', 'Text', and 'Datatype'\n",
    "       :param n: An integer that defines the ngram size\n",
    "       :param answer_filename: A filename for an answer text in the df, ex. 'g0pB_taskd.txt'\n",
    "       :return: A single containment value that represents the similarity\n",
    "           between an answer text and its source text.\n",
    "    '''\n",
    "    vectorizer = CountVectorizer(analyzer='word', ngram_range=(n, n))\n",
    "    corpus = df['Text']\n",
    "    all_ngrams = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    task = df[df['File'] == answer_filename]['Task'].values[0]\n",
    "    \n",
    "    answer = df[df['File'] == answer_filename]['Text'].values[0]\n",
    "    source = df[(df['Task'] == task) & (df['Category'] == -1)]['Text'].values[0]\n",
    "    source_index = df.index[(df['Task'] == task) & (df['Category'] == -1)]\n",
    "    answer_index = df.index[df['File'] == answer_filename]\n",
    "    \n",
    "\n",
    "    source_ngram_array = (all_ngrams[source_index].toarray().ravel() > 0).astype(int)\n",
    "    answer_ngram_array = (all_ngrams[answer_index].toarray().ravel() > 0).astype(int)\n",
    "    \n",
    "\n",
    "    answer_ngrams = sum(answer_ngram_array)\n",
    "    source_ngrams = sum(source_ngram_array)\n",
    "    intersect_array = np.minimum(answer_ngram_array, source_ngram_array)\n",
    "    #print(intersect_array)\n",
    "    \n",
    "    inters_ngrams = sum(intersect_array)\n",
    "\n",
    "    return inters_ngrams / answer_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3617021276595745"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_containment(complete_df, 1, 'g0pA_taska.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "After you've implemented the containment function, you can test out its behavior. \n",
    "\n",
    "The cell below iterates through the first few files, and calculates the original category _and_ containment values for a specified n and file.\n",
    "\n",
    ">If you've implemented this correctly, you should see that the non-plagiarized have low or close to 0 containment values and that plagiarized examples have higher containment values, closer to 1.\n",
    "\n",
    "Note what happens when you change the value of n. I recommend applying your code to multiple files and comparing the resultant containment values. You should see that the highest containment values correspond to files with the highest category (`cut`) of plagiarism level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original category values: \n",
      " [0, 3, 2, 1, 0]\n",
      "\n",
      "3-gram containment values: \n",
      " [0.00975609756097561, 0.9635416666666666, 0.6084905660377359, 0.15934065934065933, 0.032432432432432434]\n"
     ]
    }
   ],
   "source": [
    "# select a value for n\n",
    "n = 3\n",
    "\n",
    "# indices for first few files\n",
    "test_indices = range(5)\n",
    "\n",
    "# iterate through files and calculate containment\n",
    "category_vals = []\n",
    "containment_vals = []\n",
    "for i in test_indices:\n",
    "    # get level of plagiarism for a given file index\n",
    "    category_vals.append(complete_df.loc[i, 'Category'])\n",
    "    # calculate containment for given file and n\n",
    "    filename = complete_df.loc[i, 'File']\n",
    "    c = calculate_containment(complete_df, n, filename)\n",
    "    containment_vals.append(c)\n",
    "\n",
    "# print out result, does it make sense?\n",
    "print('Original category values: \\n', category_vals)\n",
    "print()\n",
    "print(str(n)+'-gram containment values: \\n', containment_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39814814814814814, 1.0, 0.8693693693693694, 0.5935828877005348]\n",
      "[0.3617021276595745, 1.0, 0.8487394957983193, 0.5225225225225225]\n",
      "[0.009345794392523364, 0.9641025641025641, 0.6136363636363636, 0.15675675675675677]\n",
      "[0.00975609756097561, 0.9635416666666666, 0.6084905660377359, 0.15934065934065933]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "n=1 calculations are incorrect. Double check the intersection calculation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cacba0005ac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# test containment calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# params: complete_df from before, and containment function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_containment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplete_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_containment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/ML_SageMaker_Studies/Project_Plagiarism_Detection/problem_unittests.py\u001b[0m in \u001b[0;36mtest_containment\u001b[0;34m(complete_df, containment_fn)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# check correct results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_1gram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-04\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;34m'n=1 calculations are incorrect. Double check the intersection calculation.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;31m# check correct results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_3gram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-04\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: n=1 calculations are incorrect. Double check the intersection calculation."
     ]
    }
   ],
   "source": [
    "# run this test cell\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# test containment calculation\n",
    "# params: complete_df from before, and containment function\n",
    "tests.test_containment(complete_df, calculate_containment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1: Why can we calculate containment features across *all* data (training & test), prior to splitting the DataFrame for modeling? That is, what about the containment calculation means that the test and training data do not influence each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** This is the calculation of a feature that is independent from the fact whether the data is labeled or not\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Longest Common Subsequence\n",
    "\n",
    "Containment a good way to find overlap in word usage between two documents; it may help identify cases of cut-and-paste as well as paraphrased levels of plagiarism. Since plagiarism is a fairly complex task with varying levels, it's often useful to include other measures of similarity. The paper also discusses a feature called **longest common subsequence**.\n",
    "\n",
    "> The longest common subsequence is the longest string of words (or letters) that are *the same* between the Wikipedia Source Text (S) and the Student Answer Text (A). This value is also normalized by dividing by the total number of words (or letters) in the  Student Answer Text. \n",
    "\n",
    "In this exercise, we'll ask you to calculate the longest common subsequence of words between two texts.\n",
    "\n",
    "### EXERCISE: Calculate the longest common subsequence\n",
    "\n",
    "Complete the function `lcs_norm_word`; this should calculate the *longest common subsequence* of words between a Student Answer Text and corresponding Wikipedia Source Text. \n",
    "\n",
    "It may be helpful to think of this in a concrete example. A Longest Common Subsequence (LCS) problem may look as follows:\n",
    "* Given two texts: text A (answer text) of length n, and string S (original source text) of length m. Our goal is to produce their longest common subsequence of words: the longest sequence of words that appear left-to-right in both texts (though the words don't have to be in continuous order).\n",
    "* Consider:\n",
    "    * A = \"i think pagerank is a link analysis algorithm used by google that uses a system of weights attached to each element of a hyperlinked set of documents\"\n",
    "    * S = \"pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents\"\n",
    "\n",
    "* In this case, we can see that the start of each sentence of fairly similar, having overlap in the sequence of words, \"pagerank is a link analysis algorithm used by\" before diverging slightly. Then we **continue moving left -to-right along both texts** until we see the next common sequence; in this case it is only one word, \"google\". Next we find \"that\" and \"a\" and finally the same ending \"to each element of a hyperlinked set of documents\".\n",
    "* Below, is a clear visual of how these sequences were found, sequentially, in each text.\n",
    "\n",
    "<img src='notebook_ims/common_subseq_words.png' width=40% />\n",
    "\n",
    "* Now, those words appear in left-to-right order in each document, sequentially, and even though there are some words in between, we count this as the longest common subsequence between the two texts. \n",
    "* If I count up each word that I found in common I get the value 20. **So, LCS has length 20**. \n",
    "* Next, to normalize this value, divide by the total length of the student answer; in this example that length is only 27. **So, the function `lcs_norm_word` should return the value `20/27` or about `0.7408`.**\n",
    "\n",
    "In this way, LCS is a great indicator of cut-and-paste plagiarism or if someone has referenced the same source text multiple times in an answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCS, dynamic programming\n",
    "\n",
    "If you read through the scenario above, you can see that this algorithm depends on looking at two texts and comparing them word by word. You can solve this problem in multiple ways. First, it may be useful to `.split()` each text into lists of comma separated words to compare. Then, you can iterate through each word in the texts and compare them, adding to your value for LCS as you go. \n",
    "\n",
    "The method I recommend for implementing an efficient LCS algorithm is: using a matrix and dynamic programming. **Dynamic programming** is all about breaking a larger problem into a smaller set of subproblems, and building up a complete result without having to repeat any subproblems. \n",
    "\n",
    "This approach assumes that you can split up a large LCS task into a combination of smaller LCS tasks. Let's look at a simple example that compares letters:\n",
    "\n",
    "* A = \"ABCD\"\n",
    "* S = \"BD\"\n",
    "\n",
    "We can see right away that the longest subsequence of _letters_ here is 2 (B and D are in sequence in both strings). And we can calculate this by looking at relationships between each letter in the two strings, A and S.\n",
    "\n",
    "Here, I have a matrix with the letters of A on top and the letters of S on the left side:\n",
    "\n",
    "<img src='notebook_ims/matrix_1.png' width=40% />\n",
    "\n",
    "This starts out as a matrix that has as many columns and rows as letters in the strings S and O **+1** additional row and column, filled with zeros on the top and left sides. So, in this case, instead of a 2x4 matrix it is a 3x5.\n",
    "\n",
    "Now, we can fill this matrix up by breaking it into smaller LCS problems. For example, let's first look at the shortest substrings: the starting letter of A and S. We'll first ask, what is the Longest Common Subsequence between these two letters \"A\" and \"B\"? \n",
    "\n",
    "**Here, the answer is zero and we fill in the corresponding grid cell with that value.**\n",
    "\n",
    "<img src='notebook_ims/matrix_2.png' width=30% />\n",
    "\n",
    "Then, we ask the next question, what is the LCS between \"AB\" and \"B\"?\n",
    "\n",
    "**Here, we have a match, and can fill in the appropriate value 1**.\n",
    "\n",
    "<img src='notebook_ims/matrix_3_match.png' width=25% />\n",
    "\n",
    "If we continue, we get to a final matrix that looks as follows, with a **2** in the bottom right corner.\n",
    "\n",
    "<img src='notebook_ims/matrix_6_complete.png' width=25% />\n",
    "\n",
    "The final LCS will be that value **2** *normalized* by the number of n-grams in A. So, our normalized value is 2/4 = **0.5**.\n",
    "\n",
    "### The matrix rules\n",
    "\n",
    "One thing to notice here is that, you can efficiently fill up this matrix one cell at a time. Each grid cell only depends on the values in the grid cells that are directly on top and to the left of it, or on the diagonal/top-left. The rules are as follows:\n",
    "* Start with a matrix that has one extra row and column of zeros.\n",
    "* As you traverse your string:\n",
    "    * If there is a match, fill that grid cell with the value to the top-left of that cell *plus* one. So, in our case, when we found a matching B-B, we added +1 to the value in the top-left of the matching cell, 0.\n",
    "    * If there is not a match, take the *maximum* value from either directly to the left or the top cell, and carry that value over to the non-match cell.\n",
    "\n",
    "<img src='notebook_ims/matrix_rules.png' width=50% />\n",
    "\n",
    "After completely filling the matrix, **the bottom-right cell will hold the non-normalized LCS value**.\n",
    "\n",
    "This matrix treatment can be applied to a set of words instead of letters. Your function should apply this to the words in two texts and return the normalized LCS value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the normalized LCS given an answer text and a source text\n",
    "\n",
    "def lcs_norm_word(answer_text, source_text):\n",
    "    '''Computes the longest common subsequence of words in two texts; returns a normalized value.\n",
    "       :param answer_text: The pre-processed text for an answer text\n",
    "       :param source_text: The pre-processed text for an answer's associated source text\n",
    "       :return: A normalized LCS value'''\n",
    "    print(\"ANSWER\")\n",
    "    print(answer_text)\n",
    "    print(\"SOURCE\")\n",
    "    print(source_text)\n",
    "    source_sequence = []\n",
    "    answer_words = answer_text.split()\n",
    "    source_words = source_text.split()\n",
    "    answer_columns = len(answer_words)\n",
    "    source_rows = len(source_words)\n",
    "    lcs_array = np.zeros((source_rows + 1, answer_columns + 1))\n",
    "    source_pointer, answer_pointer = 0, 0\n",
    "    max_row_found, max_col_found = 0, 0\n",
    "    answer_sequence = []\n",
    "    for source_row in range(1, source_rows + 1):\n",
    "        matches_in_row = 0\n",
    "        source_pointer = source_row - 1\n",
    "        found_in_row = False\n",
    "        for answer_column in range(1, answer_columns + 1):\n",
    "            answer_pointer = answer_column - 1\n",
    "            current_val = max(lcs_array[source_row][answer_column - 1], lcs_array[source_row - 1][answer_column])\n",
    "            \n",
    "            if (source_pointer) < len(source_words):\n",
    "                source_word = source_words[source_pointer]\n",
    "                answer_word = answer_words[answer_pointer]\n",
    "                if source_word == answer_word:\n",
    "                    current_val = lcs_array[source_row-1][answer_column - 1] + 1\n",
    "                    max_row_found, max_col_found = source_row, answer_column\n",
    "                    if not found_in_row:\n",
    "                        source_sequence.append(source_word)\n",
    "                    found_in_row = True\n",
    "                    \n",
    "            lcs_array[source_row][answer_column] = current_val\n",
    "    \n",
    "    lcs_before_norm = lcs_array[source_rows][answer_columns]\n",
    "    lcs_norm = lcs_before_norm / answer_columns \n",
    "    source_str = \" \".join(source_sequence)\n",
    "    print(f'SOURCE SEQUENCE: {source_str}')\n",
    "    print(f'{lcs_before_norm}, {len(source_sequence)} finish at source in {source_row} and answer in {answer_column}')\n",
    "    return lcs_norm\n",
    "\n",
    "def lcs_norm_word_old(answer_text, source_text):\n",
    "    '''Computes the longest common subsequence of words in two texts; returns a normalized value.\n",
    "       :param answer_text: The pre-processed text for an answer text\n",
    "       :param source_text: The pre-processed text for an answer's associated source text\n",
    "       :return: A normalized LCS value'''\n",
    "    print(\"ANSWER\")\n",
    "    print(answer_text)\n",
    "    print(\"SOURCE\")\n",
    "    print(source_text)\n",
    "    source_sequence = []\n",
    "    answer_words = answer_text.split()\n",
    "    source_words = source_text.split()\n",
    "    answer_columns = len(answer_words)\n",
    "    source_rows = len(source_words)\n",
    "    lcs_array = np.zeros((source_rows + 1, answer_columns + 1))\n",
    "    source_pointer, answer_pointer = 0, 0\n",
    "    max_row_found, max_col_found = 0, 0\n",
    "    answer_sequence = []\n",
    "    for source_row in range(1, source_rows + 1):\n",
    "        matches_in_row = 0\n",
    "        source_pointer = source_row - 1\n",
    "        found_in_row = False\n",
    "        for answer_column in range(1, answer_columns + 1):\n",
    "            answer_pointer = answer_column - 1\n",
    "            current_max = max(lcs_array[source_row][answer_column - 1], lcs_array[source_row - 1][answer_column])\n",
    "            \n",
    "            if (source_pointer) < len(source_words):\n",
    "                source_word = source_words[source_pointer]\n",
    "                answer_word = answer_words[answer_pointer]\n",
    "                if source_word == answer_word and not found_in_row:\n",
    "                    current_max += 1\n",
    "                    found_in_row = True\n",
    "                    max_row_found, max_col_found = source_row, answer_column\n",
    "                    source_sequence.append(source_word)\n",
    "            lcs_array[source_row][answer_column] = current_max\n",
    "   \n",
    "    lcs_before_norm = lcs_array[source_rows][answer_columns]\n",
    "    lcs_norm = lcs_before_norm / answer_columns \n",
    "    source_str = \" \".join(source_sequence)\n",
    "    print(f'SOURCE SEQUENCE: {source_str}')\n",
    "    print(f'{lcs_before_norm} finish at source in {source_row} and answer in {answer_column}')\n",
    "    return lcs_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "Let's start by testing out your code on the example given in the initial description.\n",
    "\n",
    "In the below cell, we have specified strings A (answer text) and S (original source text). We know that these texts have 20 words in common and the submitted answer is 27 words long, so the normalized, longest common subsequence should be 20/27.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER\n",
      "i think pagerank is a link analysis algorithm used by google that uses a system of weights attached to each element of a hyperlinked set of documents\n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents\n",
      "SOURCE SEQUENCE: pagerank is a link analysis algorithm used by google that a to each element of a hyperlinked set of documents\n",
      "20.0, 20 finish at source in 27 and answer in 27\n",
      "LCS =  0.7407407407407407\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# Run the test scenario from above\n",
    "# does your function return the expected value?\n",
    "\n",
    "A = \"i think pagerank is a link analysis algorithm used by google that uses a system of weights attached to each element of a hyperlinked set of documents\"\n",
    "S = \"pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents\"\n",
    "# COMMON = pagerank is a link analysis algorithm used by google that \n",
    "# calculate LCS\n",
    "lcs = lcs_norm_word(A, S)\n",
    "#lcs = lcs_norm_word_nf(A, S)\n",
    "\n",
    "print('LCS = ', lcs)\n",
    "\n",
    "\n",
    "# expected value test\n",
    "assert lcs==20/27., \"Incorrect LCS value, expected about 0.7408, got \"+str(lcs)\n",
    "\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell runs a more rigorous test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER\n",
      "inheritance in object oriented programming is where a new class is formed using classes which have allready been defined these classes have have some of the behavior and attributes which where existent in the classes that it inherited from the peropos of inheritance in object oriented programming is to minimize the reuse of existing code without modification  inheritance allowes classes to be categorized similer to the way humans catagorize it also provides a way to generalize du to the is a relationship between classes for example a cow is a generalization of animal similarly so are pigs  cheaters  defeining classes in this way allows us to define attributes and behaviours which are commen to all animals in one class so cheaters would natuarly inheart properities commen to all animals  the advantage of inheritance is that classes which would otherwise have alot of similar code  can instead shair the same code thus reducing the complexity of the program inheritance therefore can also be refered to as polymorphism which is where many pieces of code are controled by shared control code  inheritance can be accomplished by overriding methods in its ancestor or by adding new methods  \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a way to new classes of which are using classes that have been defined the inheritance in for the new classes as classes or attributes and behavior of the existing classes which are to as classes or ancestor classes it is to reuse existing code or modification inheritance provides the for by in is a of to by of generalization is is to a a can be and to be its inheritance is also generalization the is a a between classes of for a is a generalization of and many one can to be of are is a all the to all as a for the of a advantage of inheritance is that similar can a of code reducing the complexity of the program inheritance therefore a polymorphism which many pieces of code by shared control code inheritance is accomplished by overriding one or methods by ancestor or by adding new methods to by ancestor inheritance or inheritance a that is to the\n",
      "83.0, 169 finish at source in 308 and answer in 194\n",
      "ANSWER\n",
      "inheritance is a basic concept of object oriented programming where the basic idea is to create new classes that add extra detail to existing classes this is done by allowing the new classes to reuse the methods and variables of the existing classes and new methods and classes are added to specialise the new class inheritance models the is kind of relationship between entities or objects  for example postgraduates and undergraduates are both kinds of student this kind of relationship can be visualised as a tree structure where student would be the more general root node and both postgraduate and undergraduate would be more specialised extensions of the student node or the child nodes  in this relationship student would be known as the superclass or parent class whereas  postgraduate would be known as the subclass or child class because the postgraduate class extends the student class  inheritance can occur on several layers where if visualised would display a larger tree structure for example we could further extend the postgraduate node by adding two extra extended classes to it called  msc student and phd student as both these types of student are kinds of postgraduate student this would mean that both the msc student and phd student classes would inherit methods and variables from both the postgraduate and student classes  \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a to new classes of are called objects classes that the inheritance concept in for the new classes known as classes or inherit and of the existing classes are to as classes or classes it is to reuse existing or inheritance the for by in is a of to by of is known entities is to a a can be and to be inheritance is called because the is a a between classes of objects for a is a of and can to be of are is a inherit the to as a for the of a of inheritance is that can a of the of the inheritance a called of by inheritance is by or more methods by or by adding new methods to by inheritance or inheritance a that is to the\n",
      "42.0, 140 finish at source in 308 and answer in 219\n",
      "Calculated: 0.1917808219178082, Expected: 0.1917808219178082\n",
      "ANSWER\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google  the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank  other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm  \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e the pagerank is a of google and the pagerank s the is to and to google google on the from the in google in for of the the in for google pagerank pagerank on the of the web by its link as of page s value in google a link from page a to page as a by page a for page google the of links a page it also the page that the by pages that and to other pages in other words a pagerank from a the other pages on the world wide web a page is a to a page as a of the pagerank of a page is and on the and pagerank of pages that link to it links a page that is to by pages with pagerank a links to a web page is for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in to and google other factors influence pagerank pagerank page and s in the pagerank to be to and to pagerank and to links from documents with pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com the ibm clever project and the trustrank algorithm\n",
      "174.0, 383 finish at source in 535 and answer in 212\n",
      "Calculated: 0.8207547169811321, Expected: 0.8207547169811321\n",
      "ANSWER\n",
      "the vector space model also called term vector model is an algebraic model used to represent text documents as well as any objects in general as vectors of identifiers it is used in information retrieval and was first used in the smart information retrieval system  a document is represented as a vector and each dimension corresponds to a separate term if a term appears in the document then its value in the vector is non zero many different ways of calculating these values also known as term weights have been developed one of the best known methods is called tf idf weighting  the definition of term depends on the application but generally terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary which is the number of distinct words occurring in the corpus  the vector space model has several disadvantages firstly long documents are represented badly because they have poor similarity values secondly search keywords must accurately match document terms and substrings of words might result in a false positive match  thirdly documents with similar context but different term vocabulary will not be associated resulting in a false negative match  finally the order in which the terms appear in the document is lost in the vector space representation  \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or term vector model is an algebraic model text documents and any objects in general as vectors of identifiers as terms it is used in information information retrieval and its first was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term in the document its value in the vector is non zero several different ways of these values also known as term weights have been developed one of the best known is tf idf weighting the the definition of term depends on the application terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus the vector space model has the long documents are represented because they have poor similarity values a and a dimensionality search keywords must match document terms substrings might result in a false positive match documents with similar context but different term vocabulary be associated resulting in a false negative match the order in which the terms appear in the document is lost in the vector space representation\n",
      "193.0, 207 finish at source in 242 and answer in 228\n",
      "Calculated: 0.8464912280701754, Expected: 0.8464912280701754\n",
      "ANSWER\n",
      "bayes theorem was names after rev thomas bayes and is a method used in probability theory this theorem aims to relate the conditional and marginal probabilities of two random events occuring and given various observations is frequently used to compute subsequent probabilities bayes theorem is also often known as bayes law  an example of where bayes theorem may be used is in the following extract  suppose there exists a school with forty percent females and sixty percent males as students the female students can only wear skirts or trousers in equal numbers whereas all the male students can only wear trousers an observer randomly sees a student from a distance and all he can see is that this student is wearing trousers what is the probability this student is female  there is a debate amongst frequentists and bayesians about how bayes theorem plays a major role around the beginnings of statistical mathematics frequentist and bayesian explanations do not agree about the ways in which probabilities should be assigned this is primarily because bayesians assign probabilities in terms of beliefs whereas frequentists assign probabilities to random events according to the frequencies of them occurring \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability theory bayes theorem often bayes law after rev thomas bayes the conditional and marginal probabilities of two random events is often used to compute probabilities given observations example a may be to bayes theorem can be used to compute the probability that a is given that see example as a theorem bayes theorem is in all of probability plays a role in the debate around the of frequentist and bayesian about the ways in which probabilities should be assigned in frequentists assign probabilities to random events according to frequencies of or to of as of the bayesians probabilities in terms of beliefs and of the bayesian probability and frequentist probability in bayes theorem the conditional and marginal probabilities of events a and where a probability a a a in bayes theorem a a is the probability or marginal probability of a is in the that not about a is the conditional probability of a given is also the probability because is from or the of a is the conditional probability of given a is the or marginal probability of and as a bayes theorem in this the in which beliefs about a\n",
      "61.0, 194 finish at source in 306 and answer in 193\n",
      "Calculated: 0.3160621761658031, Expected: 0.3160621761658031\n",
      "ANSWER\n",
      "dynamic programming is an algorithm design technique used for optimisation problems such as minimising or maximising like divide and conquer dynamic programming solves problems by combining solutions to sub problems however unlike divide and conquer sub problems are not always independent as sub problems may share sub sub problems but solution to one sub problem may not affect the solutions to other sub problems of the same problem  there are four steps in dynamic programming  1 characterise structure of an optimal solution  2 define value of optimal solution recursively  3 compute optimal solution values either top down with caching or bottom up in a table  4 construct an optimal solution from computed values  an example of the type of problem for which dynamic programming may be used is given two sequences x x1 xm and y y1 yn find a common subsequence whose length is maximum  dynamic programming reduces computation by solving sub problems in a bottom up fashion and by storing solution to a sub problem the first time it is solved also looking up the solution when a sub problem is encountered again helps reduce computation however the key in dynamic programming is to determine the structure of optimal solutions  \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and dynamic programming is a of solving problems the of and optimal the time the used in the by to the of solving problems one to find the one by to the the as a and is by the is in the of the a of dynamic programming which an problem in the programming in dynamic programming to programming and from the programming a for the is the optimal for is for a of an is a programming in an of an algorithm optimal optimal solutions of be used to find the optimal solutions of the problem for example the to a from a in a be by first the to the from and to the as in 1 in a problem with optimal a 1 the problem 2 problems recursively 3 optimal solutions to construct an optimal solution for the problem the are solved by sub and is in time 2 the for the it is not a but a to a problem is to the same are used to problems for example in the and and are to compute a to may up or are a may time optimal solutions to it solved in to the solutions to problems solved to the same problem and computed solution is not also are a solution it to in compute the solutions to in\n",
      "49.0, 224 finish at source in 516 and answer in 202\n",
      "Calculated: 0.24257425742574257, Expected: 0.24257425742574257\n",
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# run test cell\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# test lcs implementation\n",
    "# params: complete_df from before, and lcs_norm_word function\n",
    "tests.test_lcs(complete_df, lcs_norm_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, take a look at a few resultant values for `lcs_norm_word`. Just like before, you should see that higher values correspond to higher levels of plagiarism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER\n",
      "inheritance is a basic concept of object oriented programming where the basic idea is to create new classes that add extra detail to existing classes this is done by allowing the new classes to reuse the methods and variables of the existing classes and new methods and classes are added to specialise the new class inheritance models the is kind of relationship between entities or objects  for example postgraduates and undergraduates are both kinds of student this kind of relationship can be visualised as a tree structure where student would be the more general root node and both postgraduate and undergraduate would be more specialised extensions of the student node or the child nodes  in this relationship student would be known as the superclass or parent class whereas  postgraduate would be known as the subclass or child class because the postgraduate class extends the student class  inheritance can occur on several layers where if visualised would display a larger tree structure for example we could further extend the postgraduate node by adding two extra extended classes to it called  msc student and phd student as both these types of student are kinds of postgraduate student this would mean that both the msc student and phd student classes would inherit methods and variables from both the postgraduate and student classes  \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a to new classes of are called objects classes that the inheritance concept in for the new classes known as classes or inherit and of the existing classes are to as classes or classes it is to reuse existing or inheritance the for by in is a of to by of is known entities is to a a can be and to be inheritance is called because the is a a between classes of objects for a is a of and can to be of are is a inherit the to as a for the of a of inheritance is that can a of the of the inheritance a called of by inheritance is by or more methods by or by adding new methods to by inheritance or inheritance a that is to the\n",
      "42.0, 140 finish at source in 308 and answer in 219\n",
      "ANSWER\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google  the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank  other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm  \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e the pagerank is a of google and the pagerank s the is to and to google google on the from the in google in for of the the in for google pagerank pagerank on the of the web by its link as of page s value in google a link from page a to page as a by page a for page google the of links a page it also the page that the by pages that and to other pages in other words a pagerank from a the other pages on the world wide web a page is a to a page as a of the pagerank of a page is and on the and pagerank of pages that link to it links a page that is to by pages with pagerank a links to a web page is for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in to and google other factors influence pagerank pagerank page and s in the pagerank to be to and to pagerank and to links from documents with pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com the ibm clever project and the trustrank algorithm\n",
      "174.0, 383 finish at source in 535 and answer in 212\n",
      "ANSWER\n",
      "the vector space model also called term vector model is an algebraic model used to represent text documents as well as any objects in general as vectors of identifiers it is used in information retrieval and was first used in the smart information retrieval system  a document is represented as a vector and each dimension corresponds to a separate term if a term appears in the document then its value in the vector is non zero many different ways of calculating these values also known as term weights have been developed one of the best known methods is called tf idf weighting  the definition of term depends on the application but generally terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary which is the number of distinct words occurring in the corpus  the vector space model has several disadvantages firstly long documents are represented badly because they have poor similarity values secondly search keywords must accurately match document terms and substrings of words might result in a false positive match  thirdly documents with similar context but different term vocabulary will not be associated resulting in a false negative match  finally the order in which the terms appear in the document is lost in the vector space representation  \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or term vector model is an algebraic model text documents and any objects in general as vectors of identifiers as terms it is used in information information retrieval and its first was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term in the document its value in the vector is non zero several different ways of these values also known as term weights have been developed one of the best known is tf idf weighting the the definition of term depends on the application terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus the vector space model has the long documents are represented because they have poor similarity values a and a dimensionality search keywords must match document terms substrings might result in a false positive match documents with similar context but different term vocabulary be associated resulting in a false negative match the order in which the terms appear in the document is lost in the vector space representation\n",
      "193.0, 207 finish at source in 242 and answer in 228\n",
      "ANSWER\n",
      "bayes theorem was names after rev thomas bayes and is a method used in probability theory this theorem aims to relate the conditional and marginal probabilities of two random events occuring and given various observations is frequently used to compute subsequent probabilities bayes theorem is also often known as bayes law  an example of where bayes theorem may be used is in the following extract  suppose there exists a school with forty percent females and sixty percent males as students the female students can only wear skirts or trousers in equal numbers whereas all the male students can only wear trousers an observer randomly sees a student from a distance and all he can see is that this student is wearing trousers what is the probability this student is female  there is a debate amongst frequentists and bayesians about how bayes theorem plays a major role around the beginnings of statistical mathematics frequentist and bayesian explanations do not agree about the ways in which probabilities should be assigned this is primarily because bayesians assign probabilities in terms of beliefs whereas frequentists assign probabilities to random events according to the frequencies of them occurring \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability theory bayes theorem often bayes law after rev thomas bayes the conditional and marginal probabilities of two random events is often used to compute probabilities given observations example a may be to bayes theorem can be used to compute the probability that a is given that see example as a theorem bayes theorem is in all of probability plays a role in the debate around the of frequentist and bayesian about the ways in which probabilities should be assigned in frequentists assign probabilities to random events according to frequencies of or to of as of the bayesians probabilities in terms of beliefs and of the bayesian probability and frequentist probability in bayes theorem the conditional and marginal probabilities of events a and where a probability a a a in bayes theorem a a is the probability or marginal probability of a is in the that not about a is the conditional probability of a given is also the probability because is from or the of a is the conditional probability of given a is the or marginal probability of and as a bayes theorem in this the in which beliefs about a\n",
      "61.0, 194 finish at source in 306 and answer in 193\n",
      "ANSWER\n",
      "dynamic programming is an algorithm design technique used for optimisation problems such as minimising or maximising like divide and conquer dynamic programming solves problems by combining solutions to sub problems however unlike divide and conquer sub problems are not always independent as sub problems may share sub sub problems but solution to one sub problem may not affect the solutions to other sub problems of the same problem  there are four steps in dynamic programming  1 characterise structure of an optimal solution  2 define value of optimal solution recursively  3 compute optimal solution values either top down with caching or bottom up in a table  4 construct an optimal solution from computed values  an example of the type of problem for which dynamic programming may be used is given two sequences x x1 xm and y y1 yn find a common subsequence whose length is maximum  dynamic programming reduces computation by solving sub problems in a bottom up fashion and by storing solution to a sub problem the first time it is solved also looking up the solution when a sub problem is encountered again helps reduce computation however the key in dynamic programming is to determine the structure of optimal solutions  \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and dynamic programming is a of solving problems the of and optimal the time the used in the by to the of solving problems one to find the one by to the the as a and is by the is in the of the a of dynamic programming which an problem in the programming in dynamic programming to programming and from the programming a for the is the optimal for is for a of an is a programming in an of an algorithm optimal optimal solutions of be used to find the optimal solutions of the problem for example the to a from a in a be by first the to the from and to the as in 1 in a problem with optimal a 1 the problem 2 problems recursively 3 optimal solutions to construct an optimal solution for the problem the are solved by sub and is in time 2 the for the it is not a but a to a problem is to the same are used to problems for example in the and and are to compute a to may up or are a may time optimal solutions to it solved in to the solutions to problems solved to the same problem and computed solution is not also are a solution it to in compute the solutions to in\n",
      "49.0, 224 finish at source in 516 and answer in 202\n",
      "Original category values: \n",
      " [0, 3, 2, 1, 0]\n",
      "\n",
      "Normalized LCS values: \n",
      " [0.1917808219178082, 0.8207547169811321, 0.8464912280701754, 0.3160621761658031, 0.24257425742574257]\n"
     ]
    }
   ],
   "source": [
    "# test on your own\n",
    "test_indices = range(5) # look at first few files\n",
    "\n",
    "category_vals = []\n",
    "lcs_norm_vals = []\n",
    "# iterate through first few docs and calculate LCS\n",
    "for i in test_indices:\n",
    "    category_vals.append(complete_df.loc[i, 'Category'])\n",
    "    # get texts to compare\n",
    "    answer_text = complete_df.loc[i, 'Text'] \n",
    "    task = complete_df.loc[i, 'Task']\n",
    "    # we know that source texts have Class = -1\n",
    "    orig_rows = complete_df[(complete_df['Class'] == -1)]\n",
    "    orig_row = orig_rows[(orig_rows['Task'] == task)]\n",
    "    source_text = orig_row['Text'].values[0]\n",
    "    \n",
    "    # calculate lcs\n",
    "    lcs_val = lcs_norm_word(answer_text, source_text)\n",
    "    lcs_norm_vals.append(lcs_val)\n",
    "\n",
    "# print out result, does it make sense?\n",
    "print('Original category values: \\n', category_vals)\n",
    "print()\n",
    "print('Normalized LCS values: \\n', lcs_norm_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create All Features\n",
    "\n",
    "Now that you've completed the feature calculation functions, it's time to actually create multiple features and decide on which ones to use in your final model! In the below cells, you're provided two helper functions to help you create multiple features and store those in a DataFrame, `features_df`.\n",
    "\n",
    "### Creating multiple containment features\n",
    "\n",
    "Your completed `calculate_containment` function will be called in the next cell, which defines the helper function `create_containment_features`. \n",
    "\n",
    "> This function returns a list of containment features, calculated for a given `n` and for *all* files in a df (assumed to the the `complete_df`).\n",
    "\n",
    "For our original files, the containment value is set to a special value, -1.\n",
    "\n",
    "This function gives you the ability to easily create several containment features, of different n-gram lengths, for each of our text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Function returns a list of containment features, calculated for a given n \n",
    "# Should return a list of length 100 for all files in a complete_df\n",
    "def create_containment_features(df, n, column_name=None):\n",
    "    \n",
    "    containment_values = []\n",
    "    \n",
    "    if(column_name==None):\n",
    "        column_name = 'c_'+str(n) # c_1, c_2, .. c_n\n",
    "    \n",
    "    # iterates through dataframe rows\n",
    "    for i in df.index:\n",
    "        file = df.loc[i, 'File']\n",
    "        # Computes features using calculate_containment function\n",
    "        if df.loc[i,'Category'] > -1:\n",
    "            c = calculate_containment(df, n, file)\n",
    "            containment_values.append(c)\n",
    "        # Sets value to -1 for original tasks \n",
    "        else:\n",
    "            containment_values.append(-1)\n",
    "    \n",
    "    print(str(n)+'-gram containment features created!')\n",
    "    return containment_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating LCS features\n",
    "\n",
    "Below, your complete `lcs_norm_word` function is used to create a list of LCS features for all the answer files in a given DataFrame (again, this assumes you are passing in the `complete_df`. It assigns a special value for our original, source files, -1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Function creates lcs feature and add it to the dataframe\n",
    "def create_lcs_features(df, column_name='lcs_word'):\n",
    "    \n",
    "    lcs_values = []\n",
    "    \n",
    "    # iterate through files in dataframe\n",
    "    for i in df.index:\n",
    "        # Computes LCS_norm words feature using function above for answer tasks\n",
    "        if df.loc[i,'Category'] > -1:\n",
    "            # get texts to compare\n",
    "            answer_text = df.loc[i, 'Text'] \n",
    "            task = df.loc[i, 'Task']\n",
    "            # we know that source texts have Class = -1\n",
    "            orig_rows = df[(df['Class'] == -1)]\n",
    "            orig_row = orig_rows[(orig_rows['Task'] == task)]\n",
    "            source_text = orig_row['Text'].values[0]\n",
    "\n",
    "            # calculate lcs\n",
    "            lcs = lcs_norm_word(answer_text, source_text)\n",
    "            lcs_values.append(lcs)\n",
    "        # Sets to -1 for original tasks \n",
    "        else:\n",
    "            lcs_values.append(-1)\n",
    "\n",
    "    print('LCS features created!')\n",
    "    return lcs_values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Create a features DataFrame by selecting an `ngram_range`\n",
    "\n",
    "The paper suggests calculating the following features: containment *1-gram to 5-gram* and *longest common subsequence*. \n",
    "> In this exercise, you can choose to create even more features, for example from *1-gram to 7-gram* containment features and *longest common subsequence*. \n",
    "\n",
    "You'll want to create at least 6 features to choose from as you think about which to give to your final, classification model. Defining and comparing at least 6 different features allows you to discard any features that seem redundant, and choose to use the best features for your final model!\n",
    "\n",
    "In the below cell **define an n-gram range**; these will be the n's you use to create n-gram containment features. The rest of the feature creation code is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram containment features created!\n",
      "2-gram containment features created!\n",
      "3-gram containment features created!\n",
      "4-gram containment features created!\n",
      "5-gram containment features created!\n",
      "6-gram containment features created!\n",
      "ANSWER\n",
      "inheritance is a basic concept of object oriented programming where the basic idea is to create new classes that add extra detail to existing classes this is done by allowing the new classes to reuse the methods and variables of the existing classes and new methods and classes are added to specialise the new class inheritance models the is kind of relationship between entities or objects  for example postgraduates and undergraduates are both kinds of student this kind of relationship can be visualised as a tree structure where student would be the more general root node and both postgraduate and undergraduate would be more specialised extensions of the student node or the child nodes  in this relationship student would be known as the superclass or parent class whereas  postgraduate would be known as the subclass or child class because the postgraduate class extends the student class  inheritance can occur on several layers where if visualised would display a larger tree structure for example we could further extend the postgraduate node by adding two extra extended classes to it called  msc student and phd student as both these types of student are kinds of postgraduate student this would mean that both the msc student and phd student classes would inherit methods and variables from both the postgraduate and student classes  \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a to new classes of are called objects classes that the inheritance concept in for the new classes known as classes or inherit and of the existing classes are to as classes or classes it is to reuse existing or inheritance the for by in is a of to by of is known entities is to a a can be and to be inheritance is called because the is a a between classes of objects for a is a of and can to be of are is a inherit the to as a for the of a of inheritance is that can a of the of the inheritance a called of by inheritance is by or more methods by or by adding new methods to by inheritance or inheritance a that is to the\n",
      "42.0, 140 finish at source in 308 and answer in 219\n",
      "ANSWER\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google  the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank  other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm  \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e the pagerank is a of google and the pagerank s the is to and to google google on the from the in google in for of the the in for google pagerank pagerank on the of the web by its link as of page s value in google a link from page a to page as a by page a for page google the of links a page it also the page that the by pages that and to other pages in other words a pagerank from a the other pages on the world wide web a page is a to a page as a of the pagerank of a page is and on the and pagerank of pages that link to it links a page that is to by pages with pagerank a links to a web page is for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in to and google other factors influence pagerank pagerank page and s in the pagerank to be to and to pagerank and to links from documents with pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com the ibm clever project and the trustrank algorithm\n",
      "174.0, 383 finish at source in 535 and answer in 212\n",
      "ANSWER\n",
      "the vector space model also called term vector model is an algebraic model used to represent text documents as well as any objects in general as vectors of identifiers it is used in information retrieval and was first used in the smart information retrieval system  a document is represented as a vector and each dimension corresponds to a separate term if a term appears in the document then its value in the vector is non zero many different ways of calculating these values also known as term weights have been developed one of the best known methods is called tf idf weighting  the definition of term depends on the application but generally terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary which is the number of distinct words occurring in the corpus  the vector space model has several disadvantages firstly long documents are represented badly because they have poor similarity values secondly search keywords must accurately match document terms and substrings of words might result in a false positive match  thirdly documents with similar context but different term vocabulary will not be associated resulting in a false negative match  finally the order in which the terms appear in the document is lost in the vector space representation  \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or term vector model is an algebraic model text documents and any objects in general as vectors of identifiers as terms it is used in information information retrieval and its first was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term in the document its value in the vector is non zero several different ways of these values also known as term weights have been developed one of the best known is tf idf weighting the the definition of term depends on the application terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus the vector space model has the long documents are represented because they have poor similarity values a and a dimensionality search keywords must match document terms substrings might result in a false positive match documents with similar context but different term vocabulary be associated resulting in a false negative match the order in which the terms appear in the document is lost in the vector space representation\n",
      "193.0, 207 finish at source in 242 and answer in 228\n",
      "ANSWER\n",
      "bayes theorem was names after rev thomas bayes and is a method used in probability theory this theorem aims to relate the conditional and marginal probabilities of two random events occuring and given various observations is frequently used to compute subsequent probabilities bayes theorem is also often known as bayes law  an example of where bayes theorem may be used is in the following extract  suppose there exists a school with forty percent females and sixty percent males as students the female students can only wear skirts or trousers in equal numbers whereas all the male students can only wear trousers an observer randomly sees a student from a distance and all he can see is that this student is wearing trousers what is the probability this student is female  there is a debate amongst frequentists and bayesians about how bayes theorem plays a major role around the beginnings of statistical mathematics frequentist and bayesian explanations do not agree about the ways in which probabilities should be assigned this is primarily because bayesians assign probabilities in terms of beliefs whereas frequentists assign probabilities to random events according to the frequencies of them occurring \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability theory bayes theorem often bayes law after rev thomas bayes the conditional and marginal probabilities of two random events is often used to compute probabilities given observations example a may be to bayes theorem can be used to compute the probability that a is given that see example as a theorem bayes theorem is in all of probability plays a role in the debate around the of frequentist and bayesian about the ways in which probabilities should be assigned in frequentists assign probabilities to random events according to frequencies of or to of as of the bayesians probabilities in terms of beliefs and of the bayesian probability and frequentist probability in bayes theorem the conditional and marginal probabilities of events a and where a probability a a a in bayes theorem a a is the probability or marginal probability of a is in the that not about a is the conditional probability of a given is also the probability because is from or the of a is the conditional probability of given a is the or marginal probability of and as a bayes theorem in this the in which beliefs about a\n",
      "61.0, 194 finish at source in 306 and answer in 193\n",
      "ANSWER\n",
      "dynamic programming is an algorithm design technique used for optimisation problems such as minimising or maximising like divide and conquer dynamic programming solves problems by combining solutions to sub problems however unlike divide and conquer sub problems are not always independent as sub problems may share sub sub problems but solution to one sub problem may not affect the solutions to other sub problems of the same problem  there are four steps in dynamic programming  1 characterise structure of an optimal solution  2 define value of optimal solution recursively  3 compute optimal solution values either top down with caching or bottom up in a table  4 construct an optimal solution from computed values  an example of the type of problem for which dynamic programming may be used is given two sequences x x1 xm and y y1 yn find a common subsequence whose length is maximum  dynamic programming reduces computation by solving sub problems in a bottom up fashion and by storing solution to a sub problem the first time it is solved also looking up the solution when a sub problem is encountered again helps reduce computation however the key in dynamic programming is to determine the structure of optimal solutions  \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and dynamic programming is a of solving problems the of and optimal the time the used in the by to the of solving problems one to find the one by to the the as a and is by the is in the of the a of dynamic programming which an problem in the programming in dynamic programming to programming and from the programming a for the is the optimal for is for a of an is a programming in an of an algorithm optimal optimal solutions of be used to find the optimal solutions of the problem for example the to a from a in a be by first the to the from and to the as in 1 in a problem with optimal a 1 the problem 2 problems recursively 3 optimal solutions to construct an optimal solution for the problem the are solved by sub and is in time 2 the for the it is not a but a to a problem is to the same are used to problems for example in the and and are to compute a to may up or are a may time optimal solutions to it solved in to the solutions to problems solved to the same problem and computed solution is not also are a solution it to in compute the solutions to in\n",
      "49.0, 224 finish at source in 516 and answer in 202\n",
      "ANSWER\n",
      "inheritance is a basic concept in object oriented programming it models the reuse of existing class code in new classes  the is a kind of relationship  for example a house is a kind of building similarly an office block is a kind of building both house and office block will inherit certain characteristics from buildings but also have their own personal characteristics  a house may have a number of occupants whereas an office block will have a number of offices however these personal characteristics don t apply to all types of buildings  in this example the building would be considered the superclass  it contains general characteristics for other objects to inherit  and the house and office block are both subclasses  they are specific types and specialise the characteristics of the superclass  java allows object inheritance when one class inherits from another class all the public variables and methods are available to the subclass  public class shape private color colour public void setcolour color newcolour  colour  newcolour  public class circle extends shape private int radius public void setradius int newradius  radius  newradius  in this example the circle class is a subclass of the shape class the shape class provides a public setcolour method which will be available to the circle class and other subclasses of shape however the private variable colour as defined in the shape class will not be available for direct manipulation by the circle class because it is not inherited the circle class specialises the shape class which means that setradius is available to the circle class and all subclasses of circle but it isn t available to the superclass shape  \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a to new classes of which are objects classes that have defined the inheritance concept in for the new classes as classes inherit and of the existing classes which are to as classes classes it is to reuse existing code inheritance provides the for by in is a number of to by means of is specific is to a a be and to be specific inheritance is also because the is a a classes of objects for a is a of and one to be an of are an is a may inherit all the to all as a for the of a an of inheritance is that a of code the of the inheritance another a which of code by code inheritance is by one methods by by new methods to by an inheritance inheritance a that is not may to the\n",
      "44.0, 149 finish at source in 308 and answer in 273\n",
      "ANSWER\n",
      "pagerank pr refers to both the concept and the google system used for ranking the importance of pages on the web the pagerank of a site refers to its importance or value on the web in relation to the rest of the sites that have been pagerank ed  the algorithm basically works like a popularity contest  if your site is linked to by popular websites then your site is considered more popular however the pr doesn t just apply to the website as a whole  different pages within a website get given different prs dependent on a number of factors inbound links backlinks  how many pages other than the ones on your website link to this particular page  outbound links forward links  how many external pages the particular page links to  dangling links  how many pages with no external links are linked to from a particular page  deep links  how many links that are not the home page are linked to from a particular page pr tries to emulate a random surfer  the algorithm includes a dampening factor which is the probability that a random surfer will get bored and go and visit a new page  by default this is 0 85 a variation on this is the intentional surfer  where the importance of a page is based on the actual visits to sites by users this method is used in the google toolbar which reports back actual site visits to google \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link algorithm used by the google that a to of a of as the web with the of its importance within the the algorithm to of with and the that to given is the pagerank of and by pr the pagerank is a of google and the pagerank been however the is to and not to google google on the from the in google in for of the the in for google pagerank pagerank on the of the web by its link as of page value in google a link from page a to page as a by page a for page google more than the of or links a page the page that the by pages that are more and to other pages in other a pagerank from a the other pages on the web how a page is a to a page as a of the pagerank of a page is and on the number and pagerank of pages that link to links a page that is linked to by many pages with pagerank a if are no links to a web page is no for that page google a from 0 for on the this pagerank a site importance in the of google the pagerank is from a probability value on a like the the pagerank of a particular page is based the of inbound links as as the pagerank of the pages the links is that other factors of on the page and actual visits to the page by the google toolbar the pagerank in to and google no how other factors pagerank pagerank have been page and in the pagerank concept to to and been to pagerank and to links from with pagerank other link based ranking for web pages the algorithm by used by and the and the algorithm\n",
      "73.0, 308 finish at source in 535 and answer in 242\n",
      "ANSWER\n",
      "vector space model is an algebraic model for representing text documents and in general any objects as vectors of identifiers such as for example index terms its first use was in the smart information retrieval system it is used in information filtering information retrieval indexing and relevancy rankings  a document is represented as a vector and each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  one of the best known schemes is tf idf weighting proposed by salton wong and yang in the classic vector space model the term specific weights in the document vectors are products of local and global parameters  relevancy rankings of documents in a keyword search can be calculated using the assumptions of document similarities theory by comparing the deviation of angles between each document vector and the original query vector where the query is represented as same kind of vector as the documents  the vector space model has the following limitations   search keywords must precisely match document terms word substrings might result in a false positive match   semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match   the order in which the terms appear in the document is lost in the vector space representation  long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality  \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting the example the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus the vector space model has the following limitations long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality search keywords must precisely match document terms word substrings might result in a false positive match semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match the order in which the terms appear in the document is lost in the vector space representation\n",
      "189.0, 236 finish at source in 242 and answer in 304\n",
      "ANSWER\n",
      "bayes theorem relates the conditional and marginal probabilities of two random events for example a person may be seen to have certain medical symptoms bayes theorem can then be used to compute the probability that given that observation the proposed diagnosis is the right one  bayes theorem forms a relationship between the probabilities xcof events a and b intuitively bayes theorem in this form describes the way in which one s recognition of a are updated by having observed b  p a  b  p b  a p a  p b  p a b is the conditional probability of a given b it is derived from or depends upon the specified value of b therefore it is also known as the posterior probability  p b a is the conditional probability of b given a  p a is the prior probability a it doesn t take into account any information about b so it is prior  p b is the prior or marginal probability of b and acts to normalise the probability  to derive the theorem we begin with the definition of conditional probability by combining and re arranging these two equations for a and b we get a the lemma called product rule for probabilities provided that p b is not a zero dividing both sides by p b renders us with bayes theorem \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability bayes theorem called bayes bayes relates the conditional and marginal probabilities of two random events it is used to compute posterior probabilities given for example a may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is given that observation example as a theorem bayes theorem is in of probability it a in the the of and about the in which probabilities be in probabilities to random events to of or to of as of the probabilities in of and of the probability and probability these in bayes theorem relates the conditional and marginal probabilities of events a and b b a probability p a b p b a p a p b in bayes theorem a p a is the prior probability or marginal probability of a it is prior in the that it not take into account any information about b p a b is the conditional probability of a given b it is also called the posterior probability it is derived from or depends upon the specified value of b p b a is the conditional probability of b given a p b is the prior or marginal probability of b and acts as a intuitively bayes theorem in this form describes the way in which one s about a are updated by having observed b\n",
      "108.0, 231 finish at source in 306 and answer in 223\n",
      "ANSWER\n",
      "dynamic programming is a method for solving mathematical programming problems that exhibit the properties of overlapping subproblems and optimal substructure this is a much quicker method than other more naive methods the word programming in dynamic programming relates optimization which is commonly referred to as mathematical programming richard bellman originally coined the term in the 1940s to describe a method for solving problems where one needs to find the best decisions one after another and by 1953 he refined his method to the current modern meaning  optimal substructure means that by splitting the programming into optimal solutions of subproblems these can then be used to find the optimal solutions of the overall problem one example is the computing of the shortest path to a goal from a vertex in a graph first compute the shortest path to the goal from all adjacent vertices then using this the best overall path can be found thereby demonstrating the dynamic programming principle this general three step process can be used to solve a problem  1 break up the problem different smaller subproblems  2 recursively use this three step process to compute the optimal path in the subproblem  3 construct an optimal solution using the computed optimal subproblems for the original problem  this process continues recursively working over the subproblems by dividing them into sub subproblems and so forth until a simple case is reached one that is easily solvable  \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure the method much than naive methods the term originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he refined this to the modern meaning the as a and that is by the bellman is in the of the bellman a of dynamic programming which an optimization problem in the word programming in dynamic programming to programming all and from the term mathematical programming a for optimization the is the optimal for that is for a of an is a programming in this means an of an optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to the best overall path as in 1 in general can solve a problem optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems by dividing them into sub subproblems and so until simple case that is solvable in 2 the subproblem graph for the that is a a overlapping subproblems to that a problem overlapping subproblems is to that the subproblems used to solve different problems for example in the and computing computing and to compute a naive to computing up computing more this overlapping subproblems a naive optimal solutions to subproblems in to this the solutions to problems then to solve the problem can and computed solution this is this term a solution can to in can compute the solutions to subproblems that in\n",
      "141.0, 335 finish at source in 516 and answer in 236\n",
      "ANSWER\n",
      "inheritance in object oriented programming is where a new class is formed using classes which have allready been defined these classes have have some of the behavior and attributes which where existent in the classes that it inherited from the peropos of inheritance in object oriented programming is to minimize the reuse of existing code without modification  inheritance allowes classes to be categorized similer to the way humans catagorize it also provides a way to generalize du to the is a relationship between classes for example a cow is a generalization of animal similarly so are pigs  cheaters  defeining classes in this way allows us to define attributes and behaviours which are commen to all animals in one class so cheaters would natuarly inheart properities commen to all animals  the advantage of inheritance is that classes which would otherwise have alot of similar code  can instead shair the same code thus reducing the complexity of the program inheritance therefore can also be refered to as polymorphism which is where many pieces of code are controled by shared control code  inheritance can be accomplished by overriding methods in its ancestor or by adding new methods  \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a way to new classes of which are using classes that have been defined the inheritance in for the new classes as classes or attributes and behavior of the existing classes which are to as classes or ancestor classes it is to reuse existing code or modification inheritance provides the for by in is a of to by of generalization is is to a a can be and to be its inheritance is also generalization the is a a between classes of for a is a generalization of and many one can to be of are is a all the to all as a for the of a advantage of inheritance is that similar can a of code reducing the complexity of the program inheritance therefore a polymorphism which many pieces of code by shared control code inheritance is accomplished by overriding one or methods by ancestor or by adding new methods to by ancestor inheritance or inheritance a that is to the\n",
      "83.0, 169 finish at source in 308 and answer in 194\n",
      "ANSWER\n",
      "there are many attributes which infulance the ranking of a page in google the main too are the content key words and links the content of a webpage generaly gives a good idea about what the page is about however there are some flaws in this for example for along time ibm web page didnt contain the word computer dispite it being strongly associated with them to solve this problem web pages can assign itself key words which contribute to its ranking in searches  the second method is the use of links the more sights which links to your web page and the higher the rank of those sights the higher the rank of your site will be this method is used as links are seen as an adoursment of a sight  with both these methods of ranking web pages there are issues key words can be compromised by sparming google solves this problem by penolizing such activity useing links to rank a page also has its problems for example link farms which have recursive links for the sole perpos of raising there ranking google takels this by useing a dampaning algorthem  \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: is a link used by the google a to of a of such as the web with the of its the the be to of with and the it to is also the of and by the is a of google and the has however the is to and to google google has the the in google in for use of the the in for google the of the web by its link as an of an page in google a link page a to page as a by page a for page google more the of links a page it also the page the by pages are more and to pages in words a a the pages the web about a page is a to a page as a of the of a page is and the and of pages link to it links a page is to by many pages with a rank itself there are links to a web page there is for page google a for webpage the this a site in the of google the is a a the the of a page is the of links as as the of the pages the links it is of words the page and to the page by the google also the in to and google about have page and in the has to be to and has to and to links with link ranking for web pages the by used by and the ibm and the\n",
      "52.0, 250 finish at source in 535 and answer in 192\n",
      "ANSWER\n",
      "the vector space model is where each document is viewed as a bag of words where there order has little significance each document is a vector where each word is a dimension the vector is then constucted of the frequency of eacher word dimension  the draw back to this approach is that the length of the document as an inpact on the vector to compensate for this you can comput the cosine similarity between your two comparism documents this will find the difference between the two vectors the dot product  ignoreing the size of them  inorder to query the search space the query can also be represented as a vector then you find the document whos vector has the greatest cosine similarities to your query there are a number of wighting sceems which can be incoperated inorder to increase the accuracy of the vextors  there are some drawbacks with this approach computing the cosine similarities between each vector can be expensive as the number of dimensions can be in the thousands to tackle this problem you can use inverted indexs and then a series heuristics inorder to inprove on this to top \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model vector model is an model for documents and in as vectors of as for is in and use in the a document is represented as a vector each dimension to a a in the document in the vector is of computing also as of the is the the of on the are words the words are to be the the of the vector is the number of words in the the number of words in the the vector space model has the documents are represented similarity a product and a search document word in a documents with be in a the order in which the in the document is in the vector space\n",
      "43.0, 116 finish at source in 242 and answer in 192\n",
      "ANSWER\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is used to compute posterior probabilities given observations for example a person may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct  as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned to each other bayesians describe probabilities in terms of beliefs and degrees of uncertainty while frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole the articles on bayesian probability and frequentist probability discuss these debates in detail \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that example as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in detail bayes theorem relates the conditional and marginal probabilities of events a and a probability a a a each in bayes theorem a a is the probability or marginal probability of a it is in the that it about a is the conditional probability of a given it is called the posterior probability it is or the of a is the conditional probability of given a is the or marginal probability of and as a bayes theorem in the in which beliefs about a observed\n",
      "135.0, 235 finish at source in 306 and answer in 150\n",
      "ANSWER\n",
      "in computer science dynamic programming is a way of solving problems consist of overlapping subproblems and optimal substructure the method is more effiecent than naive methods  the term was first coined in the 1940s by richard bellman to describe the process of solving problems where you need to find the best decisions consecutavly in 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman equation is a central result of dynamic programming which restates an optimization problem in recursive form  dynamic programming has little connection to computer programming at all and instead comes from the term mathematical programming a synonym for optimization thus the program is the best plan for action that is produced for instance a events schedule at an exhibition is sometimes called a program programming means finding a plan of action  \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and computer science dynamic programming is a method of solving problems that the of overlapping subproblems and optimal substructure the method than naive methods the term was in the 1940s by richard bellman to describe the process of solving problems where to find the best decisions by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman is in the of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the programming in dynamic programming has connection to computer programming at all and instead comes from the term mathematical programming a synonym for optimization thus the program is the optimal plan for action that is produced for instance a schedule of events at an exhibition is sometimes called a program programming in this means finding an plan of action an optimal substructure means that optimal of subproblems to find the optimal of the problem for the to a from a in a by first the to the from all and this to the best as in in a problem optimal substructure a process the problem subproblems problems this process optimal to an optimal for the problem the subproblems by subproblems and that is in the for the that is a a overlapping subproblems to that a problem has overlapping subproblems is to that the subproblems to problems for in the and and to a naive to more this overlapping subproblems a naive optimal to subproblems has in to this instead the to problems need to the problem and this is called this term need a to in the to subproblems that need in\n",
      "135.0, 289 finish at source in 516 and answer in 151\n",
      "ANSWER\n",
      "inheritance in object oriented programming is a way to form new classes using classes that have already been defined the new classes known as derived classes inherit attributes and behaviour of the existing classes which are referred to as base classes with little or no modification it is intended to help reuse existing code it is typically accomplished either by overriding one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor inheritance is also sometimes called generalization because there is a relationships represent a hierarchy between classes of objects a fruit  for instance is a generalization of orange  mango  apples and many others one can consider fruit to be an abstraction of apple orange etc since apples are fruit i e  an apple is a fruit  conversely apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program  \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a way to form new classes of which are called objects using classes that have already been defined the inheritance in for the new classes known as derived classes or inherit attributes and of the existing classes which are referred to as base classes or ancestor classes it is intended to help reuse existing code with little or no modification inheritance the for by in is a of to by of generalization is known is to a a can be and to be inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple orange mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e an apple is a fruit apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance a called which many of code being by code inheritance is typically accomplished either by overriding one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor inheritance or inheritance a that is sufficiently may to the\n",
      "149.0, 236 finish at source in 308 and answer in 181\n",
      "ANSWER\n",
      "pagerank algorithm is patented by stanford university it is a link analysis algorithm employed by the google internet search engine that assigns a value used to measure the importance to each element of a hyperlinked set of documents such as the www with the purpose of  measuring its relative significance within the set  google owns exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in return for use of the patent  \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link analysis algorithm used by the google internet search engine that assigns a to each element of a hyperlinked set of documents such as the with the purpose of measuring its relative importance within the set the algorithm to of with the that it assigns to element is the pagerank of by the pagerank is a of google the pagerank patented patent the patent is to stanford university to google google exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in for use of the patent the shares in for million google pagerank pagerank on the of the by its link as of value in google a link from a to as a by a for google the of a it the that the by that to in a pagerank from a the on the a is a to a as a of the pagerank of a is on the pagerank of that link to it a that is to by with pagerank a to a is for that google assigns a from for each on the internet pagerank a importance in the of google the pagerank is from a value on a the the pagerank of a is the of as as the pagerank of the the it is that of search on the to the by the google the pagerank in to google pagerank pagerank in the pagerank to to to pagerank to from documents with pagerank link for the algorithm by used by the the algorithm\n",
      "62.0, 261 finish at source in 535 and answer in 80\n",
      "ANSWER\n",
      "an algebraic model for representing text documents and any objects in general is known by the name vector space model it represents these as vectors of identifiers index terms are one illustration of these the vector space model was first used in the smart information retrieval system and it is utilised variously in indexing information filtering indexing and information retrieval  a document has representation as a vector every dimension is precisely related to a separate term the way in which term is defined depends entirely on the application typically terms are either single words keywords or longer phrases the dimensionality of the vector is the number of words in the vocabulary if it is the words that are chose to be the terms so the same rule applies with keywords and indeed longer phrases  if a term occurs in the document its value in the vector is non zero several different ways of computing these values additionally known as term weights have been developed one of the most famous schemes is tf idf weighting  \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers as for index terms it is used in information filtering information retrieval indexing and its first was in the smart information retrieval system a document is as a vector dimension to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values known as term weights have been developed one of the known schemes is tf idf weighting the the of term depends on the application typically terms are single words keywords or longer phrases if the words are to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of words in the the vector space model has the documents are have values a and a dimensionality keywords precisely document terms in a documents with different term vocabulary be in a the in which the terms in the document is in the vector space representation\n",
      "80.0, 182 finish at source in 242 and answer in 174\n",
      "ANSWER\n",
      "baye s theorm in connection with conditional probabilities is of fundamental importance since it permits a calculation of prob ab from prob ba  statistical information that is often gathered in great volume can therefore be avoided \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in often conditional probabilities of it is often probabilities a be can be that a is that a is in of it a in of in probabilities be in probabilities of of of probabilities in of of in conditional probabilities of a a a a a in a a is of a it is in that it information a is conditional of a it is it is from of a is conditional of a is of a in in s a\n",
      "11.0, 81 finish at source in 306 and answer in 36\n",
      "ANSWER\n",
      "dynamic programming dp is an extremely powerful general tool for solving optimization difficulties on left right ordered item for example character strings it is similar to divide and conquer however is differentiated as its subproblems are not independent it is easily applicable in relative terms once understood however until one has witnessed enough examples it looks like magic  dp minimizes computation by solving subproblems from the base upwards storing solution to a subproblem when it is initially conquered and looking up the solution when the subproblem is experienced for a second time  \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and dynamic programming is a solving the subproblems and the time the in the by to the solving one to the one by to the the as a and is by the is in the the a dynamic programming an optimization in the programming in dynamic programming has to programming and from the programming a for optimization the is the for is for a an is a programming in an an subproblems to the the for example the to a from a in a by the to the from and to the as in in general a a the subproblems to an solution for the the subproblems are by subproblems and on until is in time the subproblem for the it is not a a subproblems to a has subproblems is to the subproblems are to for example in the and and are to a to up subproblems are a time to subproblems it has in to the to to the and solution is not are a solution it to in the to subproblems in\n",
      "26.0, 176 finish at source in 516 and answer in 92\n",
      "ANSWER\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula the new classes known as derived classes take over or inherit attribute and behaviour of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula the new classes known as derived classes take over or inherit and of the pre existing classes which are referred to as base classes or ancestor classes it is intended to help reuse existing code with little or no modification inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple orange mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e an apple is a fruit apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor inheritance or inheritance a that is sufficiently may to the\n",
      "286.0, 296 finish at source in 308 and answer in 288\n",
      "ANSWER\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references pagerank uses in google toolbar measures popularity of a site marketing value updated periodically in google directory pagerank sort links within categories volunteers evaluate classify annotate open directory project using pagerank  \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical that assigns to any element is the pagerank of and by the pagerank is a of google and the pagerank the is to and to google google the the in google in of the the in google pagerank pagerank the of the web by using its link as of value in google a link a to as a by a google the of links a the that the by that and to in a pagerank a the the world wide web a is a to a as a of the pagerank of a is and the and pagerank of that link to links a that is to by with pagerank a links to a web is that google assigns a weighting each the internet pagerank a site importance in the of google the pagerank is a value a the the pagerank of a is the of links as as the pagerank of the the links is that of search the and to the by the google toolbar the pagerank in to and google pagerank pagerank and in the pagerank to be to and to pagerank and to links documents with pagerank link web the algorithm by used by and the project and the algorithm\n",
      "71.0, 265 finish at source in 535 and answer in 90\n",
      "ANSWER\n",
      "the representation of a set of documents as vectors in a common vector space is known as the vector space vector space model and is fundamental to a host of information retrieval ir operations including scoring documents on a query document classification and document clustering we first develop the basic ideas underlying vector space scoring a pivotal step in this development is the view of queries as vectors in the same vector space as the document collection  \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model vector model is model documents and in as vectors of as is in information information retrieval and first in the information retrieval a document is as a vector to a a in the document in the vector is of known as of the known is the the of on the the to the the of the vector is the of in the the of in the the vector space model the documents a and a document in a documents in a the in the in the document is in the vector space representation\n",
      "25.0, 96 finish at source in 242 and answer in 77\n",
      "ANSWER\n",
      "bayes theorem is an important theorem relating conditional probabilities it allows us to calculate prob a b from prob b a  bayes theorem is important because it can save us from gathering vast amounts of statistical evidence the main theory is prob a b  prob b a  prob a  prob b  it means using prob win rain from earlier we can find the probability that it rained on a day that harry won a race \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: probability theory bayes theorem bayes bayes the conditional probabilities of it is to probabilities a to bayes theorem can to the probability that a is that a theorem bayes theorem is of probability it a the the of the probabilities probabilities to to of to of of the probabilities of of the on probability probability bayes theorem the conditional probabilities of a b b a probability a b b a a b bayes theorem a a is the probability probability of a it is the that it b a b is the conditional probability of a b it is the probability because it is from the of b b a is the conditional probability of b a b is the probability of b a bayes theorem the a b\n",
      "26.0, 129 finish at source in 306 and answer in 75\n",
      "ANSWER\n",
      "dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm  \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and computer dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below the method takes much less time than naive methods the term in the to the of solving problems to the this to the the a and that is the is in the of the a of dynamic programming an optimization in the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal of subproblems to the optimal of the for the to a from a in a the to the from all and this to the in in a optimal substructure a the subproblems problems this optimal to an optimal for the the subproblems subproblems and that is in time the for the that is a a overlapping subproblems to that a has overlapping subproblems is to that the subproblems to problems for in the and and to a naive to this overlapping subproblems a naive time optimal to subproblems has in to this instead the to problems to the and this is called this term a particular to in the to subproblems that in\n",
      "96.0, 249 finish at source in 516 and answer in 96\n",
      "ANSWER\n",
      "in object oriented programming objects are grouped together into classes according to their type structure and the functions that can be performed on them inheritance is a process in object oriented programming in which objects acquire or inherit the properties of objects of another class it is therefore used to create relationships between one object and another each class groups together objects of a similar type with similar properties new classes can be formed by this process whose objects will have properties of both the classes from which this new class is formed a superclass has all of the properties of the subclasses below it at the same time subclasses are each distinctive from each other but related via the superclass subclasses are said to extend superclasses due to these relationships object oriented programmes tend to be easier to modify since they do not need to be changed when a new object with different properties is added instead a new object is made to inherit properties of objects which already exist inheritance can be divided into two main processes single inheritance and multiple inheritance single inheritance means that the class can only inherit from one other class whereas multiple inheritance allows for inheritance from several classes \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a to new classes of which are objects classes that have already the inheritance in for the new classes classes or inherit and of the classes which are to classes or classes it is to with or inheritance the for by in is a of to by means of is is to a a can be and to be each only inheritance is the is a relationships a between classes of objects for a is a of and one can to be of since are is a inherit all the properties to all a for the of a of inheritance is that with similar can a of the of the inheritance therefore has another a which of by inheritance is by one or by or by new to by inheritance or inheritance used a that is not to the\n",
      "39.0, 145 finish at source in 308 and answer in 206\n",
      "ANSWER\n",
      "the pagerank algorithm is used to designate every aspect of a set of hyperlinked documents with a numerical weighting it is used by the google search engine to estimate the relative importance of a web page according to this weighting the system uses probability distribution to determine the odds that a person randomly clicking on links will arrive at any given page following this each web page is given a ranking of 0 10 according to its relevance to a search the pagerank is calculated by taking into consideration the number of inbound links and the pagerank of the pages supplying these links this means therefore that if a webpage is linked to others that have a high ranking then it too will receive a high rank  due to the nature of the pagerank system it is susceptible to manipulation and has been exploited so that certain pages are given a false exaggerated ranking in these cases only goggle has access to the genuine pagerank however much research has been conducted into methods of avoiding links from documents with a false pagerank to try and iron out the bugs in this system and from 2007 google has actively penalized schemes which try to increase rankings artificially \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a algorithm used by the google search engine that a numerical weighting to each of a hyperlinked set of documents the web with the of its relative importance the set the algorithm to any of with and the numerical that it to any given is the pagerank of and by the pagerank is a of google and the pagerank has been however the is to and to google google has on the from the in google in of the the in google pagerank pagerank on the nature of the web by its of page in google a from page a to page a by page a page google at the of links a page it the page that the by pages that are and to pages in a pagerank from a the pages on the web a page is a to a page a of the pagerank of a page is and on the number and pagerank of pages that to it links a page that is linked to by pages with high pagerank a high rank if are links to a web page is that page google a weighting from 0 10 each webpage on the this pagerank a importance in the of google the pagerank is from a probability on a the the pagerank of a page is the of inbound links the pagerank of the pages the links it is that relevance of search on the page and to the page by the google the pagerank in to manipulation and google pagerank pagerank have been page and in the pagerank has to to manipulation and research has been to pagerank and to links from documents with pagerank ranking web pages the algorithm by used by and the and the algorithm\n",
      "76.0, 295 finish at source in 535 and answer in 206\n",
      "ANSWER\n",
      "the vector space model is an algebraic model used to represent text documents and any objects generally as vectors of identifiers for instance index terms its applications include information filtering information retrieval indexing and relevancy rankings with reference to this model documents are represented as vectors each dimension corresponds to a separate term the value of a vector is non zero if a term occurs in the document several different ways have been developed of calculating these values also known as term weights  one of the best known schemes is tf idf term frequency inverse document frequency weighting  the model can be used to determine the relevancy rankings of documents in a keyword search using the assumptions of document similarities theory by comparing the original query vector where the query is represented as same kind of vector as the documents and the deviation of angles between each document vector  the classic vector space model was put forward by salton wong and yang and is known as term frequency inverse document frequency model in this classic model the term specific weights in the document vectors are products of local and global parameters in a simpler term count model the term specific weights are just the counts of term occurrences and therefore do not include the global parameter  \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model term vector model is an algebraic model for text documents and any objects in as vectors of identifiers as for index terms is used in information filtering information retrieval indexing and relevancy rankings its was in the information retrieval a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of these values also known as term weights have been developed one of the best known schemes is tf idf weighting the the of term the terms are if the are to be the terms the of the vector is the of in the the of in the the vector space model the documents are represented have values a and a search document terms in a documents with different term be in a the in the terms in the document is in the vector space\n",
      "90.0, 159 finish at source in 242 and answer in 216\n",
      "ANSWER\n",
      "bayes theorem relates the conditional and marginal probabilities of two random events and is named after the reverend thomas bayes 1702 1761  who studied how to compute a distribution for the parameter of a binomial distribution it is valid in all common interpretations of probability it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty applications of bayes theorem often assume the philosophy underlying bayesian probability that uncertainty and degrees of belief can be measured as probabilities one of bayes results proposition 5 gives a simple description of conditional probability and shows that it can be expressed independently of the order in which things occur if there be two subsequent events the probability of the second b n and the probability of both together p n and it being first discovered that the second event has also happened from hence i guess that the first event has also happened the probability i am right i e  the conditional probability of the first event being true given that the second has also happened is p b  note that the expression says nothing about the order in which the events occurred it measures correlation not causation \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability bayes theorem often bayes after thomas bayes relates the conditional and marginal probabilities of two random events it is often to compute probabilities given for a be to bayes theorem can be to compute the probability that a is given that as a theorem bayes theorem is valid in all common interpretations of probability it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the bayesian probability and frequentist probability in bayes theorem relates the conditional and marginal probabilities of events a and b b has a probability p a b p b a p a p b in bayes theorem has a p a is the probability or marginal probability of a it is in the that it not about b p a b is the conditional probability of a given b it is also the probability it is from or the of b p b a is the conditional probability of b given a p b is the or marginal probability of b and as a bayes theorem in the in which one beliefs about a b\n",
      "121.0, 234 finish at source in 306 and answer in 247\n",
      "ANSWER\n",
      "dynamic programming is an algorithmic technique used to solve certain optimization problems where the object is to find the best solution from a number of possibilities it uses a so called bottom up approach meaning that the problem is solved as a set of sub problems which in turn are made up of sub sub problems sub problems are then selected and used to solve the overall problem these sub problems are only solved once and the solutions are saved so that they will not need to be recalculated again whilst calculated individually they may also overlap when any sub problem is met again it can be found and re used to solve another problem since it searches all possibilities it is also very accurate this method is far more efficient than recalculating and therefore considerably reduces computation it is widely used in computer science and can be applied for example to compress data in high density bar codes  dynamic programming is most effective and therefore most often used on objects that are ordered from left to right and whose order cannot be rearranged this means it works well on character chains for example  \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and computer science dynamic programming is a method of problems that the of and the method than the used in the to the of problems where to find the best another this to the meaning the as a and that is the is in the of the a of dynamic programming which an optimization problem in the programming in dynamic programming to computer programming all and from the programming a for optimization the is the for that is for a of an is called a programming in this means an of an means that solutions of can be used to find the solutions of the overall problem for example the to a from a in a can be found the to the from all and then this to the best overall as in in can solve a problem a the problem solve these problems this these solutions to an solution for the problem the are solved sub and so on that is in the for the that it is not a a to that a problem is to that the are used to solve problems for example in the and number and are to a approach to may up more this are a approach may solutions to it solved in order to this the solutions to problems solved then need to solve the problem can and solution this approach is called not this also are need a solution can it to in can the solutions to that need in\n",
      "48.0, 250 finish at source in 516 and answer in 194\n",
      "ANSWER\n",
      "inheritance is one of the basic concepts of object oriented programming  its objective is to add more detail to pre existing classes whilst still allowing the methods and variables of these classes to be reused  the easiest way to look at inheritance is as an is a kind of relationship  for example a guitar is a kind of string instrument electric acoustic and steel stringed are all types of guitar the further down an inheritance tree you get the more specific the classes become  an example here would be books  books generally fall into two categories fiction and non fiction  each of these can then be sub divided into more groups  fiction for example can be split into fantasy horror romance and many more  non fiction splits the same way into other topics such as history geography cooking etc  history of course can be sub divided into time periods like the romans the elizabethans the world wars and so on \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: object oriented programming inheritance is a way to classes of are classes the inheritance for the classes as classes and of the pre existing classes are to as classes classes is to existing inheritance the for is a of to of is specific is to a a can be and to be each specific its inheritance is the is a a classes of for a is a of and many one can to be an of etc are an is a all the to all such as a for the of a an of inheritance is can a of the of the inheritance a many of inheritance is one more methods methods to an inheritance inheritance a is to the\n",
      "35.0, 120 finish at source in 308 and answer in 160\n",
      "ANSWER\n",
      "a websites page rank is how important it is on the web  it is essentially a popularity meter  popularity or importance is determined by the amount of links relating to the page there are there are four different types  inbound links from other pages to yours  outbound links from your page to others  dangling links to a page which has no links to others  deep links to a specific page usually bypassing the homepage  the page rank algorithm takes the probability of a random surfer becoming bored and requesting another random page otherwise known as the dampening factor away from 1 and divides this number by the number of pages in the system adding it to the dampening factor multiplied by the page rank of a linked page divided by the number of outbound links on that linked page  adding on this last section for every other page linked to from the original page  google uses this algorithm to assist intentional surfers in finding the best websites to suit their needs  one of the problems with this popularity algorithm is that it is easily manipulated and can give false values hence the frequent recalculating of page ranks \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: is a algorithm by the google that a to of a of as the web with the of importance the the algorithm to of with and the that it to is the of and by the is a of google and the has the is to and to google google has on the from the 1 in google in for of the the in for google on the of the web by as of page in google a from page a to page as a by page a for page google the of or links a page it the page that the by pages that are important and to other pages important in other a from a the other pages on the web how important a page is a to a page as a of the of a page is and on the number and of pages that to it links a page that is linked to by pages with a rank there are no links to a web page there is no for that page google a from for on the this a importance in the of google the is from a probability on a the the of a page is the of inbound links as as the of the pages the links it is known that other of on the page and to the page by the google the in to and google no specific how other page and original in the has to to and has to and to links from with other for web pages the algorithm by by and the and the algorithm\n",
      "58.0, 268 finish at source in 535 and answer in 197\n",
      "ANSWER\n",
      "the algebraic model for representing text documents and objects as vectors of identifiers is called the vector space model  it is used in information filtering indexing relevancy rankings and information retrieval it was first used in the smart information retrieval system  when a document is represented as a vector each dimension corresponds to a separate term a term which occurs in the document has a value in the vector of non zero other ways of computing these values or weights have been developed the most popular is tf idf weighting depending on the application the definition of term varies  single words keywords and occasionally longer phrases are used for terms  the dimensionality of the vector if words are used as terms is the total number of words available for use  by using the assumptions of the document similarities theory the relevancy rankings of documents in a keyword search can be worked out by comparing the deviation of angles between vectors both within the document and the original query where the vectors of both are the same type the limitations of the vector space model are thus  due to poor similarity values long documents are poorly represented  false positive matches may be returned if search keywords do not precisely match document terms  false negative matches could be returned when documents share a context but have different term vocabulary  vector space representation results in the loss of the order which the terms are in the document \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or term vector model is algebraic model for representing text documents and objects in as vectors of identifiers as for terms it is used in information filtering information retrieval indexing and relevancy rankings first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document value in the vector is non zero different ways of computing these values as term weights have been developed of the is tf idf weighting the the definition of term on the application terms are single words keywords or longer phrases if the words are to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of words in the the vector space model has the limitations long documents are poorly represented have poor similarity values a and a dimensionality search keywords precisely match document terms in a false positive match documents context but different term vocabulary be in a false negative match the order in which the terms in the document is in the vector space representation\n",
      "126.0, 192 finish at source in 242 and answer in 244\n",
      "ANSWER\n",
      "bayes theorem relates the conditional and marginal probabilities of two random events  it is mainly used to calculate the probability of one events outcome given that a previous event happened  for example the probability that a doctors diagnosis is correct given that the doctor had previously observed symptoms in the patient  bayes theorem can be used for all forms of probability however it is currently at the centre of a debate concerning the ways in which probabilities should be assigned in applications  the theorem states that the probability of event a happening given event b is the probability of b given a multiplied by the probability of a regardless of b all divided by the probability of b regardless of a which acts as a normalising constant  bayes theorem formed in this way basically details how ones beliefs about event a are renewed or updated knowing that event b happened  when calculating conditional probabilities such as these it is often useful to create a table containing the number of occurrences or relative frequencies of each outcome for each of the variables independently  \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability bayes theorem often bayes bayes relates the conditional and marginal probabilities of two random events it is often used to probabilities given for example a patient be observed to symptoms bayes theorem can be used to the probability that a diagnosis is correct given that example as a theorem bayes theorem is in all of probability however it a in the debate the of and about the ways in which probabilities should be assigned in applications probabilities to random events to frequencies of or to of as of the probabilities in of beliefs and of the probability and probability these in bayes theorem relates the conditional and marginal probabilities of events a and b b a probability a b b a a b each in bayes theorem a a is the probability or marginal probability of a it is in the that it about b a b is the conditional probability of a given b it is the probability it is or the of b b a is the conditional probability of b given a b is the or marginal probability of b and acts as a constant bayes theorem in this the way in which one beliefs about a are updated by observed b\n",
      "86.0, 207 finish at source in 306 and answer in 182\n",
      "ANSWER\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping sub problems and optimal substructure the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm dynamic programming usually takes one of two approaches the top down approach the problem is broken into sub problems and these sub problems are solved and the solutions remembered in case they need to be solved again this is recursion and memorization combined together and the bottom up approach all sub problems that might be needed are solved in advance and then used to build up solutions to larger problems this approach is slightly better in stack space and number of function calls but it is sometimes not intuitive to figure out all the sub problems needed for solving the given problem some programming languages can automatically memorize the result of a function call with a particular set of arguments in order to speed up call by name some languages make it possible portably e g scheme common lisp or perl  some need special extensions this is only possible for a referentially transparent function  \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping and optimal substructure the method takes the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the was a and that is by the bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of can be used to find the optimal solutions of the problem for the to a from a in a can be by the to the from all and then this to the best in figure in can a problem with optimal substructure a process the problem into these problems this process these optimal solutions to an optimal for the problem the are solved by into sub and some case that is in figure the for the that it is not a but a overlapping to that a problem has overlapping is to that the are used to larger problems for in the and number and are needed to a approach to up or this overlapping are a approach optimal solutions to it has solved in order to this instead the solutions to problems solved then need to the problem can and this approach is called not memorization this term are need a particular can it to space in some can the solutions to that need in advance\n",
      "188.0, 339 finish at source in 516 and answer in 310\n",
      "ANSWER\n",
      "inheritance is a method of forming new classes using predefined classes the new classes are called derived classes and they inherit the behaviours and attributes of the base classes it was intended to allow existing code to be used again with minimal or no alteration it also offers support for representation by categorization in computer languages this is a powerful mechanism of information processing vital to human learning by means of generalization and cognitive economy inheritance is occasionally referred to as generalization due to the fact that is a relationships represent a hierarchy between classes of objects inheritance has the advantage of reducing the complexity of a program since modules with very similar interfaces can share lots of code due to this inheritance has another view called polymorphism where many sections of code are being controlled by some shared control code inheritance is normally achieved by overriding one or more methods exposed by ancestor or by creating new methods on top of those exposed by an ancestor inheritance has a variety of uses each different use focuses on different properties for example the external behaviour of objects internal structure of an object inheritance hierarchy structure or software engineering properties of inheritance occasionally it is advantageous to differentiate between these uses as it is not necessarily noticeable from context  \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object inheritance is a to new classes of are called objects using classes that the inheritance was in for the new classes as derived classes or inherit attributes and of the existing classes are referred to as base classes or ancestor classes it is intended to existing code with or no inheritance the support for representation by categorization in computer languages categorization is a powerful mechanism of information processing to human learning by means of generalization is is to a a can be and cognitive economy information to be each inheritance is also called generalization the is a relationships represent a hierarchy between classes of objects for a is a generalization of and many one can to be an of since are an is a inherit the properties to as being a for the of a an advantage of inheritance is that modules with similar interfaces can share a of code reducing the complexity of the program inheritance has another view a called polymorphism many of code being controlled by shared control code inheritance is by overriding one or more methods exposed by ancestor or by new methods to those exposed by an ancestor inheritance or inheritance used a that is not to the\n",
      "117.0, 205 finish at source in 308 and answer in 218\n",
      "ANSWER\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale pagerank is a probability distribution used to represent the likelihood that a person randomly clicking on links will arrive at any particular page pagerank can be calculated for collections of documents of any size it is assumed in several research papers that the distribution is evenly divided between all documents in the collection at the beginning of the computational process the pagerank computations require several passes called iterations  through the collection to adjust approximate pagerank values to more closely reflect the theoretical true value a probability is expressed as a numeric value between 0 and 1 a 0 5 probability is commonly expressed as a 50 chance of something happening hence a pagerank of 0 5 means there is a 50 chance that a person clicking on a random link will be directed to the document with the 0 5 pagerank the pagerank theory holds that even an imaginary surfer who is randomly clicking on links will eventually stop clicking the probability at any step that the person will continue is a damping factor d various studies have tested different damping factors but it is generally assumed that the damping factor will be set around 0 85  \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm be to any collection of with and the numerical that it assigns to any element is called the pagerank of and by the pagerank is a of google and the pagerank process s the is to and to google google on the from the 1 in google in for of the the in for google pagerank pagerank on the of the web by its link as an of an page s value in google a link from page a to page as a by page a for page but google at more the of links a page it the page that the by that more and to in a pagerank from a all the on the world wide web a page is a to a page as a of the pagerank of a page is and on the and pagerank of all that link to it links a page that is to by with pagerank a there links to a web page there is for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is the of links as as the pagerank of the the links it is that factors of search on the page and to the page by the google the pagerank in to and google factors pagerank papers pagerank have page and s in the pagerank to be to and research to pagerank and to links from documents with pagerank link for web the algorithm by used by and the and the algorithm\n",
      "112.0, 334 finish at source in 535 and answer in 284\n",
      "ANSWER\n",
      "within information retrieval each document in a set can be represented as a point in high dimensional vector space this representation is called the vector space model information retrieval queries are also represented as vectors in the same vector space these are then used in conjunction with the document vectors to find relevant documents the two vectors are compared and the documents with a higher document query similarity are ranked higher in terms of relevance there are a variety of techniques that can be used to compare the two vectors the most frequently used method for the vector space model is the cosine coefficient which calculates the angle between the two vectors and produces a value between 0 and 1  \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model vector model is model for documents and in as vectors of as for terms is used in information information retrieval and in the information retrieval a document is represented as a vector each to a a in the document value in the vector is of these also as of the is the the of the terms are the are to be the terms the of the vector is the of in the the of in the the vector space model the 1 documents are represented similarity a and a document terms in a documents with be in a the in which the terms in the document is in the vector space representation\n",
      "31.0, 115 finish at source in 242 and answer in 120\n",
      "ANSWER\n",
      "bayes theorem is a mathematical formula used to calculate conditional probabilities given the probability of event a given event b bayes theorem can be used to calculate the probability of b given a  this is achieved using the conditional probability of b given a and the prior probabilities of both events a and b for example suppose there is a bag of coloured balls with 25 red ones and 75 black ones lucky joe likes to predict the colour of the ball he selects and he is 80 accurate joe records all of his results and about 0 5 of the time he accidently records the wrong results using all of this information more probabilities can be inferred including using bayes theorem to calculate various probabilities like joe recording correctly if he guesses correctly or joe recording incorrectly when his guess was correct and other like combinations  \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: probability bayes theorem bayes bayes the conditional and probabilities of events is used to probabilities given for example a be to bayes theorem can be used to the probability a is correct given example a theorem bayes theorem is all of probability a the the of and about the probabilities be probabilities to events to of or to of of the probabilities of and of the probability and probability bayes theorem the conditional and probabilities of events a and b b a probability a b b a a b bayes theorem a a is the prior probability or probability of a is prior the information about b a b is the conditional probability of a given b is the probability is or the of b b a is the conditional probability of b given a b is the prior or probability of b and a bayes theorem this the about a b\n",
      "41.0, 152 finish at source in 306 and answer in 147\n",
      "ANSWER\n",
      "dynamic programming is a faster method of solving problems that make use of optimal substructure overlapping sub problems and memoization it has no relationship to computer programming instead it is a process of finding a satisfactory algorithm  optimal substructure is the process of using the optional solutions to sub problems to find the optimal solution to the overall problem when the same sub problem solutions can be used to solve various bigger problems it is said to have overlapping sub problems memoization is used in order to save time the solutions are stored rather than be recomputed a solution can be disposed of once we are positive that it will no longer be required in some cases a solution to a future problem can be computed in advance  there are two main approaches for dynamic programming the first is the bottom up approach although it is not always simple to find all of them any required sub problems are solved in advance and then used to create solutions to larger problems the other method is the top down approach which is a method that combines memorization and recursion the main problem is divided into sub problems which are solved and stored for future use \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and computer dynamic programming is a method of solving problems that the of overlapping and optimal substructure the method time than the used in the to the process of solving problems to find the to the the a and that is the is in the of the a of dynamic programming which problem in the programming in dynamic programming has no to computer programming all and instead the programming a for the is the optimal for that is for a of is a programming in finding of algorithm optimal substructure that optimal solutions of can be used to find the optimal solutions of the overall problem for the to a a in a can be first the to the all and then using to the overall in in we can solve a problem optimal substructure using a process the problem into solve problems using process use optimal solutions to optimal solution for the problem the are solved them into sub and we some simple that is in time the for the that it is not a a overlapping to that a problem has overlapping is to that the same are used to solve larger problems for in the and and are to a approach to up overlapping are a approach time optimal solutions to it has solved in order to we instead save the solutions to problems we have solved then we to solve the same problem we can and computed solution approach is memoization not memorization although we are we a solution we can it to save in some cases we can the solutions to we that we in advance\n",
      "70.0, 272 finish at source in 516 and answer in 204\n",
      "ANSWER\n",
      "inheritance allows programs developed in an object orientated language to reuse code without having it replicated unnecessarily elsewhere within the program  to achieve this the programmer has to note generalisations and similarities about various aspects of the program  for example a program could exist to model different forms of transport at first glance a car and a train may not have much in common but abstractly both will have a speed at which they are travelling a direction and a current position methods utilising this data can be specified high up in the inheritance hierarchy for example in a transport class for example you could have a method which works out the new position of a train after travelling x minutes in direction y likewise you might want to be able to find out the same information for an object of the type car  inheritance means that if such a method was defined in the superclass of the train and car classes any car or train object can utilise it  the train and car subclasses are said to extend the transport class as they will have additional characteristics which they dont share e g passenger capacity would be a class variable of both car and train but have different values  and a train may have methods along the lines of is toilet engaged if you then wanted to add additional forms of transport such as an aeroplane you may wish for that also to have a toilet engaged function then you could have an extended hierarchy where a mass transport class extends the transport class under which youd have a train and aeroplane which would inherit characteristics from both super classes \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object inheritance is a to new classes of which are classes that have defined the inheritance was in for the new classes as classes or inherit and of the classes which are to as classes or classes it is to reuse code or inheritance the for in is a of information to means of is about is to a a can be and information to be about inheritance is also the is a a hierarchy classes of for a is a of and can to be an of are e an is a may inherit the common to such as a for the of a an of inheritance is that can share a of code the of the program inheritance has a which of code code inheritance is or methods or new methods to an inheritance or inheritance within a that is not may to the\n",
      "43.0, 147 finish at source in 308 and answer in 281\n",
      "ANSWER\n",
      "the algorithm that google uses to assign a weighting to each element of a linked set of documents with the purpose of measuring its relative importance within the set  a particular websites pagerank results from a vote from other pages on the internet about how important that website actually is a link to a page is seen as a vote of support the pagerank depends on the pagerank rating and number of all pages that have links to it additionally if a page is linked to by pages with a high pagerank rating this increases the rating of the original page the pagerank scale ranges from 0 10 the rating of a certain page is generally based upon the quantity of inbound links as well as the perceived quality of the pages providing the links  pagerank could be described as a probability distribution representing the chance that someone randomly clicking on links will reach a certain page the pagerank calculations require iterations through the collection of web pages to alter approximate pagerank values to accurately reflect the actual rank in order to prevent spamming google releases little information on the way in which a pagerank is calculated the pagerank algorithm has led to many sites being spammed with links in an attempt to artificially inflate the pagerank of the linked page notably in blog comments and message boards in 2005 a nofollow tag was added as an attribute of a html link to be used where google shouldnt change the pagerank of the linked page as a result of the link \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link algorithm used by the google internet that a weighting to each element of a set of documents as the web with the purpose of measuring its relative importance within the set the algorithm be to collection of with and the that it to element is the pagerank of and by the pagerank is a of google and the pagerank has the is to and to google google has on the from the in google in of the the in 2005 google pagerank pagerank on the of the web by its link as an of an page in google a link from page a to page as a vote by page a page google the of links a page it the page that the vote by pages that important and to other pages important in other a pagerank results from a all the other pages on the web about how important a page is a to a page as a vote of support the pagerank of a page is and depends on the number and pagerank of all pages that link to it links a page that is linked to by many pages with high pagerank a high rank if links to a web page is support that page google a weighting from 0 10 each on the internet this pagerank a importance in the of google the pagerank is from a probability on a scale the scale the pagerank of a particular page is based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is that other of on the page and actual to the page by the google the pagerank in order to prevent and google about how other pagerank pagerank have page and original in the pagerank has to be to and has to pagerank and to links from documents with pagerank other link based web pages the algorithm by used by and the and the algorithm\n",
      "119.0, 332 finish at source in 535 and answer in 261\n",
      "ANSWER\n",
      "a vector space model or term vector model is an algebraic way of representing text documents and any objects in general as vectors of identifiers such as index terms it is used in information filtering information retrieval indexing and relevancy rankings its first application was in the smart information retrieval system a document can be represented as a vector every dimension relates to a different term if a term appears in the document the terms value in the vector is non zero many different methods of calculating these values sometimes known as term weights have been developed tf idf weighting is one of the most well known schemes  see below example  the definition of a term depends on the application normally a term is a single word keyword or a longer phrase if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has some limitations 1 longer documents are represented poorly because the documents have poor similarity values namely a small scalar product and a large dimensionality 2 search keywords have to precisely match document terms word substrings could potentially result in a false positive match 3 semantic sensitivity documents with a similar context but different term vocabulary won t be associated resulting in a false negative match  4 the order in which terms appear in the document is lost in a vector space representation \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or term vector model is an algebraic model representing text documents and any objects in general as vectors of identifiers such as example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first was in the smart information retrieval system a document is represented as a vector dimension to a term if a term in the document its value in the vector is non zero different of these values known as term weights have been developed one of the known schemes is tf idf weighting see the example below the definition of term depends on the application terms are single words keywords or longer if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus the vector space model has the limitations 1 documents are poorly represented because have poor similarity values a small scalar product and a large dimensionality 2 search keywords precisely match document terms word substrings result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation\n",
      "205.0, 223 finish at source in 242 and answer in 250\n",
      "ANSWER\n",
      " in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications  suppose there is a co ed school having 60 boys and 40 girls as students the girl students wear trousers or skirts in equal numbers the boys all wear trousers an observer sees a random student from a distance all they can see is that this student is wearing trousers what is the probability this student is a girl the correct answer can be computed using bayes theorem the event a is that the student observed is a girl and the event b is that the student observed is wearing trousers to compute p a b  we first need to know p b a  or the probability of the student wearing trousers given that the student is a boy this is given as 1 p a  or the probability that the student is a girl regardless of any other information since the observers sees a random student meaning that all students have the same probability of being observed and the fraction of girls among the students is 40  this probability equals 0 4 p a  or the probability that the student is a boy regardless of any other information a is the complementary event to a  this is 60  or 0 6 p b a  or the probability of the student wearing trousers given that the student is a girl as they are as likely to wear skirts as trousers this is 0 5\n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation see example as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications probabilities to random events to of or to of as of the probabilities in of and of the bayesian probability and frequentist probability in bayes theorem relates the conditional and marginal probabilities of events a and b b a probability p a b p b a p a p b in bayes theorem a p a is the probability or marginal probability of a it is in the that it any information about b p a b is the conditional probability of a given b it is called the posterior probability it is from or the of b p b a is the conditional probability of b given a p b is the or marginal probability of b and as a bayes theorem in this the in which about a are having observed b\n",
      "153.0, 242 finish at source in 306 and answer in 340\n",
      "ANSWER\n",
      "dynamic programming is a very powerful mathematical technique often utilised in programming for solving optimization problems normally minimizing or maximizing  greedy algorithms focus on making the best local choice at each decision making stage without a proof of correctness such an algorithm is likely to fail with dynamic programming we can design our own algorithm which searches for all possibilities which ensures correctness whilst storing the results to avoid having to recomputed leading to computational efficiency  dynamic programming solves problems by combining the solutions of subproblems these subproblems are not however independent subproblems can share subsubproblems but the solution to one subproblem doesn t necessarily affect the solutions to other subproblems stemming from the same problem dynamic programming reduces computation time by solving subproblems in a bottom up way it stores the solution to a subproblem the first time it is solved meaning that it can look up the solution when that subproblem is encountered subsequently  the key to dynamic programming is to find the structure of optimal solutions the steps required are as follows 1 generalise the structure of an optimal solution 2 recursively define the value of an optimal solution 3 compute the optimal solution values either top down with caching  or bottom up using a table 4 generate the optimal solution of these computed values \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in dynamic programming is a of solving problems that the of subproblems optimal the time the in the by to the of solving problems one to find the best one by to the meaning the as a that is by the is in the of the a of dynamic programming which an optimization problem in the programming in dynamic programming to programming at all from the mathematical programming a for optimization the is the optimal for that is for a of at an is a programming in an of an algorithm optimal that optimal solutions of subproblems can to find the optimal solutions of the problem for the to a from a in a can by first the to the from all using to the best as in 1 in we can a problem with optimal using a 1 the problem subproblems 2 these problems using recursively 3 these optimal solutions to an optimal solution for the problem the subproblems are solved by subproblems on we that is in time 2 the subproblem for the that it is not a but a subproblems to that a problem subproblems is to that the same subproblems are to problems for in the each are to compute a to up or subproblems are a time optimal solutions to subproblems it solved in to avoid we the solutions to problems we solved we to the same problem we can our computed solution is not we are we t a solution we can it to in we can compute the solutions to subproblems we that we in\n",
      "50.0, 262 finish at source in 516 and answer in 218\n",
      "ANSWER\n",
      " inheritance is an important feature in object orientated programming this is because it allows new classes to be made that extend previous classes and to go into more detail  this is carried out by allowing the new class to reuse the existing class methods and variables whilst also creating class specific methods and variables this means that the new class the subclass is a more specialised version of the original or superclass  because of this it means that the subclass can use all the public methods and variables from the superclass however any private methods or variables are still private  also it should be noted that a class can only extend one class e g can only be a subclass to one superclass however a superclass can have more then one subclass and a class can both be a subclass and a superclass if this occurs then all of the non private methods and variables can be used by the most specialised class  this means that inheritance is used when types have common factors and these would be put into the superclass then the subclass es then extend these to add more detail an example of this could be using a superclass of employee and then to have two subclasses called fulltime and part time as employee could have name address and other details whilst full time could just have salary and part time could work out the salary from part time hours worked as the full time members of staff wouldnt need these \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object programming inheritance is a to new classes of are called using classes that have the inheritance in the new classes as classes or and of the existing classes are to as classes or classes it is to reuse existing or inheritance the by in is a of to by means of is specific is to a a can be and to be specific only inheritance is also called because the is a a classes of a is a of and one can to be an of are e an is a all the common to all as a the of a an of inheritance is that can a of the of the inheritance a called of by inheritance is by one or more methods by or by new methods to by an inheritance or inheritance used a that is to the\n",
      "42.0, 143 finish at source in 308 and answer in 254\n",
      "ANSWER\n",
      "the first thing to consider when talking about googles pagerank algorithm is that a pagerank is essentially how important that web page is to the internet so in essence it is a popularity contest between webpages  originally search engines used highest keyword density however this could be abused if keyword spamming was implemented instead google uses a system that is based on sites linking to each other e g the more important a site is that is linked to yours the higher your site will become  the algorithm google actually users is based on 4 factors total number of pages dampening factor pagerank of a single page and the number of outbound links a dampening factor is used to counter random surfers who get bored and then switch to other pages this formula is then re used until the results seem to converge together to find the pagerank so it is calculated iteratively  pagerank is used by google to measure a popularity of the site and a number between 0 10 is assigned to each webpage depending on their pagerank this allows google to calculate a marketing value for different webpages  also it should be noted that the pagerank is periodically updated every 3 to 6 months this is counter hackers influence on different pageranks \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a algorithm used by the google internet search that a to each of a of the web the of the the algorithm be to of and the that it to e is also the pagerank of e and by e the pagerank is a of google and the pagerank 6 however the is assigned to and to google google on the the in google in for of the the in for google pagerank pagerank on the of the web by of page value in essence google a page a to page a by page a for page google more the of links a page it also the page that the by pages that important more and to other pages important in other a pagerank results a the other pages on the web about how important a page is a to a page a of the pagerank of a page is and on the number and pagerank of pages that to it links a page that is linked to by pages pagerank a if links to a web page is for that page google a 0 10 for each webpage on the internet this pagerank a site in the of google the pagerank is a value on a the the pagerank of a page is based the of links the pagerank of the pages the links it is that other factors e g of search on the page and to the page by the google also influence the pagerank in to and google about how other factors influence pagerank pagerank page and in the pagerank to be to and to pagerank and to links pagerank other based for web pages the algorithm by used by and the and the algorithm\n",
      "56.0, 291 finish at source in 535 and answer in 215\n",
      "ANSWER\n",
      "a vector space model is an algebraic model for representing text documents as vectors of identifiers a possible use for a vector space model is for retrieval and filtering of information other possible uses for vector space models are indexing and also to rank the relevancy of differing documents to explain further vector space models basically a document is characterized by a vector with each separate term corresponding to the differing dimensions there has been multiple ways of trying to compute the different possible values for vector space models with the most recognised being the tf idf weighting the differing application has a direct influence on what the definition of the term means a normal term is usually a single word keywords or longer phrases the number of unique words in the vocabulary denotes the dimensionality if words are used for the terms however whilst vector space modelling is useful there are 4 key problems with using it they are that the order of the terms are lost keywords must be precise if searched for bigger documents have a poor similarity value due to being poorly represented and two documents based on the same topic wont be associated if term vocabulary differs \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or term vector model is an algebraic model for representing text documents and in as vectors of identifiers as for terms it is used in information filtering information retrieval indexing and relevancy use in the information retrieval a document is represented as a vector each to a separate term if a term in the document value in the vector is different ways of values also as term have been of the is tf idf weighting the the definition of term on the application terms are single words keywords or longer phrases if the words are to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of words in the the vector space model has the documents are poorly represented they have poor similarity values a and a dimensionality keywords must document terms word in a documents with different term vocabulary be associated in a 4 the order in the terms in the document is lost in the vector space\n",
      "69.0, 171 finish at source in 242 and answer in 202\n",
      "ANSWER\n",
      " in probability theory bayes theorem also called bayes law after rev thomas bayes compares the conditional and marginal probabilities of two random events it is often used to calculate posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to calculate the likelihood that a proposed analysis is accurate given that observation  as an official theorem bayes theorem is valid in all universal interpretations of probability however it plays a fundamental role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications  frequentists assign probabilities to random events according to their frequencies of happening or to subsets of populations as proportions of the whole whilst bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem compares the conditional and marginal probabilities of events a and b where b has a non vanishing probability each term in bayes theorem has a conventional name p a is the previous probability of a it is previous in the sense that it does not take into account any information about b p a b is the conditional probability of a given b it is also called the subsequent probability because it is derived from or depends upon the specified value of b p b a is the conditional probability of b given a p b is the previous \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability theory bayes theorem often called bayes law after rev thomas bayes the conditional and marginal probabilities of two random events it is often used to posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to the probability that a proposed is given that observation example as a theorem bayes theorem is valid in all interpretations of probability however it plays a role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of or to subsets of populations as proportions of the whole bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b p b a p a p b each term in bayes theorem has a conventional name p a is the probability or marginal probability of a it is in the sense that it does not take into account any information about b p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b p b a is the conditional probability of b given a p b is the or marginal probability of b and as a bayes theorem in the in which beliefs about a observed b\n",
      "237.0, 274 finish at source in 306 and answer in 255\n",
      "ANSWER\n",
      " in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure the method takes much less time than naive methods the term was originally used in the 1940s to describe the process of solving problems where one needs to find the best decisions one after another  the field was founded as a systems analysis and engineering topic that is recognized by the ieee the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure the method takes much less time than naive methods the term was originally used in the 1940s by to describe the process of solving problems where one needs to find the best decisions one after another by this to the the field was founded as a systems analysis and engineering topic that is recognized by the ieee is in the of the a of dynamic programming an optimization problem in the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as in 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time 2 the graph for the that is a a overlapping subproblems to that a problem has overlapping subproblems is to that the subproblems are used to solve problems for example in the and computing computing and are to a naive to computing computing this overlapping subproblems are a naive time optimal solutions to subproblems has solved in to this we instead the solutions to problems we solved then we to solve the problem we can and solution this is called this term we are we a particular solution we can to in some we can the solutions to subproblems we that we in\n",
      "275.0, 399 finish at source in 516 and answer in 275\n",
      "ANSWER\n",
      "inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code  inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  in defining this inheritance hierarchy we have already defined certain restrictions not all of which are desirable singleness using single inheritance a subclass can inherit from only one superclass visibility whenever client code has access to an object it generally has access to all the object s superclass data static the inheritance hierarchy of an object is fixed at instantiation when the object s type is selected and does not change with time \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance in the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes it is intended to help reuse existing code with little or no modification inheritance the by in is a of to by of is known is to a a can and to only inheritance is called the is a a hierarchy classes of objects a is a of and many one can to an of are an is a inherit all the to all as being a the of a an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor inheritance or inheritance a that is not sufficiently to the\n",
      "138.0, 205 finish at source in 308 and answer in 206\n",
      "ANSWER\n",
      "the pagerank is a recursive algorithm used by google to determine which webpages are more important than others the algorithm considers the importance of a webpage to be reflected by how many other webpages link to that page and the importance of those pages  for each page that links to a page a the pagerank between zero and one is calculated iteratively according to the following two key factors the probability of a user navigating away from a page randomly the pagerank of any page that links to a divided by the total number of outbound links from that page this assumes that a link among many outbound links is less valuable than a link among fewer outbound links a variation of the pagerank method bases the importance of a webpage on how many visits the page gets  the method can be abused when people deliberately link to sites in order to raise a site s pagerank however it is still a good indicator for search engines to use as a variable in deciding on the most appropriate results according to a query  \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link algorithm used by the google search that a to each of a of as the the of importance the the algorithm be to any of and the that it to any is the pagerank of and by the pagerank is a of google and the pagerank s however the is to and to google google on the from the in google in for use of the the in for google pagerank pagerank on the of the by link as indicator of page s in google a link from page a to page as a by page a for page google more than the of links a page it the page that the by pages that are important more and to other pages important in other a pagerank results from a among the other pages on the how important a page is a to a page as a of the pagerank of a page is and on the number and pagerank of pages that link to it links a page that is to by many pages pagerank a are links to a page is for that page google a from for each webpage on the this pagerank a site s importance in the of google the pagerank is from a probability on a the the pagerank of a page is the of links as as the pagerank of the pages the links it is that other factors of search on the page and visits to the page by the google the pagerank in order to and google how other factors pagerank pagerank page and s in the pagerank to be to and to pagerank and to links from pagerank other link for pages the algorithm by used by and the and the algorithm\n",
      "65.0, 296 finish at source in 535 and answer in 183\n",
      "ANSWER\n",
      "in the vector space model vsm  documents take the form of bags of words  a standard information retrieval approach which represents documents as in a mathematical bag structure recording what terms are present and how often they occur  the vector space model is used in information retrieval to determine how similar documents are to one another and how similar documents are to a search query  in a collection of documents each document can be viewed as a vector of n values the terms in the document  where each term is an axis queries can also be represented as vectors on this vector space model and so deciding which document matches the query the closest becomes a matter of selecting the document vector which is nearest to the query vector  the query vector is compared to each document vector in turn using a vector similarity measure  which is the cosine of the angle between the query vector and the document vector  this equation is calculated by dividing the dot product of the query vector and the document vector by the modulus of the query vector multiplied by the modulus of the document vector the denominator takes into account differences in the length of the vector and has the effect of normalising the length whichever document returns the highest cosine similarity score is considered to be the closest matching document to the query  \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model term vector model is an model documents and in as vectors of as terms is used in information information retrieval and in the information retrieval a document is represented as a vector each to a term a term in the document in the vector is of values also as term one of the is the the of term on the terms are words the words are to be the terms the of the vector is the of words in the the of words in the the vector space model has the documents are represented they similarity values a product and a search document terms in a documents similar term be in a the in which the terms in the document is in the vector space\n",
      "54.0, 128 finish at source in 242 and answer in 231\n",
      "ANSWER\n",
      "in probability theory bayes theorem relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations  bayes theorem is expressed mathematically as  p a b p b a p a  p b  where p a b is the conditional probability of a given b p a is the prior probability of a p b is the prior probability of b and p b a is the conditional probability of b given a  bayes theorem relates the conditional and marginal probabilities of two random events p a and p b  and is valid in all common interpretations of probability for example in a school in made up of 3 5 boys and 2 5 girls the girls wear skirts of trousers in equal numbers and the boys all wear trousers if a student is observed from a distance wearing trousers bayes theorem can be used to determine the probability of this student being a girl  p a is the probability of the student being a girl which is 2 5  p b a is the probability of the student wearing trousers given that the student is a girl which is 0 5 p b is the probability of a random student wearing trousers which can be calculated as p b  p b a p a  p b a p a  where  denotes a complementary event which is 0 8  therefore the probability using the formula is 0 25  bayes theorem is often used to compute posterior probabilities given observations for instance the probability that a proposed medical diagnosis is correct given certain observed symptoms  \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability theory bayes theorem often bayes bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a be observed to certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that example 2 as a theorem bayes theorem is valid in all common interpretations of probability it a in the the of and interpretations the in which probabilities be in probabilities to random events to of to of as of the probabilities in of and of the probability and probability in bayes theorem relates the conditional and marginal probabilities of events a and b where b a probability p a b p b a p a p b in bayes theorem a p a is the prior probability marginal probability of a it is prior in the that it b p a b is the conditional probability of a given b it is the posterior probability it is from the of b p b a is the conditional probability of b given a p b is the prior marginal probability of b and as a bayes theorem in this the in which a observed b\n",
      "95.0, 207 finish at source in 306 and answer in 272\n",
      "ANSWER\n",
      "dynamic programming is a problem solving method which solves recursive problems the term is derived from mathematical programming which is commonly referred to as optimisation hence dynamic programming is an optimal method of solving the problems and takes much less time than na ve methods  dynamic programming uses the properties of optimal substructure overlapping subproblems and memoization to create an algorithm to solve such problems optimal substructure means that the structure of the problem is made up of sub problems which can be used to find the solution to the problem overall a problem with overlapping subproblems means that the same subproblems may be used to solve many different larger problems each sub problem is solved by being divided into sub subproblems until a case is reached which is solvable in constant time memoization stores solutions which have already been computed in order to reduce unnecessary re computation  dynamic programming can be divided into two main approaches top down and bottom up the top down approach breaks the problem into subproblems which are solved and remembered using a combination of memoization and recursion the bottom up approach solves all subproblems that might be need in advance and then uses these solutions to build up the solutions to the bigger problem  \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and dynamic programming is a method of solving problems that the properties of overlapping subproblems and optimal substructure the method takes much less time than methods the term used in the by to the of solving problems to find the by to the the as a and that is by the is remembered in the of the a of dynamic programming which an problem in recursive the programming in dynamic programming to programming all and from the term mathematical programming a the is the optimal that is a of an is a programming in means an of an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem the to a from a in a can be by the to the from all and then using to the overall as in in can solve a problem with optimal substructure using a the problem into subproblems solve these problems using these optimal solutions to an optimal solution the problem the subproblems are solved by into sub subproblems and until case that is solvable in constant time the the that is a a overlapping subproblems to that a problem overlapping subproblems is to that the same subproblems are used to solve many different larger problems in the and each and are to a approach to may up overlapping subproblems are a approach may time optimal solutions to subproblems already solved in order to the solutions to problems have already solved then need to solve the same problem can and already computed solution approach is memoization term are need a solution can to in can the solutions to subproblems that need in advance\n",
      "73.0, 282 finish at source in 516 and answer in 210\n",
      "ANSWER\n",
      "when we talk about inheritance in object oriented programming languages which is a concept that was invented in 1967 for simula we are usually talking about a way to form new classes and classes are instances of which are called objects and involve using classes that have already been defined  derived classes are intended to help reuse existing code with little or no modification and are the new classes that take over or inherit attributes and behavior of the pre existing classes usually referred to as base classes or ancestor classes  categorization in computer languages is a powerful way number of processing information and inheritance provides the support for representation by categorization furthermore  it is fundamental for helping humans learn by means of generalization in what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive processing which involves less information being acquired to be stored about each specific entity but in actual fact only its particularities an instance of a fruit is a generalization of apple  orange  mango and many others inheritance can also sometimes be referred to as generalization because is a relationships represent a hierarchy amongst classes of objects it can be considered that fruit is an abstraction of apple orange etc conversely since apples are fruit they may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  modules with sufficiently similarities in interfaces would be able to share a lot of code and therefore reducing the complexity of the program this can be known as one of the advantages of inheritance therefore inheritance can be known to have a further view a dual which describes many parts of code that are under control of shared control code named as polymorphism  on the other hand inheritance is normally accomplished either by replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor a well known term used for this replacing act is called overriding \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes it is intended to help reuse existing code with little or no modification inheritance provides the support for representation by categorization in computer languages categorization is a powerful number of information processing to by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive less information to be stored about each specific entity only its particularities inheritance is also sometimes called generalization because the is a relationships represent a hierarchy classes of objects for instance a fruit is a generalization of apple orange mango and many others one can fruit to be an abstraction of apple orange etc conversely since apples are fruit an apple is a fruit apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant an of inheritance is that modules with sufficiently interfaces can share a lot of code reducing the complexity of the program inheritance therefore view a dual called polymorphism which describes many of code being by shared control code inheritance is accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor inheritance or inheritance used a that is sufficiently may to the\n",
      "197.0, 282 finish at source in 308 and answer in 347\n",
      "ANSWER\n",
      "pagerank is a link analysis algorithm that is used by search engine such as google internet that assigns a numerical weighting to every element of a hyperlinked set of documents like the world wide web with the hope of measuring the relative importance held in the set the algorithm may be applied to any numbr of entities with reciprocal quotations and references the weight taking a numerical value which assigns to any given element e is also known as the pagerank of e and is denoted by pr e  a trademark of google has the name pagerank  and this process has been patented u s patent 6 285 999  nevertheless the patent is assigned to the university of stanford and not to google google has exclusive license rights on the patent from the university of stanford and the university received 1 8 million shares in google in exchange for use of the patent the in the year 2005 shares were sold for 336 million \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to element of a hyperlinked set of documents such as the world wide web with the of measuring relative importance the set the algorithm may be applied to any of entities with reciprocal quotations and references the numerical weight that assigns to any given element e is also the pagerank of e and denoted by pr e the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999 the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google pagerank pagerank on the of the web by link as of s value in google a link from a to as a by a for google the of a also the that the by that and to in a pagerank from a the on the world wide web a is a to a as a of the pagerank of a is and on the and pagerank of that link to a that is to by with pagerank a to a web is for that google assigns a weighting from for on the internet this pagerank a s importance in the of google the pagerank is from a value on a like the the pagerank of a is the of as as the pagerank of the the is known that e of search on the and to the by the google also the pagerank in to and google pagerank pagerank been and s in the pagerank has to be to and has been to pagerank and to from documents with pagerank link for web the algorithm by used by and the and the algorithm\n",
      "127.0, 327 finish at source in 535 and answer in 164\n",
      "ANSWER\n",
      "nformation retrieval ir is the science of searching for documents for information within documents and for metadata about documents as well as that of searching relational databases and the world wide web ir is interdisciplinary based on computer science mathematics library science information science information architecture cognitive psychology linguistics statistics and physics there is overlap in the usage of the terms data retrieval document retrieval information retrieval and text retrieval but each also has its own body of literature theory praxis and technologies  automated information retrieval systems are used to reduce what has been called information overload  many universities and public libraries use ir systems to provide access to books journals and other documents  \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: is for text documents and in as of as for terms is used in information information retrieval and its use in the information retrieval document is as each to in the document its in the is of also as been of the is the the of on the terms are the are to the terms the of the is the of in the the of in the the has the documents are and document terms in documents but in the in the terms in the document is in the\n",
      "22.0, 89 finish at source in 242 and answer in 114\n",
      "ANSWER\n",
      "the probability of an event happening mean considering the likelihood of or the number of the instance occurring and dividing this value by the total number of events the equation for this calculation would look as follows probability p  number of instance  total number of events on the other hand probability theory p usually involves assigning values to events for example  p 1 event is certain to occur p 0 event is certain not to occur p 0 5 event occurs half of the time  there is also conditional probability which is usually interested in the way variables relate to each other bayes theorem is the name given to an important theorem relating conditional probabilities and it can be seen as a way of understanding how the probability that a theory is true is affected by a new piece of evidence it has been used in a wide variety of contexts ranging from marine biology to the development of bayesian spam blockers for email systems  \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability theory bayes theorem bayes bayes the conditional and probabilities of events it is used to probabilities given for example a be to certain bayes theorem can be used to the probability that a is given that example as a theorem bayes theorem is in of probability it a in the the of and bayesian the in which probabilities be in probabilities to events to of or to of as of the probabilities in of and of the on bayesian probability and probability in bayes theorem the conditional and probabilities of events a and has a probability p a p a p a p each in bayes theorem has a name p a is the probability or probability of a it is in the that it not p a is the conditional probability of a given it is also the probability it is from or the value of p a is the conditional probability of given a p is the or probability of and as a bayes theorem in this the way in which a by\n",
      "36.0, 177 finish at source in 306 and answer in 165\n",
      "ANSWER\n",
      "dynamic programming dp is in basic terms an algorithm design technique that is used for optimization problems and often involves minimizing or maximizing  furthermore by combining solutions to subproblems dp solves problems subproblems may include and contain many other subsubproblems and even in such cases the solution to one subproblem may not affect the solutions to other subproblems involved in the same problem  by solving subproblems in a bottom up fashion which is basically when storing solution to a subproblem the first time it is solved and looking up to find the solution when a subproblem is come across once more  this would cause dp to reduce computations  the following is a generalization path to be taken in dynamic programming firstly it is needed to characterize the structure of an optimal solution secondly to define the value of the optimal solution recursively furthermore to compute the optimal solution values either by following a top down method with caching or a bottom up method in a table the last point would be to construct an optimal solution from the computed values \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and dynamic programming is a method of solving problems that the of subproblems and optimal the method time the used in the by to the of solving problems one to find the one by this to the the a and that is by the is in the of the a of dynamic programming which an optimization problem in the programming in dynamic programming to programming and from the programming a for optimization the is the optimal for that is for a of an is a programming in this an of an algorithm optimal that optimal solutions of subproblems be used to find the optimal solutions of the problem for the path to a from a in a be by first the path to the from and this to the path in in a problem with optimal a the problem subproblems problems this recursively optimal solutions to construct an optimal solution for the problem the subproblems solved by subproblems and that is in time the subproblem for the that it is not a a subproblems to that a problem subproblems is to that the same subproblems used to many problems for in the and involves and needed to compute a to may up or more this subproblems a may time optimal solutions to subproblems it solved in to this the solutions to problems solved to the same problem and computed solution this is not this a solution it to in cases even compute the solutions to subproblems that in\n",
      "48.0, 249 finish at source in 516 and answer in 180\n",
      "ANSWER\n",
      "in object oriented programming inheritance is the ability to specify one class to be a subclass of another this leads to a hierarchy of classes with the child classes inheriting and specialising  and sometimes adding to  the functionality and data structures of the parent classes the hierarchy that is formed is also useful for the organisation of classes and objects as it defines a relationship between the child and the parent the child class is a kind of the parent class  inheritance is useful for situations where several classes share common features such as needed functions or data variables in addition to this child classes can be referenced in terms of their parent classes which can be useful when storing large data structures of objects of several classes which can all be referenced as one base class inheritance is a core aspect of object oriented programming and is available in some form or another in most if not all object oriented languages available today most of these languages provide an extend keyword which is used to subclass another also the functions and data variables that are inherited by the subclasses can be controlled through the use of visibility modifiers \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a to form classes of which are objects classes that the inheritance in for the classes as classes or and of the classes which are to as base classes or classes it is to with or inheritance the for by in languages is a of to by of is is to a a can be and to be inheritance is also sometimes the is a a hierarchy between classes of objects for a is a of and one can to be an of are an is a all the common to all such as a for the of a an of inheritance is that with can share a of the of the inheritance another a which of controlled by inheritance is by one or by or by adding to by an inheritance or inheritance used a that is not to the\n",
      "44.0, 147 finish at source in 308 and answer in 199\n",
      "ANSWER\n",
      "the google search engine uses a link analysis algorithm called pagerank to assign a relative numerical importance to a set of hyperlinked documents such as the world wide web for a given page it s importance the pagerank value results from a ballot among all the other pages in the set for a page to give a vote to another it must link to it and so the pagerank depends on the number of incoming links anf the pagerank of those pages that provide the links pages that are linked to by many high ranking pages will themselves obtain a high rank if a page has no incoming links there is no support for that page the pagerank is a numeric weighting of 0 to 10 and denotes how important a site is in google s eyes like the richter scale the pagerank is a value on a logerithmic scale that is derived from a probability in addition to the quantity and quality of inbound links other factors affect the pagerank such as the number of visits to the page and the search words that are used on the page to prevent sites from manipulating or spoofing pagerank very little details are provided by google as to what factors actually affect it \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link analysis algorithm used by the google search engine that a numerical weighting to of a hyperlinked set of documents such as the world wide web the of relative importance the set the algorithm to of and the numerical that it to given is called the pagerank of and by the pagerank is a of google and the pagerank has s the is to and to google google has on the from the in google in for of the the in for google pagerank pagerank on the of the web by link as of page s value in google a link from page a to page as a vote by page a for page google the of or links a page it the page that the vote by pages that are themselves important and to other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web how important a page is a to a page as a vote of support the pagerank of a page is and depends on the number and pagerank of all pages that link to it incoming links a page that is linked to by many pages high pagerank a high rank if there are no links to a web page there is no support for that page google a numeric weighting from 0 10 for on the pagerank denotes a site s importance in the eyes of google the pagerank is derived from a probability value on a scale like the richter scale the pagerank of a page is the quantity of inbound links as as the pagerank of the pages the links it is that other factors of search words on the page and visits to the page by the google the pagerank in to prevent spoofing and google no details how other factors pagerank pagerank page and s in the pagerank has to to and has to pagerank and to links from documents pagerank other link ranking for web pages the algorithm by used by and the and the algorithm\n",
      "107.0, 351 finish at source in 535 and answer in 212\n",
      "ANSWER\n",
      "vector space model or term vector model as it is also known is an algebraic model for representing objects although it is mainly used for text documents as vectors of identifiers for example index terms it is used in information retrieval and filtering indexing and relevancy rankings and was first used in the smart information retrieval system  a document is represented as a vector with each dimension corresponding to a separate term if a term occurs in the document the value will be non zero in the vector many different ways of computing these values aka term weights have been developed one of the best known schemes is tf idf weighting  the way that a term is defined depends on the application typically terms are single words keywords or sometimes even longer phrases if the words are chosen as the terms the number of dimensions in the vector is the number of distinct words in the corpus  relevancy ranks for documents in a keyword search can be calculated this uses the assumptions of document similarities theory by comparing the difference of angles between each document vector and the original query vector where the query is represented as same format vector as the documents  generally it is easier to calculate the cosine of the angle between the vectors instead of the angle itself a zero value for the cosine indicates that the query and document vector are orthogonal and so had no match this means the query term did not exist in the document being considered  however the vector space model has limitations long documents are poorly represented due to their poor similarity values a small scalar product and a large dimensionality  search keywords must match precisely the document terms word substrings might result in a false positive match  similar context documents but different term vocabulary won t be associated leading to a false negative match  and the order that the terms appear in the document is not represented in the vector space model \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or term vector model is an algebraic model for representing text documents and objects in as vectors of identifiers as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings first was in the smart information retrieval system a document is represented as a vector each dimension to a separate term if a term occurs in the document value in the vector is non zero different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting the example the of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words in the corpus the vector space model has the limitations long documents are poorly represented have poor similarity values a small scalar product and a large dimensionality search keywords must precisely match document terms word substrings might result in a false positive match documents with similar context but different term vocabulary won t be associated in a false negative match the order in the terms appear in the document is in the vector space\n",
      "186.0, 217 finish at source in 242 and answer in 333\n",
      "ANSWER\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms  bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail  bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability  p a b p b  a x p a p b  each term in bayes theorem has a conventional name p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b p b a is the conditional probability of b given a p b is the prior or marginal probability of b and acts as a normalizing constant  intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation example as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b p b a p a p b each term in bayes theorem has a conventional name p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b p b a is the conditional probability of b given a p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b\n",
      "302.0, 303 finish at source in 306 and answer in 303\n",
      "ANSWER\n",
      "in the field of computer science term dynamic programming relates to the style of programming that breaks a large problem down into smaller subproblems and generally allows for the finding of the optimal solution when the problem is split into subproblems these themselves may be split into smaller problems and so on until they cannot be reduced any more it is also common for dynamic programming to make use of recursion and the saving of previous results for faster computation later this also leads to higher efficiency as calculations are not being redone for example when a problem is reduced into sub problems and those are then reduced further it may be that there are common subsubproblems and so only one calculation needs to be done and the result saved to help solve more than one subproblem an example of this gain in efficiency is a path finding problem if there are two distinct routes in a network of 10 nodes tagged a to j then if the two routes share a common section say between nodes b and d  the cost of that section should be calculated for the first route and saved then when the second route is being processed the cost of b to d does not need to be calculated again in general dynamic programming is used on optimisation problems where the most efficient solution is needed areas where this sort of programming is useful is in ai computer graphics compression routines and biomedical applications \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and computer science dynamic programming is a of problems that the of subproblems and optimal the than the term used in the to the of problems where one needs to the one this to the the field as a and that is the is in the of the a result of dynamic programming an problem in the programming in dynamic programming to computer programming and the term programming a for the is the optimal for that is for a of an is a programming in this finding an of an optimal that optimal of subproblems be used to the optimal of the problem for example the path to a a in a be first the path to the and then this to the path as in in general solve a problem optimal a the problem into smaller subproblems solve these problems this use these optimal to an optimal solution for the problem the subproblems are themselves into sub subproblems and so on until that is in the subproblem for the that it is not a a subproblems to say that a problem subproblems is to say that the subproblems are used to solve problems for example in the and and are needed to a to may more this subproblems are a may optimal to subproblems it in to this the to problems then if need to solve the problem later and solution this is not this term also if are need a solution it to in the to subproblems that need in\n",
      "57.0, 253 finish at source in 516 and answer in 249\n",
      "ANSWER\n",
      "inheritance is a concept in object oriented programming where a child or sub class inherits characteristics from a parent or super class  the concept takes its name from genetic inheritance where a child can inherit genetic characteristics from its parents  inheritance at its simplest allows programmers to model a relationship where one object is a kind of another  for instance two classes one representing an undergraduate student and another representing a post graduate student could both be said to belong to a more generalised class representing all students  similarly we could say that dogs and cats are two kinds of animal or that bridges and skyscrapers are two types of man made structure  subclasses are said to extend or specialise their superclasses  attributes variables and behaviours functions that are common between classes can be included in the definition of the superclass leaving the subclass definitions containing only the attributes and behaviours that are unique to that class  inheritance can be used to create a multiple level architecture of classes  in such an architecture even the bottom most subclasses inherit all of the attributes and behaviours that are defined in the very top most superclasses  this can save the programmer time because it renders unnecessary a lot of code duplication \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a to classes of are classes that defined the inheritance concept in for the classes classes or inherit attributes and of the classes are to classes or classes it is to code or inheritance the for in is a of to of is is to a a can be and to be only its inheritance is because the is a a between classes of for instance a is a of and one can to be an of are an is a inherit all the common to all such a for the of a an of inheritance is that can a lot of code the of the inheritance another a of code code inheritance is one or more or to an inheritance or inheritance used a that is to the\n",
      "36.0, 135 finish at source in 308 and answer in 209\n",
      "ANSWER\n",
      "pagerank is an algorithm that was developed by google to provide the most relevant search results to its users queries  pagerank along with similar algorithms developed by google s competitors for their search engines is part of the second generation of technologies designed to rate the importance of web pages the first which was solely based on keywords in the page content and meta data could easily be influenced by those wishing to obtain a higher ranking for their less relevant pages  the different with pagerank is that it tries to determine a web page s relevance to users by attempting to determine its importance  it does this by assigning it a value of importance that is dependant upon the number of web sites that link to that page taking into account the importance value or pagerank of those pages  the pagerank is computed iteratively and it is found that the pagerank values converge fairly rapidly  although it is much better than simple keyword based ranking algorithms pagerank is not infallible we have an internet where advertising revenue can make up most  and quite frequently all  of a web site s income and the people that run these web sites will always be trying to trick the system into giving their pages a higher pagerank  one of google s attempts to counter this is their google toolbar browser plugin  google toolbar is a free tool which provides a number of useful functions in a convenient location the users web browser window  google s payoff is that it gets to track the behaviour of actual users  this allows them to see whether their pagerank algorithm is accurate in assigning high pagerank values to the most relevant web pages and just as importantly low values to those that are irrelevant and try to fool the system  \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link algorithm by the google internet search that a to of a of as the web with the of its importance the the algorithm be to of with and the that it to is the pagerank of and by the pagerank is a of google and the pagerank s the is to and not to google google on the the in google in for of the the in for google pagerank pagerank on the of the web by its link as an of an page s value in google a link page a to page as a by page a for page google than the of or a page it the page that the by pages that are and to make pages in a pagerank results a all the pages on the web a page is a to a page as a of the pagerank of a page is and on the number and pagerank of all pages that link to it a page that is to by pages with high pagerank a high are to a web page is for that page google a for on the internet this pagerank a site s importance in the of google the pagerank is a value on a the the pagerank of a page is based upon the of as as the pagerank of the pages the it is that relevance of search on the page and actual to the page by the google toolbar the pagerank in to and google provides pagerank pagerank have page and s in the pagerank to be to and to pagerank and to with pagerank link based ranking algorithms for web pages the algorithm by by and the and the algorithm\n",
      "72.0, 288 finish at source in 535 and answer in 304\n",
      "ANSWER\n",
      "there are a large number of models used in solving the problem of information retrieval and they are all based on one of three mathematical bases set theory algebra and probabilistic  the vector space model is one of these methods and it is an algebraic model  in the vector space model a document is represented as a vector  within this vector each dimension corresponds to a separate term where a term is typically a single word keyword or phrase  if the term doesn t occur within the document the value in the vector is zero  if a term occurs in the document its value is non zero  to calculate how relevant each document is in a keyword search the cosine value of the angle between the vectors is easier to calculate instead of the actual angle  the vector space model however is not without its limitations they have small similarity values long documents are poorly represented the order of words does not matter false positive matches may be brought about by terms contained within words themselves and documents that should match but use different semantics may return false negative matches  there are a number of other models that are based on or extend the vector space model and these are designed to try to eradicate these problems \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or term vector model is an algebraic model documents and in as vectors of as terms it is used in information information retrieval and its use in the information retrieval a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero different of these values as term have one of the is the the of term on the typically terms are single words or if the words are to be the terms the of the vector is the number of words in the the number of words in the the vector space model the limitations long documents are poorly represented they have similarity values a small and a large search match document terms word in a false positive match documents but different term t be in a false negative match the order in the terms in the document is in the vector space\n",
      "64.0, 164 finish at source in 242 and answer in 217\n",
      "ANSWER\n",
      "bayes theorem often called bayes law connects the conditional and marginal probabilities of two arbitrary events one of its uses is calculating posterior probabilities given observations  bayes theorem plays a key role in the debate around the principles of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications  bayes theorem is useful in evaluating the result of drug tests  if a test can identify a drug user 99 of the time and can identify a non user as testing negative 99 of the time it may seem to be a relatively accurate test  however bayes theorem will reveal the flaw that despite the apparently high accuracy of the test the probability that an employee who tested positive actually did use drugs is only about 33 \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability bayes theorem often called bayes law bayes the conditional and marginal probabilities of two events it is often to posterior probabilities given observations a may be to bayes theorem can be to the probability that a is given that as a theorem bayes theorem is in interpretations of probability however it plays a role in the debate around the of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications probabilities to events to of to of as of the probabilities in of and of the bayesian probability and frequentist probability in bayes theorem the conditional and marginal probabilities of events a and a non probability a a a in bayes theorem a a is the probability marginal probability of a it is in the that it about a is the conditional probability of a given it is called the posterior probability it is the of a is the conditional probability of given a is the marginal probability of and as a bayes theorem in the in which one about a\n",
      "67.0, 180 finish at source in 306 and answer in 133\n",
      "ANSWER\n",
      "dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure  the term was originally used in the 1940s by richard bellman  the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization  the program is the optimal plan for action that is produced  for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action  to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems  optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and computer dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure the method the term was originally used in the 1940s by richard bellman to the of solving problems to find the by this to the the was a and that is by the bellman is in the of the bellman a of dynamic programming an optimization problem in the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming a synonym for optimization the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for the to a from a in a can be by the to the from all and this to the overall in in can solve a problem optimal substructure a the problem subproblems solve problems this optimal solutions to an optimal for the problem the subproblems are by subproblems and that is in the for the that is a a overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for in the and and are to a to this overlapping subproblems are a optimal solutions to subproblems has in to this instead the solutions to problems to solve the same problem can and this is called this term are a particular can to in can the solutions to subproblems that in\n",
      "124.0, 291 finish at source in 516 and answer in 136\n",
      "ANSWER\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all ruit such as being a fleshy container for the seed of a plant  inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance in for the new classes as classes or inherit and of the classes which are to as classes or ancestor classes is to or inheritance the for by in is a of to by of generalization is is to a a can be and to be inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple orange mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e an apple is a fruit apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant an of inheritance is that can a of the of the inheritance a called which many of being by inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor inheritance or inheritance a that is may to the\n",
      "129.0, 206 finish at source in 308 and answer in 130\n",
      "ANSWER\n",
      "the pagerank algorithm used by google harnesses the implicit collective intelligence present in the structure of the world wide web any page on the internet will generally link to at least one other by modelling this link structure as a graph we can build up a symbolic representation of the world wide web  as the basic level the nodes with the highest degrees can be considered the most popular and by inference the most important  which can be used to rank the pages when returning search results  expanding on this theory we can then say that the links from an important pages are themselves more important using this idea we can adjust the rankings of our pages so that pages linked to be the most important pages are considered more relevant  the actual google pagerank algorithm is much more complex than this but follows the same underlying principles it incorporates some more advanced reasoning to avoid website creators exploiting their knowledge of the algorithm to artificially increase their pagerank through use of web rings and other similar reciprocal hyperlinking schemes \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link algorithm used by the google internet search that a to of a of as the world wide web with the of the the algorithm be to any of with reciprocal and the that it to any is the pagerank of and by the pagerank is a of google and the pagerank the is to and to google google on the from the in google in use of the the in google pagerank pagerank on the of the web by using link structure as an of an page in google a link from page a to page as a by page a page but google at more than the of links a page it the page that the by pages that are themselves important more and to other pages important in other a pagerank results from a the other pages on the world wide web important a page is a to a page as a of the pagerank of a page is and on the and pagerank of pages that link to it links a page that is linked to by pages with pagerank a rank are links to a web page is that page google a from on the internet this pagerank a in the of google the pagerank is from a on a the the pagerank of a page is the of links as as the pagerank of the pages the links it is that other of search on the page and actual to the page by the google the pagerank in to and google other pagerank pagerank page and in the pagerank to be to and to pagerank and to links from with pagerank other link web pages the algorithm by used by and the and the algorithm\n",
      "51.0, 294 finish at source in 535 and answer in 180\n",
      "ANSWER\n",
      "using the vector space model for information retrieval models all pages and queries as high dimensional sparse vectors each item in the vector represents a different keyword  the similiarity betweeen two pages or a query and a page can be computed using the dot product formula to find the cosine between them this represents the angle between them but in n dimensional space results will range from 1 to 1 with 1 being a close match normally the vectors will not have any negative values so results will always be greater than or equal to 0 the cosine is computed using cos a a b  a b \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or vector model is model for and any in as vectors as for is in information information retrieval and in the information retrieval a is as a vector each to a a in the in the vector is different values as have the is the the the or the to be the the the vector is the in the the in the the vector space model the 1 have values a product and a match in a match with but different be in a negative match the in the in the is in the vector space\n",
      "28.0, 99 finish at source in 242 and answer in 107\n",
      "ANSWER\n",
      "in probability theory the prior and conditional probabilities of two random events are related by bayes theorem the theorem is often used when we have observations and wish to compute posterior probabilities  for example given an observation that a patient is seen to have certain symptoms we can use bayes theorem to compute the probability that a suggested diagnosis is correct  p a is the prior probability of a p a b is the conditional probabilty of a given b p b a is the conditional probabilty of b given a p b is the prior probability of b and must be non zero bayes theorem is given by p a b p b a p a  p b  \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability theory bayes theorem often bayes bayes the conditional and probabilities of two random events is often used to compute posterior probabilities given observations for example a patient be to have certain symptoms bayes theorem can be used to compute the probability that a diagnosis is correct given that observation example a theorem bayes theorem is in of probability a in the the of and the in probabilities be in probabilities to random events to of to of of the probabilities in of and of the probability and probability in bayes theorem the conditional and probabilities of events a and b b a non probability p a b p b a p a p b in bayes theorem a p a is the prior probability probability of a is prior in the that b p a b is the conditional probability of a given b is the posterior probability is the of b p b a is the conditional probability of b given a p b is the prior probability of b and a bayes theorem in the in a are by b\n",
      "77.0, 184 finish at source in 306 and answer in 119\n",
      "ANSWER\n",
      "in computer science and mathematics dynamic programming is a method of problem solving that utilises the properties of overlapping subproblems and optimal substructure and thus the method takes much less time than more naive methods  in dynamic programming  the word programming has no real connection to computer programming at all it actually comes from the term mathematical programming  a synonym for optimisation thus the program is the optimal plan of action that is being produced for example a schedule of events at an exhibition is sometimes called a programme programming in this sense means finding an acceptable plan an algorithm \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in mathematics and computer science dynamic programming is a method of solving that the properties of overlapping subproblems and optimal substructure the method takes much less time than naive methods the term in the to the of solving to the this to the the a and that is the is in the of the a of dynamic programming an problem in the word programming in dynamic programming has no connection to computer programming at all and comes from the term mathematical programming a synonym for thus the program is the optimal plan for action that is produced for a schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal of subproblems to the optimal of the problem for example the to a from a in a the to the from all and this to the in in a problem optimal substructure a the problem subproblems this optimal to an optimal for the problem the subproblems subproblems and that is in time the for the that it is a a overlapping subproblems to that a problem has overlapping subproblems is to that the subproblems to for example in the and and to a naive to more this overlapping subproblems a naive time optimal to subproblems it has in to this the to to the problem and this is called this term a it to in the to subproblems that in\n",
      "85.0, 248 finish at source in 516 and answer in 100\n",
      "ANSWER\n",
      "inheritance is the ability of a subclass to inherit default protected and public attributes and methods from its superclasses each object except java lang object can be cast to an object of one of its superclasses however an object cannot be cast to a class which is no relative of it here is an example of inheritance we have the class of all living things which have attributes like weight and age we have the classes of animals plants viruses and fungi that are subclasses of the class of all living things the animals have their unique attributes organs hair etc  and methods walking mating etc  they also inherit the attributes and methods of its superclass animals can be treated cast to living things however animals cannot be treated as fungi in object oriented programming inheritance is also dependant on access level modifiers for example private attributes and methods cannot be inherited virtual attributes and methods can be shadowed overridden in java all attributes and methods are implicitly virtual object variable can store a reference to the same class or a subclass i e this or more specialised version  however object variables cannot store references to a superclass i e less specialised version of the original class \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a to classes of which are classes that have the inheritance in for the classes as classes or inherit attributes and of the classes which are to as classes or classes it is to or no inheritance the for in is a of to of is is to a a can be and less to be each its inheritance is also the is a a classes of for a is a of and one can to be an of etc are i e an is a inherit all the to all as a for the of a an of inheritance is that can a of the of the inheritance a which of inheritance is one or more methods or methods to an inheritance or inheritance a that is to the\n",
      "37.0, 136 finish at source in 308 and answer in 207\n",
      "ANSWER\n",
      "page rank algorithm is used to determine a webpages importance or relevance in the web dependant on certain criteria the criteria may include numbers of word matches with the search terms number of other webpages that link this one and or cite it as a source number of unique visits for certain amount of time etc there are some techniques that try to fool the search engines like link farms keyword spamming and a lot of meta tags the last two are somewhat easier to be dealt with simply by being ignored most of the time  link farms are groups of sites that are producing links between each other pursuing higher link counts the reason for such manipulations is the pursuit of higher page rank so even higher number of users will see the page which will lead to higher income link farms can be exploited by joining to them and get inbound linkage but refuse to add links for ones own site to the sites from the link farm googles toolbar tries to follow the intentional user model by counting the visits from actual users i e not computer bots to a website page ranks can be calculated either recursively or iteratively one of the most important uses of page rank is its meaning to advertising \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: is a link algorithm used by the search that a to each of a of such as the web with the of its importance the the algorithm may be to of with and the that it to e is the of e and by e the is a of and the the is to and not to on the from the in in for of the the in for on the of the web by its link as of page in a link from page a to page as a by page a for page but the of or links a page it the page that the by that are important and to other important in other a from a the other on the web important a page is a to a page counts as a of the of a page is recursively and on the number and of that link to it links a page that is to by with a rank there are links to a web page there is for that page a from for each on the this a site importance in the of the is from a on a like the the of a page is the of inbound links as as the of the the links it is that other e relevance of search on the page and actual visits to the page by the toolbar the in to and other page and in the to be to and to and to links from with other link for web include the algorithm by used by and the and the algorithm\n",
      "51.0, 266 finish at source in 535 and answer in 217\n",
      "ANSWER\n",
      "the vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as index terms it is used in information filtering information retrieval indexing and relevancy rankings it was used in the first time in the smart information retrieval system  a document is represented as a vector each and every dimension corresponds to a separate term if a term exists in a document its value in the vector is not equal to zero a couple of different algorithms of computing these values also known as term weights have been created one of the most popular schemes is tf idf weighting  the definition of term is dependent on the application typically terms are keywords single words or longer phrases provided that words are selected to be the terms the dimensionality of the vector is equal to the number of words in the vocabulary  it is easiest to calculate the cosinus of the angle between the vectors instead of the angle by the formula  cos theta v1 v2  v1  v2 a null cosinus value says that the query and document vector were orthogonal and had no match which means that no term of the query was ever encountered in the document \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for index terms it is used in information filtering information retrieval indexing and relevancy rankings its first was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term in the document its value in the vector is zero different of computing these values also known as term weights have been one of the known schemes is tf idf weighting the the definition of term on the application typically terms are single words keywords or longer phrases if the words are to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of words in the the vector space model the documents are represented have values a and a dimensionality keywords match document terms in a match documents different term vocabulary be in a match the in which the terms in the document is in the vector space\n",
      "141.0, 184 finish at source in 242 and answer in 213\n",
      "ANSWER\n",
      "in probability theory bayes theorem or bayes law after rev thomas bayes provides relation between the conditional and marginal probabilities of two random events it is usually used to calculate posterior probabilities given observations for example a patient might be observed to show certain symptoms bayes theorem could be used to compute the probability that a certain diagnosis is right given that observation  since it is a formal theorem bayes theorem holds in all popular interpretations of probability  bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability  p a b  p a b p a p b  terms in bayes theorem are named by a convention  p a is the prior probability or marginal probability of a it does not take into account any information about b and therefore is considered prior p a b is the conditional probability of a given b it it is derived from or depends upon the specified value of b usually it is called the posterior probability p b a is the conditional probability of b given a p b  a k a the normalizing constant is the prior or marginal probability of b  obviously bayes theorem describes the way in which one s assumptions about observing the event a are changed by having observed the event b  \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability theory bayes theorem called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is used to compute posterior probabilities given observations for example a patient be observed to certain symptoms bayes theorem be used to compute the probability that a diagnosis is given that observation example a formal theorem bayes theorem is in all interpretations of probability it a in the the of and interpretations about the in which probabilities be in probabilities to random events to of or to of of the probabilities in terms of and of the probability and probability in bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b p b a p a p b in bayes theorem has a p a is the prior probability or marginal probability of a it is prior in the that it does not take into account any information about b p a b is the conditional probability of a given b it is called the posterior probability it is derived from or depends upon the specified value of b p b a is the conditional probability of b given a p b is the prior or marginal probability of b and a normalizing constant bayes theorem in describes the way in which one s about observing a are by having observed b\n",
      "178.0, 238 finish at source in 306 and answer in 225\n",
      "ANSWER\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure  the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization programming in this sense means finding an acceptable plan of action an algorithm  optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem  the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time  to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3 computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved  in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance  dynamic programming makes use of  overlapping subproblems optimal substructure memoization dynamic programming usually takes one of two approaches  top down approach bottom up approach  \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure the method takes time naive the term used in the by to the process of solving problems one to find the one by this to the the a and that is by the is in the of the a of dynamic programming an optimization problem in the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming a synonym for optimization the is the optimal plan for action that is for a of at an is a programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the to a from a in a can be by computing the to the from all and then using this to the overall in 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time 2 the for the fibonacci sequence that it is a a overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3 f1 f2 and f4 f2 f3 computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is memoization this term if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance\n",
      "318.0, 426 finish at source in 516 and answer in 342\n",
      "ANSWER\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization and cognitive economy less information needs to be stored about each specific entity only its particularities  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes it is intended to help reuse existing code with little or no modification inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization is known about specific is to a a can be and cognitive economy less information needs to be stored about each specific entity only its particularities inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple orange mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e an apple is a fruit apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem\n",
      "247.0, 299 finish at source in 308 and answer in 289\n",
      "ANSWER\n",
      "since the develop of the web 2 0 google as one of the most popular search engine in the world  there are many algorithms in the web search accordingly implementations of link analysis algorithms will typical discount such internal links the word computer can be exploited by web search engines such as google thus the web is just like a graph and the pagerank which is our first technique for analysing the link which is assigns to every node in the web graph a numerical score between 0 and 1 since the pagerank is the most important algorithms which is used in the google engine for example there are four pages group a b c and d if every page link to a then a s pagerank value shoule be the total value of b c and d  pr a  pr b  pr c  pr d moreover there is a q  0 15 which is be use in the web page like the general algorithm below  however the disadvantage is of pagerank algorithm is that the renew system is too slow \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link analysis algorithm used by the google search engine that assigns a numerical to of a of such as the world web the of the the algorithm be to of and the numerical that assigns to is the pagerank of and by pr the pagerank is a of google and the pagerank s however the is to and to google google the the 1 in google in for use of the the in for google pagerank pagerank the of the web by link as of page s value in google a link page a to page b as a by page a for page b google the of links a page the page that the by pages that are important and to pages important in a pagerank a the pages the world web important a page is a to a page as a of the pagerank of a page is and the and pagerank of pages that link to links a page that is to by many pages pagerank a if there are links to a web page there is for that page google assigns a 0 for the pagerank a s in the of google the pagerank is a value a like the the pagerank of a page is the of links as as the pagerank of the pages the links is that of search the page and to the page by the google the pagerank in to and google pagerank pagerank since page and s in the pagerank to be to and to pagerank and to links pagerank link algorithms for web pages the algorithm by used by and the and the algorithm\n",
      "54.0, 278 finish at source in 535 and answer in 181\n",
      "ANSWER\n",
      "the vector space model are the documents which are represented as bags of words the basic idea is to represent each document as a vector of certain weighted word frequencies in order to do so the following parsing and extraction steps are needed  1 ignoring case extract all unique words from the entire set of documents  2 eliminate non content bearing  stopwords  such as  a and the  etc for sample lists of stopwords 3 for each document count the number of occurrences of each word  4 using heuristic or information theoretic criteria eliminate non content bearing  high frequency  and  low frequency  words  5 after the above elimination suppose unique words remain assign a unique identifier between and to each remaining word and a unique identifier between and to each document  \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or vector model is model for documents and in as of such as for is in information information and in the information a document is represented as a vector each to a a in the document in the vector is non of as of the is the the of the are words or the words are to the the of the vector is the number of words in the the number of words in the the vector space model the following 1 documents are represented a and a 2 document word in a 3 documents in a 4 the order in which the in the document is in the vector space\n",
      "29.0, 114 finish at source in 242 and answer in 130\n",
      "ANSWER\n",
      "in probability theory bayes theorem relates the conditional and marginal probabilities of two random events it is usually be used to compute posterior probabilities given observations for instance a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications the articles on bayesian probability and frequentist probability discuss these debates in greater detail frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole at the same time  bayesians describe probabilities in terms of beliefs and degrees of uncertainty  bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b p b a is the conditional probability of b given a p b is the prior or marginal probability of b and acts as a normalizing constant  intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability theory bayes theorem called bayes bayes relates the conditional and marginal probabilities of two random events it is used to compute posterior probabilities given observations for a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b p b a p a p b each term in bayes theorem has a conventional name p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b p b a is the conditional probability of b given a p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b\n",
      "267.0, 294 finish at source in 306 and answer in 288\n",
      "ANSWER\n",
      "in mathematics and computer science dynamic programming is a methodology of the solution of the problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the methodology takes much less time rather than naive methods the term was originally used during the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programmer which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming in general  and instead of this it comes from the term mathematical programming  a synonym for optimization therefore the program is the optimal plan for action that is produced for example a finalized schedule of events at an exhibition is sometimes called a program  optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for instance the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices after this it is using this to pick the best overall path in a word we can solve a problem with optimal substructure using a three step process \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in mathematics and computer science dynamic programming is a of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below the takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming a synonym for optimization the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this means an plan of action an optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and using this to pick the best overall path as in in general we can solve a problem with optimal substructure using a three step process the problem subproblems solve problems using this three step process optimal solutions to an optimal solution for the problem the subproblems by subproblems and we that is in time the graph for the that it is a a overlapping subproblems to that a problem has overlapping subproblems is to that the subproblems used to solve problems for example in the and computing computing and to a naive to computing computing this overlapping subproblems a naive time optimal solutions to subproblems it has in to this we instead the solutions to problems we we to solve the problem we can and solution this is called this term we we a particular solution we can it to in we can the solutions to subproblems we that we in\n",
      "232.0, 378 finish at source in 516 and answer in 255\n",
      "ANSWER\n",
      "the idea of inheritance in oop refers to the formation of new classes with the already existing classes the concept of inheritance was basically formulated for simula in 1967 as a result the newly created inherited or derived classes inherit the properties and behavior of the classes from which they are derived these original classes are either called base classes or sometimes referred to as ancestor classes the idea of inheritance is to reuse the existing code with little or no modification at all the basic support provided by inheritance is that it represents by categorization in computer languages the power mechanism number of information processing that is crucial to human learning by the means of generalization and cognitive economy is called categorization where generalization if the knowledge of specific entities and is applied to a wider group provided that belongs relation can be created on the other hand cognitive economy is where less information needs to be stored about each specific entity except for some particularities there are examples where we can have modules with similar interfaces the advantage that inheritance provides is that it makes such modules share a lot of code which consequently reduces the complexity of the program \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in inheritance is a to new classes of which are called classes that have already the inheritance concept was in 1967 for simula the new classes as derived classes or inherit and behavior of the existing classes which are referred to as base classes or ancestor classes it is to reuse existing code with little or no modification inheritance provides the support for by categorization in computer languages categorization is a mechanism number of information processing crucial to human learning by means of generalization is about specific entities is applied to a wider group a belongs relation can be and cognitive economy less information needs to be stored about each specific entity particularities inheritance is sometimes called generalization the is a a classes of for a is a generalization of and can to be of are is a inherit all the properties to all such as a for the of a advantage of inheritance is that modules with similar interfaces can share a lot of code the complexity of the program inheritance a called which of code by code inheritance is either by or by ancestor or by new to by ancestor inheritance or inheritance a that is to the\n",
      "99.0, 200 finish at source in 308 and answer in 202\n",
      "ANSWER\n",
      "pagerank is a probability distribution used to represent the likelihood that a person randomly clicking on links will arrive at any particular page  it is assumed in several research papers that the distribution is evenly divided between all documents in the collection at the beginning of the computational process pagerank can be calculated for collections of documents of any size the pagerank computations require several passes called iterations  through the collection to adjust approximate pagerank values to more closely reflect the theoretical true value a probability is expressed as a numeric value between 0 and 1 a 0 5 probability is commonly expressed as a 50 chance of something happening hence a pagerank of 0 5 means there is a 50 chance that a person clicking on a random link will be directed to the document with the 0 5 pagerank simplified algorithm how pagerank works assume a small universe of four web pages a b c and d the initial approximation of pagerank would be evenly divided between these four documents hence each document would begin with an estimated pagerank of 0 25 in the original form of pagerank initial values were simply 1 this meant that the sum of all pages was the total number of pages on the web later versions of pagerank see the below formulas would assume a probability distribution between 0 and 1 here we re going to simply use a probability distribution hence the initial value of 0 25 \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link algorithm used the that a to each of a of documents as the web with the of the the algorithm be to any collection of with and the that it to any is called the pagerank of and the pagerank is a of and the pagerank process the is to and to on the the 1 in in for use of the the were in for pagerank pagerank on the of the web link as an of an page value in a link page a to page b as a page a for page b at more the of links a page it the page that the pages that more and to pages in a pagerank a all the pages on the web how a page is a to a page as a of the pagerank of a page is and on the number and pagerank of all pages that link to it links a page that is to pages with pagerank a there links to a web page there is for that page a numeric 0 for each on the this pagerank a in the of the pagerank is a theoretical probability value on a the the pagerank of a particular page is the of links as as the pagerank of the pages the links it is that of on the page and to the page the the pagerank in to and how pagerank papers pagerank page and original in the pagerank to be to and research to pagerank and to links documents with pagerank link for web pages the algorithm used and the and the algorithm\n",
      "62.0, 272 finish at source in 535 and answer in 246\n",
      "ANSWER\n",
      "in vector space model the documents from which the information is to be retrieved are represented as vectors the term weighting indentifies the success or failure of the vector space method terms are basically the words or any indexing unit used to identify the contents of a text furthermore a term weighting scheme plays an important role for the similarity measure the similarity measures largely identify the retrieval efficiency of a particular information retrieval system  this largely depends on formulas where the formulas depend only on the frequencies within the document and they not depend on inter document frequencies the main components of the formulas are as follows binary binary formula gives every word that appears in a document equal relevance this can be useful when the number of times a word appears is not considered important term frequency this formula counts how many times the term occurs in a document the more times a term t occurs in document d the more likely it is that t is relevant to the document used alone favors common words and long documents this formula gives more credit to words that appears more frequently but often too much credit augmented normalized term frequency this formula tries to give credit to any word that appears and then give some additional credit to words that appear frequently logarithmic term frequency logarithms are a way to de emphasize the e ect of frequency literature proposes log and alternate log as the most used \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or term vector model is an model for text documents and any in as vectors of as for terms it is used in information information retrieval indexing and in the information retrieval system a document is represented as a vector to a term a term occurs in the document in the vector is of as term of the is weighting the the of term depends on the terms are words or the words are to be the terms the of the vector is the number of words in the the number of words in the the vector space model the long documents are represented they similarity a and a document terms word in a documents but term t be in a the in which the terms appear in the document is in the vector space\n",
      "44.0, 138 finish at source in 242 and answer in 248\n",
      "ANSWER\n",
      "bayes theorem is a simple mathematical formula used for calculating conditional probabilities bayes theorem is a theorem of probability theory originally stated by the reverend thomas bayes it figures prominently in subjectivist or bayesian approaches to epistemology statistics and inductive logic it can be seen as a way of understanding how the probability that a theory is true is affected by a new piece of evidence it has been used in a wide variety of contexts ranging from marine biology to the development of bayesian spam blockers for email systems in the philosophy of science it has been used to try to clarify the relationship between theory and evidence many insights in the philosophy of science involving confirmation falsification the relation between science and pseudosience and other topics can be made more precise and sometimes extended or corrected by using bayes theorem subjectivists who maintain that rational belief is governed by the laws of probability lean heavily on conditional probabilities in their theories of evidence and their models of empirical learning bayes theorem is central to these enterprises both because it simplifies the calculation of conditional probabilities and because it clarifies significant features of subjectivist position indeed the theorem s central insight that a hypothesis is confirmed by any body of data that its truth renders probable is the cornerstone of all subjectivist methodology \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability theory bayes theorem bayes thomas bayes the conditional and probabilities of it is used to probabilities for a be to bayes theorem can be used to the probability that a is that as a theorem bayes theorem is in all of probability it a central in the the of statistics and bayesian the in probabilities be in probabilities to to their of or to of as of the probabilities in of and of the on bayesian probability and probability these in bayes theorem the conditional and probabilities of a and has a probability a a a in bayes theorem has a a is the probability or probability of a it is in the that it any a is the conditional probability of a it is the probability because it is from or the of a is the conditional probability of a is the or probability of and as a bayes theorem in the way in s a by\n",
      "51.0, 160 finish at source in 306 and answer in 224\n",
      "ANSWER\n",
      "dynamic programming is a method of providing solutions to potential problems exhibiting the properties of overlapping sub problems and optimal structure this is highly used in dynamic programming the advantage being the less time consumption in comparison to other amateur methods it has to be kept in mind that the term programming in the field has got nothing to do with computer programming at all on the other hand it is derived from the term mathematical programming which is a similar word used for optimization here by meaning that a program can be an optimal plan for the produced action the typical example could be of a finalized schedule of events at an exhibition this leads to the concept of programming being a helper in finding an acceptable plan of action which can also be termed as an algorithm the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time overlapping subproblems means that the same subproblems are used to solve many different larger problems example could be of fibonacci sequence f3  f1  f2 and f4  f2  f3 computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more it means that whenever we encounter with overlapping subproblems a naive approach may waste to e recomputing optimal solutions to the already solved subproblems \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and computer dynamic programming is a method of problems that the properties of overlapping subproblems and optimal the method less time naive methods the term used in the by to the of problems to the by this to the meaning the field as a and that is by the is in the of the a of dynamic programming which an optimization in the word programming in dynamic programming has to computer programming at all and from the term mathematical programming a for optimization the program is the optimal plan for action that is produced for a finalized schedule of events at an exhibition is a program programming in this means finding an acceptable plan of action an algorithm optimal means that optimal solutions of subproblems can be used to the optimal solutions of the for example the to a from a in a can be by computing the to the from all and this to the as in in we can solve a with optimal a the into subproblems solve problems this optimal solutions to an optimal for the the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time the for the fibonacci sequence that it is a a overlapping subproblems to that a has overlapping subproblems is to that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3 f1 f2 and f4 f2 f3 computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this whenever overlapping subproblems are a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in to this we the solutions to problems we already solved we to solve the same we can and already this approach is this term also we are we a we can it to in some we can compute the solutions to subproblems we that we in\n",
      "159.0, 348 finish at source in 516 and answer in 247\n",
      "ANSWER\n",
      "object oriented programming is a style of programming that supports encapsulation inheritance and polymorphism inheritance means derived a new class from the base class  we can also say there are parents class and child classes in inheritance  inheritance was firstly derived in 1967 the child class has all the features of parents class or we can say the base class more over it may also include some additional features  inheritance is used for modification and implementation new features in computer programming language it is possible that child class has all the attributes of parents class but it is not possible that all the attributes of child class must have in base class or parent class i categorization in computer language also inheritance is a useful tool categorization define as a powerful feature it has been also used in generalisation and in human learning in some areas less information need to be stored generlisation also some time known as inheritance the main reason behind this is a hierarchi structure of objects and classes we can understand this mechanism by some examples like fruit is aq main class and mangoes apple orange is child classs of the main class so obviously inherit all the properties of fruit class \n",
      "SOURCE\n",
      "in object oriented programming inheritance is a way to form new classes instances of which are called objects using classes that have already been defined the inheritance concept was invented in 1967 for simula  the new classes known as derived classes take over or inherit attributes and behavior of the pre existing classes which are referred to as base classes or ancestor classes  it is intended to help reuse existing code with little or no modification  inheritance provides the support for representation by categorization in computer languages categorization is a powerful mechanism number of information processing crucial to human learning by means of generalization what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive economy less information needs to be stored about each specific entity only its particularities  inheritance is also sometimes called generalization because the is a relationships represent a hierarchy between classes of objects for instance a fruit is a generalization of apple  orange  mango and many others one can consider fruit to be an abstraction of apple orange etc conversely since apples are fruit i e  an apple is a fruit  apples may naturally inherit all the properties common to all fruit such as being a fleshy container for the seed of a plant  an advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program inheritance therefore has another view a dual called polymorphism which describes many pieces of code being controlled by shared control code inheritance is typically accomplished either by overriding replacing one or more methods exposed by ancestor or by adding new methods to those exposed by an ancestor  complex inheritance or inheritance used within a design that is not sufficiently mature may lead to the yo yo problem \n",
      "SOURCE SEQUENCE: in object oriented programming inheritance is a to new classes of are objects classes that have been the inheritance was in 1967 for the new classes known as derived classes over or inherit attributes and of the classes are to as base classes or classes it is to or modification inheritance the for by categorization in computer categorization is a powerful mechanism of information to human learning by means of is known is to a a can be and less information to be stored inheritance is also the is a a classes of objects for a fruit is a of apple orange and can fruit to be of apple orange are fruit i apple is a fruit may inherit all the properties to all fruit as a for the of a of inheritance is that can a of the of the inheritance has a polymorphism of by inheritance is by or more by or by new to by inheritance or inheritance used a that is not may to the\n",
      "50.0, 169 finish at source in 308 and answer in 206\n",
      "ANSWER\n",
      "pagerankalgorithm is also known as link analysis algorithm  it has been used by google the algorithm may be applied to any collection of entities with reciprocal quotations and hyperlinked set of documents such as the world wide web with the purpose of measuring references the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university  in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links numerous academic papers concerning pagerank have been published since page and brin s original paper 4 in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank  \n",
      "SOURCE\n",
      "pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents such as the world wide web with the purpose of measuring its relative importance within the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e  the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999  however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university received 1 8 million shares in google in exchange for use of the patent the shares were sold in 2005 for 336 million google describes pagerank pagerank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual page s value in essence google interprets a link from page a to page b as a vote by page a for page b but google looks at more than the sheer volume of votes or links a page receives it also analyzes the page that casts the vote votes cast by pages that are themselves important weigh more heavily and help to make other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it  incoming links  a page that is linked to by many pages with high pagerank receives a high rank itself if there are no links to a web page there is no support for that page google assigns a numeric weighting from 0 10 for each webpage on the internet this pagerank denotes a site s importance in the eyes of google the pagerank is derived from a theoretical probability value on a logarithmic scale like the richter scale the pagerank of a particular page is roughly based upon the quantity of inbound links as well as the pagerank of the pages providing the links it is known that other factors e g relevance of search words on the page and actual visits to the page reported by the google toolbar also influence the pagerank in order to prevent manipulation spoofing and spamdexing google provides no specific details about how other factors influence pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link based ranking algorithms for web pages include the hits algorithm invented by jon kleinberg used by teoma and now ask com  the ibm clever project and the trustrank algorithm \n",
      "SOURCE SEQUENCE: pagerank is a link analysis algorithm used by the google that assigns a numerical to element of a hyperlinked set of documents such as the world wide web with the purpose of measuring the set the algorithm may be applied to any collection of entities with reciprocal quotations and references the numerical weight that it assigns to any given element e is also called the pagerank of e and denoted by pr e the name pagerank is a trademark of google and the pagerank process has been patented u s patent 6 285 999 however the patent is assigned to stanford university and not to google google has exclusive license rights on the patent from stanford university the university in google in of the patent the in google pagerank pagerank on the of the web by link as of page s in google a link from page a to page as a vote by page a page google the of links a page it also the page that the vote by pages that important and to other pages important in other words a pagerank results from a ballot among all the other pages on the world wide web about how important a page is a hyperlink to a page counts as a vote of support the pagerank of a page is defined recursively and depends on the number and pagerank metric of all pages that link to it incoming links a page that is to by pages with pagerank a links to a web page is support that page google assigns a from on the pagerank a s in the of google the pagerank is from a on a the the pagerank of a page is the of links as as the pagerank of the pages the links it is known that other e of words on the page and to the page by the google also the pagerank in to manipulation and google about how other pagerank numerous academic papers concerning pagerank have been published since page and brin s original paper in practice the pagerank concept has proven to be vulnerable to manipulation and extensive research has been devoted to identifying falsely inflated pagerank and ways to ignore links from documents with falsely inflated pagerank other link web pages the algorithm by used by and the and the algorithm\n",
      "204.0, 391 finish at source in 535 and answer in 243\n",
      "ANSWER\n",
      "the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary a document is represented as a vector each dimensions corresponds to a separate terms if a term occurs in the document its value in the vector is non zero relevancy rankings of documents in a keyword search can be calculated using the assumptions of document similarities theory by comparing the deviation of angles between each document vector and the original query vector where the query is represented as same kind of vector as the documents limitation there is some limitation of vector space model models based on and extending the vector space model include  generalized vector space model  enhanced topic based vector space model 1  etvsm  extends the vector space model by removing the constraint that the term vectors be orthogonal in contrast to the generalized vector space model the enhanced topic based vector space model does not depend on concurrence based similarities between terms the enhancement of the enhanced topic based vector space model  compared to the not enhanced one is a proposal on how to derive term vectors from an ontology \n",
      "SOURCE\n",
      "vector space model or term vector model is an algebraic model for representing text documents and any objects in general as vectors of identifiers such as for example index terms it is used in information filtering information retrieval indexing and relevancy rankings its first use was in the smart information retrieval system a document is represented as a vector each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed one of the best known schemes is tf idf weighting see the example below  the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  the vector space model has the following limitations 1 long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality 2 search keywords must precisely match document terms word substrings might result in a false positive match 3 semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match 4 the order in which the terms appear in the document is lost in the vector space representation \n",
      "SOURCE SEQUENCE: vector space model or term vector model is an model documents and in as vectors of as terms is in and relevancy rankings its in the a document is represented as a vector each corresponds to a separate term if a term occurs in the document its value in the vector is non zero of as term one of the is the the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of words in the the vector space model the 1 documents are represented a and a dimensionality search keywords document terms in a documents term vocabulary be in a the in the terms in the document is in the vector space\n",
      "60.0, 144 finish at source in 242 and answer in 212\n",
      "ANSWER\n",
      " bayes theorem or bayes rule  or something called bayesian reasoning the bayesian conspiracy is a multinational interdisciplinary and shadowy group of scientists that controls publication grants tenure and the illicit traffic in grad students  the best way to be accepted into the bayesian conspiracy is to join the campus crusade for bayes in high school or college and gradually work your way up to the inner circles bayes theorem  let and be sets conditional probability requires that 1  where denotes intersection  and  and also that 2  therefore 3  now let 4  so is an event in and for  then 5 6  but this can be written 7  so this paper proposes a new measure called scaled inverse document frequency sidf which evaluates the conditional specificity of query terms over a subset s of d and without making any assumption about term independence s can be estimated from search results or searches or computed from inverted index data we have evaluated sidf values from commercial search engines by submitting queries relevant to the financial investment domain results compare favorably across search engines and queries our approach has practical applications for real world scenarios like in web mining homeland security and keyword driven marketing research scenarios  \n",
      "SOURCE\n",
      "in probability theory bayes theorem often called bayes law after rev thomas bayes relates the conditional and marginal probabilities of two random events it is often used to compute posterior probabilities given observations for example a patient may be observed to have certain symptoms bayes theorem can be used to compute the probability that a proposed diagnosis is correct given that observation  see example 2 as a formal theorem bayes theorem is valid in all common interpretations of probability however it plays a central role in the debate around the foundations of statistics frequentist and bayesian interpretations disagree about the ways in which probabilities should be assigned in applications frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole while bayesians describe probabilities in terms of beliefs and degrees of uncertainty the articles on bayesian probability and frequentist probability discuss these debates in greater detail bayes theorem relates the conditional and marginal probabilities of events a and b where b has a non vanishing probability p a b frac p b  a  p a  p b  each term in bayes theorem has a conventional name  p a is the prior probability or marginal probability of a it is prior in the sense that it does not take into account any information about b  p a b is the conditional probability of a given b it is also called the posterior probability because it is derived from or depends upon the specified value of b  p b a is the conditional probability of b given a  p b is the prior or marginal probability of b and acts as a normalizing constant intuitively bayes theorem in this form describes the way in which one s beliefs about observing a are updated by having observed b  \n",
      "SOURCE SEQUENCE: in probability bayes theorem called bayes bayes the conditional and of is to for a be to have bayes theorem can be to the probability that a is that 2 a theorem bayes theorem is in of probability a in the the of and bayesian about the in which be in applications to to of or to of of the in terms of and of the bayesian probability and probability in bayes theorem the conditional and of a and where has a probability a a a term in bayes theorem has a a is the probability or probability of a is in the that into any about a is the conditional probability of a is also called the probability is from or the of a is the conditional probability of a is the or probability of and a bayes theorem in this the way in which s about a by\n",
      "33.0, 150 finish at source in 306 and answer in 204\n",
      "ANSWER\n",
      " dynamic programming is a method for efficiently solving a broad range of search and optimization problems which exhibit the characteristics of overlappling  dynamic programming design technique like divide and conquer method  the leading and most up to date textbook on the far ranging algorithmic methododogy of dynamic programming which can be used for optimal control the word programming in the name has nothing to do with writing computer programs mathematicians use the word to describe a set of rules which anyone can follow to solve a problem they do not have to be written in a computer language  dynamic programming was the brainchild of an american mathematician richard bellman who described the way of solving problems where you need to find the best decisions one after another in the forty odd years since this development the number of uses and applications of dynamic programming has increased enormously  for example in 1982 david kohler used dynamic programming to analyse the best way to play the game of darts  1 in recent years dynamic programming languages develope very fastly especially php and ruby there is no doubt that they have already became the first choice for many programmerers when developing web applications when you learn a new natural language and you start to use it you naturally you find yourself using new concepts and paradigms that enrich the use of the language you already know expect the same result with computer languages  \n",
      "SOURCE\n",
      "in mathematics and computer science dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure described below  the method takes much less time than naive methods the term was originally used in the 1940s by richard bellman to describe the process of solving problems where one needs to find the best decisions one after another by 1953 he had refined this to the modern meaning the field was founded as a systems analysis and engineering topic that is recognized by the ieee bellman s contribution is remembered in the name of the bellman equation a central result of dynamic programming which restates an optimization problem in recursive form the word programming in dynamic programming has no particular connection to computer programming at all and instead comes from the term mathematical programming  a synonym for optimization thus the program is the optimal plan for action that is produced for instance a finalized schedule of events at an exhibition is sometimes called a program programming in this sense means finding an acceptable plan of action an algorithm optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem for example the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices and then using this to pick the best overall path as shown in figure 1 in general we can solve a problem with optimal substructure using a three step process 1 break the problem into smaller subproblems 2 solve these problems optimally using this three step process recursively 3 use these optimal solutions to construct an optimal solution for the original problem the subproblems are themselves solved by dividing them into sub subproblems and so on until we reach some simple case that is solvable in constant time figure 2 the subproblem graph for the fibonacci sequence that it is not a tree but a dag indicates overlapping subproblems to say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems for example in the fibonacci sequence f3  f1  f2 and f4  f2  f3  computing each number involves computing f2 because both f3 and f4 are needed to compute f5 a naive approach to computing f5 may end up computing f2 twice or more this applies whenever overlapping subproblems are present a naive approach may waste time recomputing optimal solutions to subproblems it has already solved in order to avoid this we instead save the solutions to problems we have already solved then if we need to solve the same problem later we can retrieve and reuse our already computed solution this approach is called memoization not memorization although this term also fits  if we are sure we won t need a particular solution anymore we can throw it away to save space in some cases we can even compute the solutions to subproblems we know that we ll need in advance \n",
      "SOURCE SEQUENCE: in and computer dynamic programming is a method of solving problems that exhibit the of and optimal described the method the was used in the richard bellman to describe the of solving problems where one to find the best decisions one after another this to the the was a and that is the bellman is in the name of the bellman a result of dynamic programming which an optimization problem in the word programming in dynamic programming has no to computer programming and the programming a for optimization the is the optimal for that is for a of an is a programming in this an of an optimal that optimal of can be used to find the optimal of the problem for example the to a a in a can be first the to the and using this to the best in 1 in can solve a problem with optimal using a 1 the problem solve problems using this use optimal to an optimal for the problem the and on that is in the for the that it is not a a to that a problem has is to that the same used to solve many problems for example in the and number and to a to up this a optimal to it has already in to this the to problems have already need to solve the same problem can and already this is not this need a can it to in can the to know that need in\n",
      "59.0, 249 finish at source in 516 and answer in 240\n",
      "LCS features created!\n",
      "\n",
      "Features:  ['c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'c_6', 'lcs_word']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define an ngram range\n",
    "ngram_range = range(1,7)\n",
    "\n",
    "\n",
    "# The following code may take a minute to run, depending on your ngram_range\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "features_list = []\n",
    "\n",
    "# Create features in a features_df\n",
    "all_features = np.zeros((len(ngram_range)+1, len(complete_df)))\n",
    "\n",
    "# Calculate features for containment for ngrams in range\n",
    "i=0\n",
    "for n in ngram_range:\n",
    "    column_name = 'c_'+str(n)\n",
    "    features_list.append(column_name)\n",
    "    # create containment features\n",
    "    all_features[i]=np.squeeze(create_containment_features(complete_df, n))\n",
    "    i+=1\n",
    "\n",
    "# Calculate features for LCS_Norm Words \n",
    "features_list.append('lcs_word')\n",
    "all_features[i]= np.squeeze(create_lcs_features(complete_df))\n",
    "\n",
    "# create a features dataframe\n",
    "features_df = pd.DataFrame(np.transpose(all_features), columns=features_list)\n",
    "\n",
    "# Print all features/columns\n",
    "print()\n",
    "print('Features: ', features_list)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>lcs_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.082418</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983516</td>\n",
       "      <td>0.963542</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.901042</td>\n",
       "      <td>0.820755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.848739</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.608491</td>\n",
       "      <td>0.520737</td>\n",
       "      <td>0.449541</td>\n",
       "      <td>0.382488</td>\n",
       "      <td>0.846491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.522523</td>\n",
       "      <td>0.261364</td>\n",
       "      <td>0.159341</td>\n",
       "      <td>0.109290</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.060440</td>\n",
       "      <td>0.316062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.435644</td>\n",
       "      <td>0.110429</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.061033</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.504505</td>\n",
       "      <td>0.157360</td>\n",
       "      <td>0.037209</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.824675</td>\n",
       "      <td>0.711027</td>\n",
       "      <td>0.664311</td>\n",
       "      <td>0.625430</td>\n",
       "      <td>0.589655</td>\n",
       "      <td>0.553633</td>\n",
       "      <td>0.621711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.465409</td>\n",
       "      <td>0.377907</td>\n",
       "      <td>0.294798</td>\n",
       "      <td>0.236994</td>\n",
       "      <td>0.190751</td>\n",
       "      <td>0.484305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.489899</td>\n",
       "      <td>0.328704</td>\n",
       "      <td>0.244344</td>\n",
       "      <td>0.180995</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.597458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        c_1       c_2       c_3       c_4       c_5       c_6  lcs_word\n",
       "0  0.361702  0.082418  0.009756  0.000000  0.000000  0.000000  0.191781\n",
       "1  1.000000  0.983516  0.963542  0.943299  0.922280  0.901042  0.820755\n",
       "2  0.848739  0.704082  0.608491  0.520737  0.449541  0.382488  0.846491\n",
       "3  0.522523  0.261364  0.159341  0.109290  0.081967  0.060440  0.316062\n",
       "4  0.435644  0.110429  0.032432  0.005319  0.000000  0.000000  0.242574\n",
       "5  0.379630  0.061033  0.008439  0.003968  0.000000  0.000000  0.161172\n",
       "6  0.504505  0.157360  0.037209  0.004525  0.000000  0.000000  0.301653\n",
       "7  0.824675  0.711027  0.664311  0.625430  0.589655  0.553633  0.621711\n",
       "8  0.650000  0.465409  0.377907  0.294798  0.236994  0.190751  0.484305\n",
       "9  0.847458  0.489899  0.328704  0.244344  0.180995  0.150000  0.597458"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print some results \n",
    "features_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Features\n",
    "\n",
    "You should use feature correlation across the *entire* dataset to determine which features are ***too*** **highly-correlated** with each other to include both features in a single model. For this analysis, you can use the *entire* dataset due to the small sample size we have. \n",
    "\n",
    "All of our features try to measure the similarity between two texts. Since our features are designed to measure similarity, it is expected that these features will be highly-correlated. Many classification models, for example a Naive Bayes classifier, rely on the assumption that features are *not* highly correlated; highly-correlated features may over-inflate the importance of a single feature. \n",
    "\n",
    "So, you'll want to choose your features based on which pairings have the lowest correlation. These correlation values range between 0 and 1; from low to high correlation, and are displayed in a [correlation matrix](https://www.displayr.com/what-is-a-correlation-matrix/), below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>lcs_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c_1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_2</th>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_3</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_4</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_5</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_6</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcs_word</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           c_1   c_2   c_3   c_4   c_5   c_6  lcs_word\n",
       "c_1       1.00  0.96  0.94  0.92  0.91  0.90      0.98\n",
       "c_2       0.96  1.00  0.99  0.98  0.98  0.97      0.98\n",
       "c_3       0.94  0.99  1.00  1.00  0.99  0.98      0.97\n",
       "c_4       0.92  0.98  1.00  1.00  1.00  0.99      0.95\n",
       "c_5       0.91  0.98  0.99  1.00  1.00  1.00      0.94\n",
       "c_6       0.90  0.97  0.98  0.99  1.00  1.00      0.94\n",
       "lcs_word  0.98  0.98  0.97  0.95  0.94  0.94      1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Create correlation matrix for just Features to determine different models to test\n",
    "corr_matrix = features_df.corr().abs().round(2)\n",
    "\n",
    "# display shows all of a dataframe\n",
    "display(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Create selected train/test data\n",
    "\n",
    "Complete the `train_test_data` function below. This function should take in the following parameters:\n",
    "* `complete_df`: A DataFrame that contains all of our processed text data, file info, datatypes, and class labels\n",
    "* `features_df`: A DataFrame of all calculated features, such as containment for ngrams, n= 1-5, and lcs values for each text file listed in the `complete_df` (this was created in the above cells)\n",
    "* `selected_features`: A list of feature column names,  ex. `['c_1', 'lcs_word']`, which will be used to select the final features in creating train/test sets of data.\n",
    "\n",
    "It should return two tuples:\n",
    "* `(train_x, train_y)`, selected training features and their corresponding class labels (0/1)\n",
    "* `(test_x, test_y)`, selected training features and their corresponding class labels (0/1)\n",
    "\n",
    "** Note: x and y should be arrays of feature values and numerical class labels, respectively; not DataFrames.**\n",
    "\n",
    "Looking at the above correlation matrix, you should decide on a **cutoff** correlation value, less than 1.0, to determine which sets of features are *too* highly-correlated to be included in the final training and test data. If you cannot find features that are less correlated than some cutoff value, it is suggested that you increase the number of features (longer n-grams) to choose from or use *only one or two* features in your final model to avoid introducing highly-correlated features.\n",
    "\n",
    "Recall that the `complete_df` has a `Datatype` column that indicates whether data should be `train` or `test` data; this should help you split the data appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Takes in dataframes and a list of selected features (column names) \n",
    "# and returns (train_x, train_y), (test_x, test_y)\n",
    "def train_test_data(complete_df, features_df, selected_features):\n",
    "    '''Gets selected training and test features from given dataframes, and \n",
    "       returns tuples for training and test features and their corresponding class labels.\n",
    "       :param complete_df: A dataframe with all of our processed text data, datatypes, and labels\n",
    "       :param features_df: A dataframe of all computed, similarity features\n",
    "       :param selected_features: An array of selected features that correspond to certain columns in `features_df`\n",
    "       :return: training and test features and labels: (train_x, train_y), (test_x, test_y)'''\n",
    "    index_answers = complete_df['Class'] != -1\n",
    "    cdf, df = complete_df[index_answers], features_df[index_answers] \n",
    "    y = cdf['Class']\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df[selected_features].to_numpy(), y.to_numpy(), test_size=0.33, random_state=42) \n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "Below, test out your implementation and create the final train/test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "test_selection = list(features_df)[:2] # first couple columns as a test\n",
    "# test that the correct train/test data is created\n",
    "(train_x, train_y), (test_x, test_y) = train_test_data(complete_df, features_df, test_selection)\n",
    "\n",
    "# params: generated train/test data\n",
    "tests.test_data_split(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Select \"good\" features\n",
    "\n",
    "If you passed the test above, you can create your own train/test data, below. \n",
    "\n",
    "Define a list of features you'd like to include in your final mode, `selected_features`; this is a list of the features names you want to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  63\n",
      "Test size:  32\n",
      "\n",
      "Training df sample: \n",
      " [[0.37962963 0.06103286 0.00843882 0.00396825 0.         0.\n",
      "  0.16117216]\n",
      " [0.55555556 0.11494253 0.02617801 0.00515464 0.         0.\n",
      "  0.24271845]\n",
      " [0.98717949 0.96491228 0.94017094 0.91452991 0.88793103 0.86086957\n",
      "  0.99230769]\n",
      " [0.65354331 0.37313433 0.1952381  0.12440191 0.08653846 0.05797101\n",
      "  0.53669725]\n",
      " [0.88679245 0.66666667 0.56164384 0.47222222 0.3943662  0.32857143\n",
      "  0.775     ]\n",
      " [0.3671875  0.05472637 0.         0.         0.         0.\n",
      "  0.23502304]\n",
      " [0.7388535  0.54873646 0.4779661  0.45945946 0.45084746 0.44217687\n",
      "  0.60645161]\n",
      " [0.82467532 0.71102662 0.66431095 0.62542955 0.58965517 0.55363322\n",
      "  0.62171053]\n",
      " [0.60810811 0.39855072 0.29878049 0.22543353 0.1741573  0.1420765\n",
      "  0.34926471]\n",
      " [0.57272727 0.3        0.205      0.1372549  0.08780488 0.05339806\n",
      "  0.41666667]]\n"
     ]
    }
   ],
   "source": [
    "# Select your list of features, this should be column names from features_df\n",
    "# ex. ['c_1', 'lcs_word']\n",
    "selected_features = ['c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'c_6', 'lcs_word']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = train_test_data(complete_df, features_df, selected_features)\n",
    "\n",
    "# check that division of samples seems correct\n",
    "# these should add up to 95 (100 - 5 original files)\n",
    "print('Training size: ', len(train_x))\n",
    "print('Test size: ', len(test_x))\n",
    "print()\n",
    "print('Training df sample: \\n', train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02000135, 0.0290664 , 0.00509646, ..., 0.02100291, 0.01215351,\n",
       "        0.02726565],\n",
       "       [0.0290664 , 0.04233743, 0.00766247, ..., 0.03134319, 0.01786834,\n",
       "        0.0399943 ],\n",
       "       [0.00509646, 0.00766247, 0.0025095 , ..., 0.00904408, 0.00334519,\n",
       "        0.00855208],\n",
       "       ...,\n",
       "       [0.02100291, 0.03134319, 0.00904408, ..., 0.03344983, 0.01334357,\n",
       "        0.0339396 ],\n",
       "       [0.01215351, 0.01786834, 0.00334519, ..., 0.01334357, 0.00904671,\n",
       "        0.01577977],\n",
       "       [0.02726565, 0.0399943 , 0.00855208, ..., 0.0339396 , 0.01577977,\n",
       "        0.04083971]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: How did you decide on which features to include in your final model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Creating Final Data Files\n",
    "\n",
    "Now, you are almost ready to move on to training a model in SageMaker!\n",
    "\n",
    "You'll want to access your train and test data in SageMaker and upload it to S3. In this project, SageMaker will expect the following format for your train/test data:\n",
    "* Training and test data should be saved in one `.csv` file each, ex `train.csv` and `test.csv`\n",
    "* These files should have class  labels in the first column and features in the rest of the columns\n",
    "\n",
    "This format follows the practice, outlined in the [SageMaker documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html), which reads: \"Amazon SageMaker requires that a CSV file doesn't have a header record and that the target variable [class label] is in the first column.\"\n",
    "\n",
    "## EXERCISE: Create csv files\n",
    "\n",
    "Define a function that takes in x (features) and y (labels) and saves them to one `.csv` file at the path `data_dir/filename`.\n",
    "\n",
    "It may be useful to use pandas to merge your features and labels into one DataFrame and then convert that into a csv file. You can make sure to get rid of any incomplete rows, in a DataFrame, by using `dropna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(x, y, filename, data_dir):\n",
    "    '''Merges features and labels and converts them into one csv file with labels in the first column.\n",
    "       :param x: Data features\n",
    "       :param y: Data labels\n",
    "       :param file_name: Name of csv file, ex. 'train.csv'\n",
    "       :param data_dir: The directory where files will be saved\n",
    "       '''\n",
    "    # make data dir, if it does not exist\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    \n",
    "    # your code here\n",
    "    pd.concat([pd.DataFrame(y), pd.DataFrame(x)], axis=1)\\\n",
    "             .to_csv(os.path.join(data_dir, filename), header=False, index=False)\n",
    "    \n",
    "    # nothing is returned, but a print statement indicates that the function has run\n",
    "    print('Path created: '+str(data_dir)+'/'+str(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "Test that your code produces the correct format for a `.csv` file, given some text features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: test_csv/to_delete.csv\n",
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "fake_x = [ [0.39814815, 0.0001, 0.19178082], \n",
    "           [0.86936937, 0.44954128, 0.84649123], \n",
    "           [0.44086022, 0., 0.22395833] ]\n",
    "\n",
    "fake_y = [0, 1, 1]\n",
    "\n",
    "make_csv(fake_x, fake_y, filename='to_delete.csv', data_dir='test_csv')\n",
    "\n",
    "# read in and test dimensions\n",
    "fake_df = pd.read_csv('test_csv/to_delete.csv', header=None)\n",
    "\n",
    "# check shape\n",
    "assert fake_df.shape==(3, 4), \\\n",
    "      'The file should have as many rows as data_points and as many columns as features+1 (for indices).'\n",
    "# check that first column = labels\n",
    "assert np.all(fake_df.iloc[:,0].values==fake_y), 'First column is not equal to the labels, fake_y.'\n",
    "print('Tests passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the test csv file, generated above\n",
    "! rm -rf test_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've passed the tests above, run the following cell to create `train.csv` and `test.csv` files in a directory that you specify! This will save the data in a local directory. Remember the name of this directory because you will reference it again when uploading this data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: plagiarism_data/train.csv\n",
      "Path created: plagiarism_data/test.csv\n"
     ]
    }
   ],
   "source": [
    "# can change directory, if you want\n",
    "data_dir = 'plagiarism_data'\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "make_csv(train_x, train_y, filename='train.csv', data_dir=data_dir)\n",
    "make_csv(test_x, test_y, filename='test.csv', data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "Now that you've done some feature engineering and created some training and test data, you are ready to train and deploy a plagiarism classification model. The next notebook will utilize SageMaker resources to train and test a model that you design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
